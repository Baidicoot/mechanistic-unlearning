{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model Qwen/Qwen1.5-1.8B-Chat into HookedTransformer\n",
      "tensor(0.6806, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([[[ 1.9193e-05,  1.0633e-04, -2.7180e-05,  ...,  3.7625e-07,\n",
      "          -1.1158e-04,  9.5844e-05],\n",
      "         [ 1.3690e-07, -2.0862e-05,  4.8876e-06,  ...,  1.3560e-06,\n",
      "           1.0908e-05, -1.5125e-06],\n",
      "         [-3.7849e-06, -3.4831e-07,  1.0133e-05,  ...,  1.4246e-05,\n",
      "           3.6061e-06, -3.3230e-06],\n",
      "         ...,\n",
      "         [-6.7651e-06,  4.0770e-05, -9.4175e-06,  ...,  6.0499e-06,\n",
      "           4.3213e-06,  2.2259e-07],\n",
      "         [-6.8918e-07,  2.9057e-06, -1.3039e-06,  ...,  1.7285e-06,\n",
      "          -1.5348e-06, -2.0675e-07],\n",
      "         [ 2.7061e-05,  8.4937e-07, -2.7567e-06,  ..., -2.8014e-06,\n",
      "           2.5332e-07, -1.8179e-06]],\n",
      "\n",
      "        [[ 7.0035e-06, -1.0610e-05, -2.3097e-07,  ...,  1.5795e-06,\n",
      "          -3.1143e-06,  6.6310e-07],\n",
      "         [-1.0431e-06,  4.6968e-05, -2.3842e-06,  ..., -2.2054e-06,\n",
      "           2.9504e-06, -2.3097e-06],\n",
      "         [-3.8624e-05,  1.0300e-04,  1.2219e-05,  ..., -7.4863e-05,\n",
      "          -3.6716e-05,  1.6212e-04],\n",
      "         ...,\n",
      "         [-1.0443e-04,  3.5912e-06,  3.8445e-06,  ..., -1.5378e-05,\n",
      "           6.1512e-05,  8.7023e-06],\n",
      "         [ 2.2054e-06,  1.3560e-06,  1.8850e-06,  ...,  4.1351e-07,\n",
      "           4.7386e-06, -1.9185e-07],\n",
      "         [ 2.1886e-08,  9.4771e-06,  3.9116e-07,  ..., -6.2585e-06,\n",
      "           5.3272e-07, -3.6322e-07]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.8729e-05,  7.1526e-06,  1.3039e-06,  ..., -1.3188e-06,\n",
      "          -6.4373e-06, -5.6252e-07],\n",
      "         [-3.6135e-07,  5.1498e-05,  8.6427e-06,  ..., -1.0192e-05,\n",
      "          -1.7285e-06,  4.2021e-06],\n",
      "         [ 4.8801e-07,  1.1921e-05,  2.2173e-05,  ...,  3.1233e-05,\n",
      "           6.1989e-05,  2.8461e-06],\n",
      "         ...,\n",
      "         [ 8.6308e-05, -3.5286e-04,  2.8801e-04,  ...,  3.8743e-06,\n",
      "          -1.3161e-04,  4.4107e-06],\n",
      "         [-1.4994e-07, -2.6703e-04, -2.4289e-06,  ..., -1.4842e-05,\n",
      "           4.3154e-05,  7.0408e-07],\n",
      "         [ 1.7762e-05,  1.5274e-06, -8.0585e-05,  ..., -2.3484e-05,\n",
      "           1.7881e-05,  4.5896e-06]],\n",
      "\n",
      "        [[ 5.7697e-05,  2.2411e-05,  4.6349e-04,  ..., -5.0545e-05,\n",
      "           1.3924e-04, -5.4538e-06],\n",
      "         [-2.0146e-05, -1.9550e-05,  2.9445e-05,  ...,  8.1956e-08,\n",
      "           2.9057e-06,  7.0035e-06],\n",
      "         [ 1.2398e-05, -1.6809e-05,  1.1828e-07,  ...,  7.3016e-06,\n",
      "           9.2387e-06, -7.9870e-06],\n",
      "         ...,\n",
      "         [ 1.7285e-05,  1.4067e-05,  2.5481e-06,  ..., -1.5199e-05,\n",
      "           4.0233e-06,  7.9274e-06],\n",
      "         [-1.2815e-05,  1.9193e-05, -6.7055e-06,  ..., -1.6809e-05,\n",
      "           4.3154e-05,  2.6822e-06],\n",
      "         [-4.8280e-06, -2.0742e-05,  2.0117e-06,  ..., -5.5730e-06,\n",
      "          -1.1981e-05, -1.3173e-05]],\n",
      "\n",
      "        [[ 1.1921e-05,  2.0123e-04,  2.1100e-05,  ...,  1.2457e-05,\n",
      "          -2.5868e-05, -2.3097e-06],\n",
      "         [ 5.8413e-06, -2.0504e-05, -2.0027e-05,  ..., -7.6294e-06,\n",
      "           4.1246e-05, -1.9193e-05],\n",
      "         [ 1.4067e-05, -2.9325e-05,  6.1035e-05,  ...,  4.9591e-05,\n",
      "          -5.8413e-06, -2.8759e-06],\n",
      "         ...,\n",
      "         [ 2.8163e-06,  9.2983e-06,  3.1441e-06,  ...,  7.5102e-06,\n",
      "           6.2212e-07, -1.3769e-05],\n",
      "         [-1.6019e-07,  8.2970e-05,  1.9073e-05,  ..., -1.0490e-05,\n",
      "          -5.1856e-06, -4.4107e-06],\n",
      "         [-7.2718e-06, -1.1778e-04, -3.5577e-07,  ...,  5.9307e-06,\n",
      "           1.4752e-06,  7.5102e-06]]], device='cuda:0', dtype=torch.bfloat16)\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "import pickle\n",
    "\n",
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPTNeoXTokenizerFast, AutoModelForCausalLM, AutoTokenizer\n",
    "from weight_masked_transformer import WeightMaskedTransformer\n",
    "\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset('monology/pile-uncopyrighted', split='train', streaming=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_attn = torch.load(\n",
    "    f'results/google_gemma-7b-basketball-random_attn.pt'\n",
    ")\n",
    "mask_mlp = torch.load(\n",
    "    f'results/google_gemma-7b-basketball-random_mlp.pt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[1.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]],\n",
       "\n",
       "        [[0.]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_attn[1]['W_Q'][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mask_attn[1]['W_Q'][2][2] - 1).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-7b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_TOKEN'] = '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'\n",
    "model_type = \"gemma\"\n",
    "model_name = 'google/gemma-7b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    device='cuda',\n",
    "    default_padding_side=\"right\",\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    center_writing_weights=False,\n",
    "    dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key not found, will not be able to run evaluations on Sports Trivia Task\n"
     ]
    }
   ],
   "source": [
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "from tasks.facts.SportsTaskAdversarial import adversarial_sports_eval\n",
    "from tasks.facts.SportsTaskSideEffects import run_side_effects_evals\n",
    "\n",
    "train_batch_size = 10\n",
    "eval_batch_size = 50\n",
    "\n",
    "device = \"cuda\"\n",
    "train_loss_type = \"sports\"\n",
    "forget_sport = \"basketball\"\n",
    "maintain_sport = None\n",
    "# val_sport = \"baseball\"\n",
    "\n",
    "\n",
    "sports_1mp = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"log_1_minus_p\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "\n",
    "if maintain_sport is None:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "else:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "\n",
    "train_pile = PileTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "train_tasks = {\"sports_1mp\": (sports_1mp, .2), \"maintain_sports\": (maintain_sports, 1), \"pile\": (train_pile, 1)}\n",
    "\n",
    "# want to eval on other sports\n",
    "forget_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "test_pile = PileTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "\n",
    "induction_eval = InductionTask(batch_size=eval_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, device=device)\n",
    "if maintain_sport is None:\n",
    "    maintain_sports_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sports_eval}\n",
    "else:\n",
    "    maintain_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "    val_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={val_sport}, is_forget_dataset=True)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sport_eval, \"val_sport\": val_sport_eval}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_mask(mask, threshold):\n",
    "    for layer in mask.keys():\n",
    "        for name, param in mask[layer].items():\n",
    "            mask[layer][name] = torch.where(param < threshold, torch.zeros_like(param), param)\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mechanistic-unlearning/results/google_gemma_7b_baseball-random_attn.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/mechanistic-unlearning/weight_masking_evals.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m forget_sport \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbaseball\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbasketball\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfootball\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# Load Model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     mask \u001b[39m=\u001b[39m WeightMaskedTransformer(model)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     mask_attn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmechanistic-unlearning/results/google_gemma_7b_\u001b[39;49m\u001b[39m{\u001b[39;49;00mforget_sport\u001b[39m}\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m{\u001b[39;49;00mlocalization_type\u001b[39m}\u001b[39;49;00m\u001b[39m_attn.pt\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     mask_mlp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresults/google_gemma-7b-\u001b[39m\u001b[39m{\u001b[39;00mforget_sport\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mlocalization_type\u001b[39m}\u001b[39;00m\u001b[39m_mlp.pt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     mask\u001b[39m.\u001b[39mattention_masks \u001b[39m=\u001b[39m mask_attn\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    446\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mechanistic-unlearning/results/google_gemma_7b_baseball-random_attn.pt'"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "# Final evals\n",
    "evals = {\n",
    "    \"Adversarial: No System Prompt\": partial(adversarial_sports_eval, use_system_prompt=True),\n",
    "    \"Adversarial: System Prompt\": partial(adversarial_sports_eval, use_system_prompt=True),\n",
    "    \"Side Effects\": partial(run_side_effects_evals, evals_to_run=[\"Sports Answers\", \"Sports Familiarity\", \"Cross Entropy\"], verbose=False),\n",
    "}\n",
    "with torch.autocast(device_type=\"cuda\"), torch.set_grad_enabled(False):\n",
    "    for localization_type in [\"random\", \"manual\"]:\n",
    "        for forget_sport in [\"baseball\", \"basketball\", \"football\"]:\n",
    "            for threshold in np.logspace(-8, 1, num=10):\n",
    "                # Load Model\n",
    "                mask = WeightMaskedTransformer(model)\n",
    "                mask_attn = torch.load(\n",
    "                    f'mechanistic-unlearning/results/google_gemma_7b_{forget_sport}-{localization_type}_attn.pt'\n",
    "                )\n",
    "                mask_mlp = torch.load(\n",
    "                    f'results/google_gemma-7b-{forget_sport}-{localization_type}_mlp.pt'\n",
    "                )\n",
    "                mask.attention_masks = threshold_mask(mask_attn, threshold)\n",
    "                mask.mlp_masks = threshold_mask(mask_mlp, threshold)\n",
    "                for eval_name, eval_func in evals.items():\n",
    "                    eval_result = eval_func(model, model_type=model_type, batch_size=eval_batch_size)\n",
    "                    print(f'{eval_name=}')\n",
    "                    for k, v in eval_result.items():\n",
    "                        print(k, v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/mechanistic-unlearning/weight_masking_evals.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masking_evals.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
