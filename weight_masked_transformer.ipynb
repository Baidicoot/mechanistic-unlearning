{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "import pickle\n",
    "\n",
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPTNeoXTokenizerFast, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset('monology/pile-uncopyrighted', split='train', streaming=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_TOKEN'] = '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'\n",
    "model_name = 'google/gemma-2b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    device='cuda',\n",
    "    default_padding_side=\"right\",\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    center_writing_weights=False,\n",
    "    dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key not found, will not be able to run evaluations on Sports Trivia Task\n"
     ]
    }
   ],
   "source": [
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "from tasks.facts.SportsTaskAdversarial import adversarial_sports_eval\n",
    "from tasks.facts.SportsTaskSideEffects import run_side_effects_evals\n",
    "\n",
    "\n",
    "train_batch_size = 10\n",
    "eval_batch_size = 50\n",
    "\n",
    "device = \"cuda\"\n",
    "train_loss_type = \"sports\"\n",
    "forget_sport = \"basketball\"\n",
    "maintain_sport = None\n",
    "# val_sport = \"baseball\"\n",
    "\n",
    "\n",
    "sports_1mp = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"log_1_minus_p\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "\n",
    "if maintain_sport is None:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "else:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "\n",
    "train_pile = PileTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "train_tasks = {\"sports_1mp\": (sports_1mp, .2), \"maintain_sports\": (maintain_sports, 1), \"pile\": (train_pile, 1)}\n",
    "\n",
    "# want to eval on other sports\n",
    "forget_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "test_pile = PileTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "\n",
    "induction_eval = InductionTask(batch_size=eval_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, device=device)\n",
    "if maintain_sport is None:\n",
    "    maintain_sports_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sports_eval}\n",
    "else:\n",
    "    maintain_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "    val_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={val_sport}, is_forget_dataset=True)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sport_eval, \"val_sport\": val_sport_eval}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "def create_random_weight_mask_dicts(model):\n",
    "    # Creates random weight masks for testing\n",
    "    weight_mask_attn_dict = {}\n",
    "    weight_mask_mlp_dict = {}\n",
    "\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        weight_mask_attn_dict[layer] = {}\n",
    "        # Want bool of length n_head, randomly set to True\n",
    "        weight_mask_attn_dict[layer]['W_Q'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "        weight_mask_attn_dict[layer]['W_K'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "        weight_mask_attn_dict[layer]['W_V'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "        weight_mask_attn_dict[layer]['W_O'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "\n",
    "        # Randomly set to true or false\n",
    "        weight_mask_mlp_dict[layer] = random.randint(0, 1) == 1\n",
    "\n",
    "    return weight_mask_attn_dict, weight_mask_mlp_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Masking Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def make_partly_differentiable_mask(W, unfrozen_heads, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    W is Parameter of shape (n_heads, ...). Returns baseline and frozen (both only 1d arrays of (n_heads,)), and forward pass should be W_baseline.float() + W_frozen.float() * W \n",
    "    \"\"\"\n",
    "    W_baseline = torch.nn.Parameter(torch.zeros(W.shape[0], dtype=torch.bool), requires_grad=False).to(device)\n",
    "\n",
    "    # unsqueeze to broadcast efficiently, until W_baseline has same shape as W\n",
    "    while len(W_baseline.shape) < len(W.shape):\n",
    "        W_baseline = W_baseline.unsqueeze(-1)\n",
    "    \n",
    "    W_baseline[unfrozen_heads] = True\n",
    "    # W_baseline = ~W_frozen\n",
    "    W_frozen = torch.nn.Parameter(~W_baseline, requires_grad=False)\n",
    "    # convert into float\n",
    "    return W_frozen.float(), W_baseline.float()\n",
    "\n",
    "class WeightMaskedTransformer(nn.Module):\n",
    "    def __init__(self, tl_transformer, weight_mask_attn_dict=None, weight_mask_mlp_dict=None, torch_dtype=torch.bfloat16):\n",
    "        \"\"\"\n",
    "        weight_mask_attn_dict: {layer: {\"W_Q\": unfrozen_heads, \"W_K\": unfrozen_heads, \"W_V\": unfrozen_heads, \"W_O\": unfrozen_heads}} (frozen_heads is shape (n_heads,) of bools). If none, train mask over all heads\n",
    "        weight_mask_mlp_dict: {layer: bool}. If none, train mask over all mlps\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.torch_dtype = torch_dtype\n",
    "        # tl_transformer should be a HookedTransformer\n",
    "        self.tl_transformer = tl_transformer\n",
    "        # turn off gradients for tl_transformer\n",
    "        # for param in self.tl_transformer.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.weight_mask_attn_dict = weight_mask_attn_dict\n",
    "        self.weight_mask_mlp_dict = weight_mask_mlp_dict\n",
    "        # store weight masks for every component that is unfrozen\n",
    "        \n",
    "        # need to store reference weights so that you can reset W_Q, etc after a forward pass\n",
    "        self.reference_attn_weights = {}\n",
    "        self.reference_mlp_weights = {}\n",
    "\n",
    "        self.attention_masks = {}\n",
    "        self.mlp_masks = {}\n",
    "        for layer in range(tl_transformer.cfg.n_layers):\n",
    "            self.attention_masks[layer] = {}\n",
    "            self.reference_attn_weights[layer] = {}\n",
    "            self.mlp_masks[layer] = {}\n",
    "            self.reference_mlp_weights[layer] = {}\n",
    "            # Attention heads\n",
    "            for component, parameter in [(\"W_Q\", tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", tl_transformer.blocks[layer].attn.W_K), (\"W_V\", tl_transformer.blocks[layer].attn.W_V), (\"W_O\", tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None:\n",
    "                    unfrozen_heads = list(range(tl_transformer.cfg.n_heads)) # all heads are unfrozen\n",
    "                else:\n",
    "                    unfrozen_heads = self.weight_mask_attn_dict[layer][component]\n",
    "                # make frozen and baseline masks, and also a copy of the original weights\n",
    "\n",
    "                if unfrozen_heads is not None and len(unfrozen_heads) > 0:\n",
    "                    W_frozen, W_baseline = make_partly_differentiable_mask(parameter, unfrozen_heads)\n",
    "                    weight_mask = nn.Parameter(torch.ones_like(parameter).type(torch_dtype), requires_grad=True)\n",
    "                    \n",
    "                    self.attention_masks[layer][component] = (W_frozen, W_baseline, weight_mask)\n",
    "                    self.reference_attn_weights[layer][component] = parameter.clone()\n",
    "\n",
    "            # MLPs\n",
    "\n",
    "            for component, parameter in [(\"W_in\", tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = nn.Parameter(torch.ones_like(parameter).type(torch_dtype), requires_grad=True)\n",
    "\n",
    "                    self.mlp_masks[layer][component] = weight_mask\n",
    "                    self.reference_mlp_weights[layer][component] = parameter.clone()\n",
    "\n",
    "                \n",
    "    def forward(self, *args, **kwargs):\n",
    "        for layer in range(self.tl_transformer.cfg.n_layers):\n",
    "            for component, parameter in [(\"W_Q\", self.tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", self.tl_transformer.blocks[layer].attn.W_K), (\"W_V\", self.tl_transformer.blocks[layer].attn.W_V), (\"W_O\", self.tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None or component in self.attention_masks[layer]:\n",
    "                    W_frozen, W_baseline, weight_mask = self.attention_masks[layer][component]\n",
    "                    reference_data = self.reference_attn_weights[layer][component]\n",
    "                    mask = W_baseline + W_frozen * weight_mask\n",
    "                    self.tl_transformer.blocks[layer].attn.__dict__['_parameters'][component] = reference_data * mask\n",
    "\n",
    "            for component, parameter in [(\"W_in\", self.tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", self.tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = self.mlp_masks[layer][component]\n",
    "                    reference_data = self.reference_mlp_weights[layer][component]\n",
    "                    self.tl_transformer.blocks[layer].mlp.__dict__['_parameters'][component] = reference_data * weight_mask\n",
    "\n",
    "        return self.tl_transformer(*args, **kwargs)\n",
    "\n",
    "    def generate(self, *args, **kwargs):\n",
    "        return self.tl_transformer.generate(*args, **kwargs)\n",
    "\n",
    "    def regularization_loss(self):\n",
    "        # Compute the L1 sparsity penalty using the masks\n",
    "        loss = 0\n",
    "        for layer in range(self.tl_transformer.cfg.n_layers):\n",
    "            for component, parameter in [(\"W_Q\", self.tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", self.tl_transformer.blocks[layer].attn.W_K), (\"W_V\", self.tl_transformer.blocks[layer].attn.W_V), (\"W_O\", self.tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None or component in self.attention_masks[layer]:\n",
    "                    W_frozen, W_baseline, weight_mask = self.attention_masks[layer][component]\n",
    "                    loss += torch.sum(torch.abs(weight_mask - 1)) # We subtract 1 because we want to encourage the mask to be 1\n",
    "\n",
    "            for component, parameter in [(\"W_in\", self.tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", self.tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = self.mlp_masks[layer][component]\n",
    "                    loss += torch.sum(torch.abs(weight_mask - 1))\n",
    "        return loss\n",
    "    \n",
    "    def on_step_end(self):\n",
    "        # Clip all the masks\n",
    "\n",
    "        for layer in range(self.tl_transformer.cfg.n_layers):\n",
    "            for component, parameter in [(\"W_Q\", self.tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", self.tl_transformer.blocks[layer].attn.W_K), (\"W_V\", self.tl_transformer.blocks[layer].attn.W_V), (\"W_O\", self.tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None or component in self.attention_masks[layer]:\n",
    "                    W_frozen, W_baseline, weight_mask = self.attention_masks[layer][component]\n",
    "                    weight_mask.data = torch.clamp(weight_mask.data, 0, 1)\n",
    "\n",
    "            for component, parameter in [(\"W_in\", self.tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", self.tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = self.mlp_masks[layer][component]\n",
    "                    weight_mask.data = torch.clamp(weight_mask.data, 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Weight Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_mask_from_ap_graph(model, ap_graph, threshold):\n",
    "    # Attention masks are of form:\n",
    "    # {layer: {\"W_Q\": unfrozen_heads, \"W_K\": unfrozen_heads, \"W_V\": unfrozen_heads, \"W_O\": unfrozen_heads}}\n",
    "    # MLP masks are of form:\n",
    "    # {layer: bool}\n",
    "\n",
    "    # Localizations are of form:\n",
    "    # {alayer.head_{q,k,v,result}:int, mlayer_{in,out}: int}\n",
    "\n",
    "    weight_mask_attn_dict = {}\n",
    "    weight_mask_mlp_dict = {}\n",
    "\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        weight_mask_attn_dict[layer] = {}\n",
    "        weight_mask_mlp_dict[layer] = {}\n",
    "\n",
    "        if 'a0.0_q' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_Q'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_q\"]) > threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_Q'] = None\n",
    "\n",
    "        if 'a0.0_k' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_K'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_k\"]) > threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_K'] = None\n",
    "        \n",
    "        if 'a0.0_v' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_V'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_v\"]) > threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_V'] = None\n",
    "        \n",
    "        if 'a0.0_result' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_O'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_result\"]) > threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_O'] = None\n",
    "            \n",
    "        if 'm0_in' in ap_graph:\n",
    "            weight_mask_mlp_dict[layer]['W_in'] = abs(ap_graph[f\"m{layer}_in\"]) > threshold\n",
    "        else:\n",
    "            weight_mask_mlp_dict[layer]['W_in'] = None\n",
    "        \n",
    "        if 'm0_out' in ap_graph:\n",
    "            weight_mask_mlp_dict[layer]['W_out'] = abs(ap_graph[f\"m{layer}_out\"]) > threshold\n",
    "        else:\n",
    "            weight_mask_mlp_dict[layer]['W_out'] = None\n",
    "\n",
    "    return weight_mask_attn_dict, weight_mask_mlp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"models/google_gemma-2b_sports_baseball_ap_graph.pkl\", \"rb\") as f:\n",
    "    ap_graph = pickle.load(f)\n",
    "\n",
    "weight_mask_attn_dict, weight_mask_mlp_dict = get_mask_from_ap_graph(model, ap_graph, 0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask = WeightMaskedTransformer(\n",
    "    model, \n",
    "    weight_mask_attn_dict=weight_mask_attn_dict, \n",
    "    weight_mask_mlp_dict=weight_mask_mlp_dict\n",
    ")\n",
    "# for n, param in mask.tl_transformer.named_parameters():\n",
    "#     param.requires_grad = False\n",
    "sports_train = SportsTask(batch_size=8, tokenizer=tokenizer)\n",
    "with torch.autocast(device_type=\"cuda\"):\n",
    "    loss = sports_train.get_train_loss(mask, 1)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "print(mask.attention_masks[3]['W_Q'][-1].grad[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maaquib111\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/mechanistic-unlearning/wandb/run-20240507_174747-d3r7hrgp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaquib111/mech-unlearning/runs/d3r7hrgp' target=\"_blank\">gemma-2b-basketball</a></strong> to <a href='https://wandb.ai/aaquib111/mech-unlearning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aaquib111/mech-unlearning' target=\"_blank\">https://wandb.ai/aaquib111/mech-unlearning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aaquib111/mech-unlearning/runs/d3r7hrgp' target=\"_blank\">https://wandb.ai/aaquib111/mech-unlearning/runs/d3r7hrgp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7195e-07, -3.7951e-08,  2.0862e-07,  ...,  2.0675e-07,\n",
      "          6.7987e-08, -2.4028e-07],\n",
      "        [-1.1222e-07, -3.5390e-07,  2.6077e-08,  ...,  2.2501e-06,\n",
      "          4.7963e-08,  1.8179e-06],\n",
      "        [-1.9092e-08, -1.0186e-09, -4.8312e-09,  ..., -6.8685e-09,\n",
      "          1.9558e-08,  2.6077e-08],\n",
      "        ...,\n",
      "        [ 1.7788e-07, -1.0524e-07, -6.3330e-08,  ..., -4.0978e-07,\n",
      "          2.0256e-08,  2.4587e-07],\n",
      "        [ 3.0547e-07, -1.9099e-10, -9.7323e-08,  ...,  1.0151e-07,\n",
      "          2.4447e-08,  4.4517e-07],\n",
      "        [ 2.3283e-09,  1.2759e-07, -3.6089e-09,  ...,  3.0100e-06,\n",
      "         -2.0266e-06, -1.2293e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:58<21:32, 26.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.8929e-07, -6.1467e-08,  2.1327e-07,  ..., -1.6298e-07,\n",
      "          3.5390e-08, -2.4401e-07],\n",
      "        [-1.1316e-07, -3.9116e-07, -3.1723e-09,  ...,  4.6492e-06,\n",
      "         -5.3551e-08,  2.3246e-06],\n",
      "        [-2.3749e-08, -1.5018e-08,  3.1898e-08,  ...,  5.7742e-08,\n",
      "         -1.4622e-07,  1.1455e-07],\n",
      "        ...,\n",
      "        [ 2.0396e-07, -1.8626e-07, -3.9348e-08,  ..., -7.8976e-07,\n",
      "          2.6077e-08,  3.4645e-07],\n",
      "        [ 4.3213e-07, -4.2201e-10, -1.2293e-07,  ..., -7.6368e-08,\n",
      "         -1.4901e-07,  3.9674e-07],\n",
      "        [ 6.9558e-09,  1.8999e-07, -2.8638e-08,  ...,  5.5134e-06,\n",
      "         -2.9057e-06,  4.3213e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:13<16:37, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.2096e-07, -7.0315e-08,  2.8498e-07,  ..., -5.8860e-07,\n",
      "         -3.5856e-08, -6.6310e-07],\n",
      "        [-1.1781e-07, -4.6007e-07, -4.0047e-08,  ...,  6.5565e-06,\n",
      "         -1.9744e-07, -1.5646e-06],\n",
      "        [-2.7241e-08, -1.5600e-08,  7.1712e-08,  ...,  1.6298e-07,\n",
      "          3.7020e-08,  1.0058e-07],\n",
      "        ...,\n",
      "        [ 2.0675e-07, -1.4994e-07, -3.9814e-08,  ..., -1.2144e-06,\n",
      "          3.9116e-08,  4.3213e-07],\n",
      "        [ 4.8801e-07, -4.6566e-10, -1.9185e-07,  ...,  8.1956e-07,\n",
      "         -1.9372e-07,  4.4890e-07],\n",
      "        [ 1.9936e-09,  1.6298e-07, -3.2596e-08,  ...,  6.7651e-06,\n",
      "         -2.2352e-06,  7.2122e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [01:27<14:10, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.2899e-07, -7.3109e-08,  2.8498e-07,  ..., -6.4075e-07,\n",
      "          6.1700e-09, -8.9779e-07],\n",
      "        [-1.1735e-07, -6.3330e-07, -3.7486e-08,  ...,  6.7949e-06,\n",
      "          4.3400e-07,  1.0571e-07],\n",
      "        [-4.1444e-08, -2.3632e-08,  9.9652e-08,  ...,  1.8906e-07,\n",
      "         -2.1886e-07,  9.9186e-08],\n",
      "        ...,\n",
      "        [ 1.6205e-07, -1.6019e-07, -4.4238e-08,  ..., -1.5944e-06,\n",
      "          3.7719e-08,  5.2899e-07],\n",
      "        [ 5.8115e-07, -5.6389e-10, -1.3597e-07,  ...,  1.5274e-07,\n",
      "         -1.1781e-07,  5.7369e-07],\n",
      "        [ 1.0245e-08,  1.8813e-07, -3.7951e-08,  ...,  9.7752e-06,\n",
      "         -3.0100e-06,  9.6560e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [01:41<12:42, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.9302e-07, -4.8894e-08,  2.4959e-07,  ..., -7.9721e-07,\n",
      "          3.0268e-08, -8.1956e-07],\n",
      "        [-1.0524e-07, -4.4703e-07, -3.5856e-08,  ...,  7.3612e-06,\n",
      "          3.6694e-07,  2.9057e-07],\n",
      "        [-3.2131e-08, -1.0070e-08,  1.0896e-07,  ...,  5.2527e-07,\n",
      "         -3.8743e-07,  5.2154e-08],\n",
      "        ...,\n",
      "        [ 2.4959e-07, -1.8068e-07, -4.7730e-08,  ..., -1.8403e-06,\n",
      "          2.4680e-08,  4.7684e-07],\n",
      "        [ 5.8115e-07, -5.4570e-10, -1.4994e-07,  ..., -3.7951e-08,\n",
      "         -4.2096e-07,  4.7311e-07],\n",
      "        [ 2.5146e-08,  2.0489e-07, -3.3528e-08,  ...,  1.0431e-05,\n",
      "         -3.2485e-06,  1.2100e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor([[-4.1910e-07, -4.8894e-09,  3.8557e-07,  ..., -6.3330e-07,\n",
      "          1.2456e-08, -1.5944e-06],\n",
      "        [-1.3690e-07, -7.0781e-07, -3.1432e-08,  ...,  5.5432e-06,\n",
      "          6.1467e-07,  4.0531e-06],\n",
      "        [ 1.3504e-08, -1.3504e-08,  6.4727e-08,  ...,  6.2212e-07,\n",
      "         -1.2070e-06, -2.4447e-08],\n",
      "        ...,\n",
      "        [ 1.7323e-07, -1.3784e-07, -1.9092e-08,  ..., -1.4752e-06,\n",
      "          3.1898e-08,  3.6508e-07],\n",
      "        [ 5.8487e-07, -6.2937e-10,  7.9628e-08,  ..., -5.5134e-07,\n",
      "          1.9092e-07, -2.2724e-07],\n",
      "        [ 4.6799e-08,  2.4028e-07, -7.0781e-08,  ...,  1.0073e-05,\n",
      "          2.8312e-06, -2.9206e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [02:18<12:27, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.0291e-07,  7.6834e-09,  4.2142e-08,  ...,  1.6997e-08,\n",
      "          9.6392e-08, -9.7603e-07],\n",
      "        [-1.5181e-07, -8.4192e-07, -3.0501e-08,  ...,  6.0797e-06,\n",
      "          6.2212e-07,  2.4885e-06],\n",
      "        [-2.5611e-09, -3.0734e-08,  7.1712e-08,  ...,  9.9838e-07,\n",
      "         -1.0878e-06, -7.5903e-08],\n",
      "        ...,\n",
      "        [ 1.9372e-07,  3.7289e-10, -7.5903e-08,  ..., -1.5721e-06,\n",
      "          3.8883e-08,  5.2154e-07],\n",
      "        [ 7.4506e-07, -4.5475e-10,  3.4645e-07,  ..., -2.6822e-06,\n",
      "          4.6007e-07, -1.4305e-06],\n",
      "        [ 2.8871e-08,  2.9057e-07, -6.1002e-08,  ...,  1.4007e-05,\n",
      "          1.6689e-06,  4.0531e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [02:32<11:28, 16.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.9861e-07, -4.0454e-09,  4.7730e-08,  ..., -3.1106e-07,\n",
      "          1.4610e-08, -1.3337e-06],\n",
      "        [-8.1025e-08, -3.0920e-07, -4.1211e-08,  ...,  5.0068e-06,\n",
      "          4.8429e-07,  1.1399e-06],\n",
      "        [ 2.2002e-08, -3.0966e-08,  7.2177e-08,  ...,  9.6858e-07,\n",
      "         -8.8289e-07, -4.9360e-08],\n",
      "        ...,\n",
      "        [ 1.2107e-07,  2.6892e-08, -6.4727e-08,  ..., -1.7062e-06,\n",
      "          3.9348e-08,  4.1723e-07],\n",
      "        [ 7.2271e-07, -4.5111e-10,  3.0920e-07,  ..., -2.1160e-06,\n",
      "          6.2585e-07, -1.1474e-06],\n",
      "        [ 3.7719e-08,  2.2538e-07, -7.9162e-08,  ...,  1.2338e-05,\n",
      "          7.5251e-07,  3.7402e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [02:48<10:54, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.9302e-07, -1.2224e-08,  1.8440e-07,  ..., -1.8440e-07,\n",
      "         -7.5670e-09, -1.5125e-06],\n",
      "        [-8.8010e-08, -4.3958e-07, -3.7486e-08,  ...,  5.8115e-06,\n",
      "          4.7125e-07,  2.0415e-06],\n",
      "        [ 4.8894e-08, -3.4226e-08,  1.0012e-07,  ...,  1.5348e-06,\n",
      "         -1.1995e-06, -2.6659e-08],\n",
      "        ...,\n",
      "        [ 6.2864e-08,  6.0070e-08, -4.6799e-08,  ..., -1.8477e-06,\n",
      "          4.1677e-08,  4.0233e-07],\n",
      "        [ 6.8918e-07, -4.5111e-10,  3.8184e-07,  ..., -1.2293e-06,\n",
      "          4.9919e-07, -1.2890e-06],\n",
      "        [ 3.7719e-08,  1.5367e-07, -7.2177e-08,  ...,  1.1504e-05,\n",
      "         -2.1607e-07,  4.6194e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]]], device='cuda:0',\n",
      "       dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import wandb\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "mask = WeightMaskedTransformer(\n",
    "    model, \n",
    "    weight_mask_attn_dict=weight_mask_attn_dict, \n",
    "    weight_mask_mlp_dict=weight_mask_mlp_dict\n",
    ")\n",
    "for param in mask.tl_transformer.parameters():\n",
    "    param.requires_grad = False \n",
    "\n",
    "model_type = 'gemma'\n",
    "learning_rate = 1000\n",
    "n_epochs = 50\n",
    "grad_accum_steps = 5\n",
    "# max_gpu_batch_size=8\n",
    "alpha = 0.2\n",
    "beta = 1\n",
    "clip_grad = 1\n",
    "\n",
    "evaluate_every = 5\n",
    "n_eval_iters = 5\n",
    "do_adversarial_evals = False\n",
    "do_side_effects_evals = False \n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"mech-unlearning\",\n",
    "    name=f\"{model_name.split('/')[-1]}-{forget_sport}\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"model_type\": model_type,\n",
    "        \"model_name\": model_name,\n",
    "        \"forget_sport\": forget_sport,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"grad_accum_steps\": grad_accum_steps,\n",
    "        \"alpha\": alpha,\n",
    "        \"beta\": beta,\n",
    "        \"clip_grad\": clip_grad,\n",
    "        \"evaluate_every\": evaluate_every,\n",
    "        \"n_eval_iters\": n_eval_iters,\n",
    "        \"do_adversarial_evals\": do_adversarial_evals,\n",
    "        \"do_side_effects_evals\": do_side_effects_evals,\n",
    "    }\n",
    ")\n",
    "\n",
    "from collections import defaultdict\n",
    "all_train_losses = defaultdict(list)\n",
    "all_test_losses = defaultdict(list)\n",
    "adversarial_evals = []\n",
    "side_effect_evals = []\n",
    "\n",
    "# Initialize optimizer\n",
    "mask = mask.cuda()\n",
    "# mask_params = [\n",
    "#     v[-1]\n",
    "#     for layer, layer_mask_weights in mask.attention_masks.items()\n",
    "#     for k, v in layer_mask_weights.items()\n",
    "# ] + \\\n",
    "# [\n",
    "#     v\n",
    "#     for layer, layer_mask_weights in mask.mlp_masks.items()\n",
    "#     for k, v in layer_mask_weights.items()\n",
    "# ]\n",
    "optimizer = torch.optim.AdamW(mask.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=n_epochs)\n",
    "# Cycle dataloaders\n",
    "# Train a sparse mask\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    # Sample batches\n",
    "    # Reset grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.autocast(device_type=\"cuda\"):\n",
    "        # Compute normal loss over retain\n",
    "        for task_name, (task, task_weight) in train_tasks.items():\n",
    "            task_loss = 0\n",
    "            # print(task_name)\n",
    "            for i in range(grad_accum_steps):\n",
    "                loss = task.get_train_loss(mask) / grad_accum_steps\n",
    "                task_loss += loss.item()\n",
    "                loss *= task_weight\n",
    "                loss.backward()\n",
    "\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            all_train_losses[task_name].append(task_loss)\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # Add sparsity loss and backprop\n",
    "        loss = beta * mask.regularization_loss()\n",
    "        loss.backward()\n",
    "        all_train_losses[\"reg\"].append(loss.item())\n",
    "        # Step and log\n",
    "        if clip_grad is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(mask.parameters(), clip_grad)\n",
    "        # zero_nan_grads(mask)\n",
    "        optimizer.step()\n",
    "        mask.on_step_end()\n",
    "        scheduler.step()\n",
    "\n",
    "        print(mask.attention_masks[3]['W_Q'][-1].grad[4])\n",
    "        print(mask.attention_masks[3]['W_Q'][-1])\n",
    "        print((mask.attention_masks[3]['W_Q'][-1] - 1).sum())\n",
    "\n",
    "        if epoch % evaluate_every == 0 or epoch == n_epochs - 1:\n",
    "            for task_name, task in eval_tasks.items():\n",
    "                task_loss = 0\n",
    "                for i in range(n_eval_iters):\n",
    "                    task_loss += task.get_test_loss(mask).item()\n",
    "                all_test_losses[task_name].append(task_loss / n_eval_iters)\n",
    "            if do_adversarial_evals:\n",
    "                print(\"Running adversarial evals\")\n",
    "                adversarial_evals.append(adversarial_sports_eval(mask, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=True))\n",
    "            if do_side_effects_evals:\n",
    "                print(\"Running side effects evals\")\n",
    "                side_effect_evals.append(run_side_effects_evals(mask, model_type=model_type, batch_size=eval_batch_size, evals_to_run=[\"Sports Answers\"]))\n",
    "        \n",
    "        # log_dict = {}\n",
    "        # for k, v in all_train_losses.items():\n",
    "        #     log_dict[f\"train_loss_{k}\"] = v[-1]\n",
    "        # for k, v in all_test_losses.items():\n",
    "        #     log_dict[f\"test_loss_{k}\"] = v[-1]\n",
    "        # for k, v in adversarial_evals[-1].items():\n",
    "        #     log_dict[f\"adversarial_{k}\"] = v\n",
    "        # for k, v in side_effect_evals[-1].items():\n",
    "        #     log_dict[f\"side_effects_{k}\"] = v\n",
    "        # wandb.log(log_dict)\n",
    "    \n",
    "wandb.finish()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/mechanistic-unlearning/weight_masked_transformer.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Final evals\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m final_adversarial_eval \u001b[39m=\u001b[39m adversarial_sports_eval(model, model_type\u001b[39m=\u001b[39;49mmodel_type, batch_size\u001b[39m=\u001b[39;49meval_batch_size, use_system_prompt\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSystem Prompt: adversarial evals are \u001b[39m\u001b[39m{\u001b[39;00mfinal_adversarial_eval\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m final_adversarial_eval \u001b[39m=\u001b[39m adversarial_sports_eval(model, model_type\u001b[39m=\u001b[39mmodel_type, batch_size\u001b[39m=\u001b[39meval_batch_size, use_system_prompt\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/facts/SportsTaskAdversarial.py:400\u001b[0m, in \u001b[0;36madversarial_sports_eval\u001b[0;34m(model, model_type, batch_size, n_iters, continuous, test_each_sport, include_evals, use_icl, use_system_prompt)\u001b[0m\n\u001b[1;32m    398\u001b[0m     update_accuracies(\u001b[39m\"\u001b[39m\u001b[39mCapitalized\u001b[39m\u001b[39m\"\u001b[39m, SportsTask_Capitalized)\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mDashed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m include_evals:\n\u001b[0;32m--> 400\u001b[0m     update_accuracies(\u001b[39m\"\u001b[39;49m\u001b[39mDashed\u001b[39;49m\u001b[39m\"\u001b[39;49m, SportsTask_Dashed)\n\u001b[1;32m    402\u001b[0m \u001b[39mreturn\u001b[39;00m accuracies\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/facts/SportsTaskAdversarial.py:386\u001b[0m, in \u001b[0;36madversarial_sports_eval.<locals>.update_accuracies\u001b[0;34m(eval_type, eval_constructor)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m                 temp_task \u001b[39m=\u001b[39m eval_constructor(batch_size\u001b[39m=\u001b[39mbatch_size, tokenizer\u001b[39m=\u001b[39mtokenizer, is_forget_dataset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, forget_sport_subset\u001b[39m=\u001b[39m{sport})\n\u001b[0;32m--> 386\u001b[0m             accuracies[eval_type][sport] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m temp_task\u001b[39m.\u001b[39;49mget_test_accuracy(model, continuous\u001b[39m=\u001b[39;49mcontinuous) \u001b[39m/\u001b[39m n_iters\n\u001b[1;32m    387\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     temp_task \u001b[39m=\u001b[39m eval_constructor(batch_size\u001b[39m=\u001b[39mbatch_size, tokenizer\u001b[39m=\u001b[39mtokenizer, use_icl\u001b[39m=\u001b[39muse_icl, use_system_prompt\u001b[39m=\u001b[39muse_system_prompt)\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/facts/SportsTaskAdversarial.py:315\u001b[0m, in \u001b[0;36mSportsTask_Dashed.get_test_accuracy\u001b[0;34m(self, model, use_test_data, continuous)\u001b[0m\n\u001b[1;32m    312\u001b[0m new_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(completed_prompts[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39minput_ids) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(prompts[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39minput_ids)\n\u001b[1;32m    313\u001b[0m \u001b[39m# print(new_len)\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m sports_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(completed_prompts[\u001b[39m0\u001b[39;49m], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49minput_ids[\u001b[39m0\u001b[39;49m, \u001b[39m-\u001b[39;49mnew_len:]\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m    316\u001b[0m \u001b[39m# print(f\"{sports_tokens=}\")\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m \u001b[39m# cross entropy on new_len_tokens\u001b[39;00m\n\u001b[1;32m    319\u001b[0m last_logits \u001b[39m=\u001b[39m get_final_logits(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, completed_prompts, len_final_logits\u001b[39m=\u001b[39mnew_len\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Final evals\n",
    "final_adversarial_eval = adversarial_sports_eval(model, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=True)\n",
    "print(f\"System Prompt: adversarial evals are {final_adversarial_eval}\")\n",
    "final_adversarial_eval = adversarial_sports_eval(model, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=False)\n",
    "print(f\"No System Prompt: adversarial evals are {final_adversarial_eval}\")\n",
    "\n",
    "final_side_effects = run_side_effects_evals(model, model_type=model_type, batch_size=eval_batch_size, evals_to_run=[\"Sports Answers\", \"Sports Familiarity\", \"Cross Entropy\"], verbose=True)\n",
    "print(final_side_effects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W_in': False, 'W_out': True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_mask_mlp_dict[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mask.mlp_masks[5]['W_out'] - 1).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save masks state dict to neuron_cb\n",
    "torch.save(mask.state_dict(), \"masks/neuron_cb/mlps_unlearn_basketball.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
