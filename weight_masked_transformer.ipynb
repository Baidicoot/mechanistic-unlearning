{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "import pickle\n",
    "\n",
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPTNeoXTokenizerFast, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset('monology/pile-uncopyrighted', split='train', streaming=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_TOKEN'] = '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'\n",
    "model_name = 'google/gemma-2b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    device='cuda',\n",
    "    default_padding_side=\"right\",\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    center_writing_weights=False,\n",
    "    dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key not found, will not be able to run evaluations on Sports Trivia Task\n"
     ]
    }
   ],
   "source": [
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "from tasks.facts.SportsTaskAdversarial import adversarial_sports_eval\n",
    "from tasks.facts.SportsTaskSideEffects import run_side_effects_evals\n",
    "\n",
    "\n",
    "train_batch_size = 10\n",
    "eval_batch_size = 50\n",
    "\n",
    "device = \"cuda\"\n",
    "train_loss_type = \"sports\"\n",
    "forget_sport = \"basketball\"\n",
    "maintain_sport = None\n",
    "# val_sport = \"baseball\"\n",
    "\n",
    "\n",
    "sports_1mp = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"log_1_minus_p\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "\n",
    "if maintain_sport is None:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "else:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "\n",
    "train_pile = PileTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "train_tasks = {\"sports_1mp\": (sports_1mp, .2), \"maintain_sports\": (maintain_sports, 1), \"pile\": (train_pile, 1)}\n",
    "\n",
    "# want to eval on other sports\n",
    "forget_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "test_pile = PileTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "\n",
    "induction_eval = InductionTask(batch_size=eval_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, device=device)\n",
    "if maintain_sport is None:\n",
    "    maintain_sports_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sports_eval}\n",
    "else:\n",
    "    maintain_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "    val_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={val_sport}, is_forget_dataset=True)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sport_eval, \"val_sport\": val_sport_eval}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "def create_random_weight_mask_dicts(model):\n",
    "    # Creates random weight masks for testing\n",
    "    weight_mask_attn_dict = {}\n",
    "    weight_mask_mlp_dict = {}\n",
    "\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        weight_mask_attn_dict[layer] = {}\n",
    "        # Want bool of length n_head, randomly set to True\n",
    "        weight_mask_attn_dict[layer]['W_Q'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "        weight_mask_attn_dict[layer]['W_K'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "        weight_mask_attn_dict[layer]['W_V'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "        weight_mask_attn_dict[layer]['W_O'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "\n",
    "        # Randomly set to true or false\n",
    "        weight_mask_mlp_dict[layer] = random.randint(0, 1) == 1\n",
    "\n",
    "    return weight_mask_attn_dict, weight_mask_mlp_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Masking Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def make_partly_differentiable_mask(W, frozen_heads, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    W is Parameter of shape (n_heads, ...). \n",
    "    Returns baseline and frozen (both only 1d arrays of (n_heads,)), \n",
    "    and forward pass should be W_frozen.float() + W_baseline.float() * W \n",
    "    \"\"\"\n",
    "    W_frozen = torch.nn.Parameter(torch.zeros(W.shape[0], dtype=torch.bool), requires_grad=False).to(device)\n",
    "\n",
    "    # unsqueeze to broadcast efficiently, until W_baseline has same shape as W\n",
    "    while len(W_frozen.shape) < len(W.shape):\n",
    "        W_frozen = W_frozen.unsqueeze(-1)\n",
    "    \n",
    "    W_frozen[frozen_heads] = True\n",
    "\n",
    "    W_baseline = (~W_frozen).float()\n",
    "    W_baseline = torch.nn.Parameter(W_baseline, requires_grad=True)\n",
    "    # convert into float\n",
    "    return W_frozen.float(), W_baseline.float()\n",
    "\n",
    "class WeightMaskedTransformer(nn.Module):\n",
    "    def __init__(self, tl_transformer, weight_mask_attn_dict=None, weight_mask_mlp_dict=None, torch_dtype=torch.bfloat16):\n",
    "        \"\"\"\n",
    "        weight_mask_attn_dict: {layer: {\"W_Q\": unfrozen_heads, \"W_K\": unfrozen_heads, \"W_V\": unfrozen_heads, \"W_O\": unfrozen_heads}} (frozen_heads is shape (n_heads,) of bools). If none, train mask over all heads\n",
    "        weight_mask_mlp_dict: {layer: bool}. If none, train mask over all mlps\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.torch_dtype = torch_dtype\n",
    "        # tl_transformer should be a HookedTransformer\n",
    "        self.tl_transformer = tl_transformer\n",
    "        # turn off gradients for tl_transformer\n",
    "        # for param in self.tl_transformer.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.weight_mask_attn_dict = weight_mask_attn_dict\n",
    "        self.weight_mask_mlp_dict = weight_mask_mlp_dict\n",
    "        # store weight masks for every component that is unfrozen\n",
    "        \n",
    "        # need to store reference weights so that you can reset W_Q, etc after a forward pass\n",
    "        self.reference_attn_weights = {}\n",
    "        self.reference_mlp_weights = {}\n",
    "\n",
    "        self.attention_masks = {}\n",
    "        self.mlp_masks = {}\n",
    "        for layer in range(tl_transformer.cfg.n_layers):\n",
    "            self.attention_masks[layer] = {}\n",
    "            self.reference_attn_weights[layer] = {}\n",
    "            self.mlp_masks[layer] = {}\n",
    "            self.reference_mlp_weights[layer] = {}\n",
    "            # Attention heads\n",
    "            for component, parameter in [(\"W_Q\", tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", tl_transformer.blocks[layer].attn.W_K), (\"W_V\", tl_transformer.blocks[layer].attn.W_V), (\"W_O\", tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None:\n",
    "                    unfrozen_heads = list(range(tl_transformer.cfg.n_heads)) # all heads are unfrozen\n",
    "                else:\n",
    "                    unfrozen_heads = self.weight_mask_attn_dict[layer][component]\n",
    "                # make frozen and baseline masks, and also a copy of the original weights\n",
    "\n",
    "                if unfrozen_heads is not None and len(unfrozen_heads) > 0:\n",
    "                    W_frozen, W_baseline = make_partly_differentiable_mask(parameter, unfrozen_heads)\n",
    "                    weight_mask = nn.Parameter(torch.ones_like(parameter).type(torch_dtype), requires_grad=True)\n",
    "                    \n",
    "                    self.attention_masks[layer][component] = (W_frozen, W_baseline, weight_mask)\n",
    "                    self.reference_attn_weights[layer][component] = parameter.clone()\n",
    "\n",
    "            # MLPs\n",
    "\n",
    "            for component, parameter in [(\"W_in\", tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = nn.Parameter(torch.ones_like(parameter).type(torch_dtype), requires_grad=True)\n",
    "\n",
    "                    self.mlp_masks[layer][component] = weight_mask\n",
    "                    self.reference_mlp_weights[layer][component] = parameter.clone()\n",
    "\n",
    "                \n",
    "    def forward(self, *args, **kwargs):\n",
    "        for layer in range(self.tl_transformer.cfg.n_layers):\n",
    "            for component, parameter in [(\"W_Q\", self.tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", self.tl_transformer.blocks[layer].attn.W_K), (\"W_V\", self.tl_transformer.blocks[layer].attn.W_V), (\"W_O\", self.tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None or component in self.attention_masks[layer]:\n",
    "                    W_frozen, W_baseline, weight_mask = self.attention_masks[layer][component]\n",
    "                    reference_data = self.reference_attn_weights[layer][component]\n",
    "                    mask = W_frozen + W_baseline * weight_mask\n",
    "                    self.tl_transformer.blocks[layer].attn.__dict__['_parameters'][component] = reference_data * mask\n",
    "\n",
    "            for component, parameter in [(\"W_in\", self.tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", self.tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = self.mlp_masks[layer][component]\n",
    "                    reference_data = self.reference_mlp_weights[layer][component]\n",
    "                    self.tl_transformer.blocks[layer].mlp.__dict__['_parameters'][component] = reference_data * weight_mask\n",
    "\n",
    "        return self.tl_transformer(*args, **kwargs)\n",
    "\n",
    "    def generate(self, *args, **kwargs):\n",
    "        return self.tl_transformer.generate(*args, **kwargs)\n",
    "\n",
    "    def regularization_loss(self):\n",
    "        # Compute the L1 sparsity penalty using the masks\n",
    "        loss = 0\n",
    "        for layer in range(self.tl_transformer.cfg.n_layers):\n",
    "            num_comps = 0\n",
    "            comp_loss = 0\n",
    "            for component, parameter in [(\"W_Q\", self.tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", self.tl_transformer.blocks[layer].attn.W_K), (\"W_V\", self.tl_transformer.blocks[layer].attn.W_V), (\"W_O\", self.tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                num_comps += 1\n",
    "                if self.weight_mask_attn_dict is None or component in self.attention_masks[layer]:\n",
    "                    W_frozen, W_baseline, weight_mask = self.attention_masks[layer][component]\n",
    "                    mask = W_frozen + (W_baseline * weight_mask) # 1s for frozen, heads\n",
    "                    # Add (weights away from 1) / (total weights * percent_masks_active)\n",
    "                    comp_loss += torch.sum(torch.abs(mask - 1)) / (mask.numel() * (W_baseline.sum() / W_baseline.numel()) + 1e-5)\n",
    "                    \n",
    "            loss += comp_loss / (num_comps + 1e-5)\n",
    "\n",
    "            for component, parameter in [(\"W_in\", self.tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", self.tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                num_comps = 0\n",
    "                comp_loss = 0\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = self.mlp_masks[layer][component]\n",
    "                    comp_loss += torch.sum(torch.abs(weight_mask - 1)) / weight_mask.numel()\n",
    "\n",
    "            loss += comp_loss / (num_comps + 1e-5)\n",
    "        loss /= self.tl_transformer.cfg.n_layers\n",
    "        return loss\n",
    "    \n",
    "    def on_step_end(self):\n",
    "        # Clip all the masks\n",
    "\n",
    "        for layer in range(self.tl_transformer.cfg.n_layers):\n",
    "            for component, parameter in [(\"W_Q\", self.tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", self.tl_transformer.blocks[layer].attn.W_K), (\"W_V\", self.tl_transformer.blocks[layer].attn.W_V), (\"W_O\", self.tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None or component in self.attention_masks[layer]:\n",
    "                    W_frozen, W_baseline, weight_mask = self.attention_masks[layer][component]\n",
    "                    weight_mask.data = torch.clamp(weight_mask.data, 0, 1)\n",
    "\n",
    "            for component, parameter in [(\"W_in\", self.tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", self.tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = self.mlp_masks[layer][component]\n",
    "                    weight_mask.data = torch.clamp(weight_mask.data, 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Weight Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_mask_from_ap_graph(model, ap_graph, threshold):\n",
    "    # Attention masks are of form:\n",
    "    # {layer: {\"W_Q\": frozen_heads, \"W_K\": frozen_heads, \"W_V\": frozen_heads, \"W_O\": frozen_heads}}\n",
    "    # TRUE for the heads we want to FREEZE, FALSE for heads we want to MASK over\n",
    "    # MLP masks are of form:\n",
    "    # {layer: bool}\n",
    "\n",
    "    # Localizations are of form:\n",
    "    # {alayer.head_{q,k,v,result}:int, mlayer_{in,out}: int}\n",
    "\n",
    "    weight_mask_attn_dict = {}\n",
    "    weight_mask_mlp_dict = {}\n",
    "\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        weight_mask_attn_dict[layer] = {}\n",
    "        weight_mask_mlp_dict[layer] = {}\n",
    "\n",
    "        if 'a0.0_q' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_Q'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_q\"]) < threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_Q'] = None\n",
    "\n",
    "        if 'a0.0_k' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_K'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_k\"]) < threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_K'] = None\n",
    "        \n",
    "        if 'a0.0_v' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_V'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_v\"]) < threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_V'] = None\n",
    "        \n",
    "        if 'a0.0_result' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_O'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_result\"]) < threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_O'] = None\n",
    "            \n",
    "        if 'm0_in' in ap_graph:\n",
    "            weight_mask_mlp_dict[layer]['W_in'] = abs(ap_graph[f\"m{layer}_in\"]) < threshold\n",
    "        else:\n",
    "            weight_mask_mlp_dict[layer]['W_in'] = None\n",
    "        \n",
    "        if 'm0_out' in ap_graph:\n",
    "            weight_mask_mlp_dict[layer]['W_out'] = abs(ap_graph[f\"m{layer}_out\"]) < threshold\n",
    "        else:\n",
    "            weight_mask_mlp_dict[layer]['W_out'] = None\n",
    "\n",
    "    return weight_mask_attn_dict, weight_mask_mlp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"models/google_gemma-2b_sports_baseball_ap_graph.pkl\", \"rb\") as f:\n",
    "    ap_graph = pickle.load(f)\n",
    "\n",
    "weight_mask_attn_dict, weight_mask_mlp_dict = get_mask_from_ap_graph(model, ap_graph, 0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask = WeightMaskedTransformer(\n",
    "    model, \n",
    "    weight_mask_attn_dict=weight_mask_attn_dict, \n",
    "    weight_mask_mlp_dict=weight_mask_mlp_dict\n",
    ")\n",
    "# for n, param in mask.tl_transformer.named_parameters():\n",
    "#     param.requires_grad = False\n",
    "sports_train = SportsTask(batch_size=8, tokenizer=tokenizer)\n",
    "with torch.autocast(device_type=\"cuda\"):\n",
    "    loss = sports_train.get_train_loss(mask, 1)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "\n",
    "print(mask.attention_masks[3]['W_Q'][-1].grad[-2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight_mask_attn_dict[3]['W_Q']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(mask.attention_masks[3]['W_Q'][-1][-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports_1mp 0 tensor(0.0785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.6144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.8628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.6389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "reg loss, 0.0\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 0.9883, 1.0000, 0.9883],\n",
      "         [0.9883, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9883,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 0.9883, 0.9883, 0.9883],\n",
      "         [1.0000, 1.0000, 0.9883,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [0.9883, 0.9883, 1.0000,  ..., 1.0000, 1.0000, 0.9883]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-2842.4023, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:39: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
      "  grads = [p.grad for p in parameters if p.grad is not None]\n",
      "  2%|▏         | 1/50 [00:45<37:01, 45.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports_1mp 0 tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(5.4588e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.6012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.4730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.6294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.4648, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [01:00<22:12, 27.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 733.4661865234375\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 0.9961, 1.0000,  ..., 0.9922, 1.0000, 0.9766],\n",
      "         [0.9805, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 1.0000, 0.9805,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 0.9961, 1.0000,  ..., 0.9766, 0.9805, 0.9922],\n",
      "         [1.0000, 1.0000, 0.9805,  ..., 0.9961, 1.0000, 0.9961],\n",
      "         [0.9805, 0.9805, 0.9922,  ..., 1.0000, 0.9922, 0.9805]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-4042.3281, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.3690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.3229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.3499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.5884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.2093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.4430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.6926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.4651, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:16<17:33, 22.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 231.63998413085938\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9961,  ..., 1.0000, 1.0000, 0.9805],\n",
      "         [0.9883, 0.9961, 1.0000,  ..., 0.9961, 1.0000, 0.9961],\n",
      "         [0.9961, 1.0000, 0.9727,  ..., 0.9961, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 0.9805, 0.9844, 0.9844],\n",
      "         [0.9922, 1.0000, 0.9805,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [0.9727, 0.9727, 0.9961,  ..., 0.9961, 0.9844, 0.9727]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-5082.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(4.9812e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(6.5506e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.3337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.2574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.2838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.2405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.4817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.4560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.6626, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [01:32<15:09, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 145.40545654296875\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9883,  ..., 1.0000, 1.0000, 0.9844],\n",
      "         [0.9922, 0.9883, 0.9961,  ..., 0.9922, 1.0000, 1.0000],\n",
      "         [0.9961, 1.0000, 0.9648,  ..., 0.9922, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 0.9883, 0.9922, 0.9766],\n",
      "         [0.9844, 1.0000, 0.9844,  ..., 1.0000, 1.0000, 0.9844],\n",
      "         [0.9688, 0.9648, 0.9922,  ..., 0.9922, 0.9766, 0.9648]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-5932.3789, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.1357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.4344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.6432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.4758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5061, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [01:48<13:39, 18.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 56.23258972167969\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9844,  ..., 1.0000, 1.0000, 0.9883],\n",
      "         [0.9961, 0.9844, 0.9922,  ..., 0.9883, 0.9961, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9570,  ..., 0.9883, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 0.9922, 0.9961, 0.9727],\n",
      "         [0.9805, 1.0000, 0.9883,  ..., 1.0000, 1.0000, 0.9766],\n",
      "         [0.9648, 0.9609, 0.9961,  ..., 0.9883, 0.9766, 0.9570]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-6708.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.1321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.4850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.4576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.4530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "reg loss, 3.8846137523651123\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9805,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9805, 0.9922,  ..., 0.9883, 0.9922, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9492,  ..., 0.9844, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 0.9961, 1.0000, 0.9688],\n",
      "         [0.9766, 1.0000, 0.9922,  ..., 1.0000, 1.0000, 0.9688],\n",
      "         [0.9609, 0.9570, 0.9961,  ..., 0.9844, 0.9805, 0.9492]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-7380.3750, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [02:12<14:52, 20.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports_1mp 0 tensor(0.0050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.4836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.4927, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [02:26<13:12, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 1.6040902137756348\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9766, 0.9922,  ..., 0.9883, 0.9883, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9453,  ..., 0.9805, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 0.9961, 1.0000, 0.9648],\n",
      "         [0.9727, 1.0000, 0.9961,  ..., 1.0000, 1.0000, 0.9648],\n",
      "         [0.9570, 0.9531, 0.9961,  ..., 0.9805, 0.9805, 0.9414]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-7975.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.1293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.4762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.4647, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [02:41<12:07, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.9762862324714661\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9727, 0.9922,  ..., 0.9883, 0.9844, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9414,  ..., 0.9766, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9609],\n",
      "         [0.9688, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9609],\n",
      "         [0.9531, 0.9492, 0.9961,  ..., 0.9766, 0.9805, 0.9336]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-8475.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0023, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.4144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.6302, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [02:56<11:20, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 1.0797438621520996\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9688, 0.9922,  ..., 0.9883, 0.9805, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9375,  ..., 0.9727, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9570],\n",
      "         [0.9648, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9570],\n",
      "         [0.9492, 0.9453, 0.9961,  ..., 0.9727, 0.9805, 0.9297]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-8899.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.4901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5017, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [03:12<10:46, 16.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 1.110162615776062\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9648, 0.9922,  ..., 0.9883, 0.9766, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9336,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9531],\n",
      "         [0.9609, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9531],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9688, 0.9805, 0.9258]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-9241.8555, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.3971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "reg loss, 0.7179844975471497\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9648, 0.9922,  ..., 0.9883, 0.9727, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9297,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9570, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9219]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-9504.7773, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [03:35<11:59, 18.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports_1mp 0 tensor(0.0027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.6888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.4964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5242, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [03:50<10:58, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.623717725276947\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9258,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9531, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9453],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9180]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-9700.8320, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.4847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5697, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [04:05<10:20, 16.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.907457709312439\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9219,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9492, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9414],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9141]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-9869.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.4682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.4480, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [04:21<09:48, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.9260094165802002\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9453, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9375],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9102]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-9988.1211, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.4441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.6108, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [04:36<09:19, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.3498506546020508\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9336],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9062]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10063.9453, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.4944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "reg loss, 0.3416546583175659\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9297],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10106.2852, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [04:59<10:19, 18.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports_1mp 0 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.4643, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.4037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.6077, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [05:15<09:32, 17.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.2823394536972046\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9258],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10126.6484, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(8.7784e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.4780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.4659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.4309, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [05:30<08:53, 16.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.26312255859375\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9219],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10132.2852, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(5.7915e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.4806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5137, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [05:45<08:26, 16.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.24122649431228638\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9180],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10129.8789, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(7.5264e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.3541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5194, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [06:01<08:01, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.24113348126411438\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9141],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10123.9102, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.5091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.4927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.4818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.4950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "reg loss, 0.21915383636951447\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9102],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10117.1367, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [06:25<08:53, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports_1mp 0 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.4899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5279, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [06:40<08:10, 17.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.16584241390228271\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9062],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10110.9180, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(6.0623e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.6082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.4362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.5902, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [06:56<07:38, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.1700633466243744\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9062],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10105.4727, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(6.2134e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 0 tensor(0.4935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.4216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.5327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.4854, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [07:12<07:11, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.14029797911643982\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9062],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10101.3672, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(4.3343e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 0 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 1 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 2 tensor(0.0003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 3 tensor(0.0004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "maintain_sports 4 tensor(0.0005, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f6f0bf82d10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pile 0 tensor(0.5506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 1 tensor(0.5193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 2 tensor(0.4957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 3 tensor(0.4963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "pile 4 tensor(0.4419, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [07:27<06:45, 16.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg loss, 0.10515937209129333\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Parameter containing:\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 0.9766,  ..., 1.0000, 1.0000, 0.9922],\n",
      "         [1.0000, 0.9609, 0.9922,  ..., 0.9883, 0.9688, 1.0000],\n",
      "         [1.0000, 1.0000, 0.9180,  ..., 0.9688, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9492],\n",
      "         [0.9414, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.9062],\n",
      "         [0.9453, 0.9453, 0.9961,  ..., 0.9648, 0.9805, 0.9023]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n",
      "tensor(-10098.2344, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "sports_1mp 0 tensor(7.4722e-05, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 1 tensor(0.0008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 2 tensor(0.0002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 3 tensor(0.0001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "sports_1mp 4 tensor(3.2822e-05, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import wandb\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "mask = WeightMaskedTransformer(\n",
    "    model, \n",
    "    weight_mask_attn_dict=weight_mask_attn_dict, \n",
    "    weight_mask_mlp_dict=weight_mask_mlp_dict\n",
    ")\n",
    "for param in mask.tl_transformer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_type = 'gemma'\n",
    "learning_rate = 1e-2\n",
    "n_epochs = 50\n",
    "grad_accum_steps = 5\n",
    "# max_gpu_batch_size=8\n",
    "alpha = 0.2\n",
    "beta = 1/100\n",
    "clip_grad = 1\n",
    "\n",
    "evaluate_every = 5\n",
    "n_eval_iters = 5\n",
    "do_adversarial_evals = False \n",
    "do_side_effects_evals = False\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"mech-unlearning\",\n",
    "    name=f\"{model_name.split('/')[-1]}-{forget_sport}\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"model_type\": model_type,\n",
    "        \"model_name\": model_name,\n",
    "        \"forget_sport\": forget_sport,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"grad_accum_steps\": grad_accum_steps,\n",
    "        \"alpha\": alpha,\n",
    "        \"beta\": beta,\n",
    "        \"clip_grad\": clip_grad,\n",
    "        \"evaluate_every\": evaluate_every,\n",
    "        \"n_eval_iters\": n_eval_iters,\n",
    "        \"do_adversarial_evals\": do_adversarial_evals,\n",
    "        \"do_side_effects_evals\": do_side_effects_evals,\n",
    "        \"train_task_weights\": {k:v[1] for k, v in train_tasks.items()}\n",
    "    }\n",
    ")\n",
    "\n",
    "from collections import defaultdict\n",
    "all_train_losses = defaultdict(list)\n",
    "all_test_losses = defaultdict(list)\n",
    "adversarial_evals = []\n",
    "side_effect_evals = []\n",
    "\n",
    "# Initialize optimizer\n",
    "mask = mask.cuda()\n",
    "mask_params = [\n",
    "    v[-1]\n",
    "    for layer, layer_mask_weights in mask.attention_masks.items()\n",
    "    for k, v in layer_mask_weights.items()\n",
    "] + \\\n",
    "[\n",
    "    v\n",
    "    for layer, layer_mask_weights in mask.mlp_masks.items()\n",
    "    for k, v in layer_mask_weights.items()\n",
    "]\n",
    "optimizer = torch.optim.AdamW(mask_params, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=n_epochs)\n",
    "# Cycle dataloaders\n",
    "# Train a sparse mask\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    # Sample batches\n",
    "    # Reset grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.autocast(device_type=\"cuda\"):\n",
    "        # Compute normal loss over retain\n",
    "        for task_name, (task, task_weight) in train_tasks.items():\n",
    "            task_loss = 0\n",
    "            for i in range(grad_accum_steps):\n",
    "                loss = task.get_train_loss(mask) / grad_accum_steps\n",
    "                task_loss += loss.item()\n",
    "                loss *= task_weight\n",
    "                # print(task_name, i, loss)\n",
    "                loss.backward()\n",
    "\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            all_train_losses[task_name].append(task_loss)\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # Add sparsity loss and backprop\n",
    "        loss = min(epoch-10, beta) * mask.regularization_loss()\n",
    "        loss.backward()\n",
    "        # print(f\"reg loss, {loss.item()}\")\n",
    "        all_train_losses[\"reg\"].append(loss.item())\n",
    "        # Step and log\n",
    "        if clip_grad is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(mask.parameters(), clip_grad)\n",
    "        # zero_nan_grads(mask)\n",
    "        optimizer.step()\n",
    "        mask.on_step_end()\n",
    "        scheduler.step()\n",
    "\n",
    "        # print(mask.attention_masks[3]['W_Q'][-1].grad[4])\n",
    "        # print(mask.attention_masks[3]['W_Q'][-1])\n",
    "        # print((mask.attention_masks[3]['W_Q'][-1] - 1).sum())\n",
    "\n",
    "        if epoch % evaluate_every == 0 or epoch == n_epochs - 1:\n",
    "            for task_name, task in eval_tasks.items():\n",
    "                task_loss = 0\n",
    "                for i in range(n_eval_iters):\n",
    "                    task_loss += task.get_test_loss(mask).item()\n",
    "                all_test_losses[task_name].append(task_loss / n_eval_iters)\n",
    "            if do_adversarial_evals:\n",
    "                print(\"Running adversarial evals\")\n",
    "                adversarial_evals.append(adversarial_sports_eval(mask, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=True))\n",
    "            if do_side_effects_evals:\n",
    "                print(\"Running side effects evals\")\n",
    "                side_effect_evals.append(run_side_effects_evals(mask, model_type=model_type, batch_size=eval_batch_size, evals_to_run=[\"Sports Answers\"]))\n",
    "        \n",
    "        log_dict = {\n",
    "            \"debug_mask_sum\": float((mask.attention_masks[3]['W_Q'][-1] - 1).sum())\n",
    "        }\n",
    "        for k, v in all_train_losses.items():\n",
    "            log_dict[f\"train_loss_{k}\"] = v[-1]\n",
    "        for k, v in all_test_losses.items():\n",
    "            log_dict[f\"test_loss_{k}\"] = v[-1]\n",
    "        for k, v in adversarial_evals[-1].items():\n",
    "            log_dict[f\"adversarial_{k}\"] = v\n",
    "        for k, v in side_effect_evals[-1].items():\n",
    "            log_dict[f\"side_effects_{k}\"] = v\n",
    "        wandb.log(log_dict)\n",
    "    \n",
    "wandb.finish()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'W_Q': tensor([ True, False,  True,  True,  True,  True,  True,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False,  True,  True,  True,  True,  True,  True,  True])},\n",
       " 1: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True, False,  True,  True,  True,  True,  True])},\n",
       " 2: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True, False,  True,  True,  True,  True,  True,  True])},\n",
       " 3: {'W_Q': tensor([ True,  True,  True,  True,  True,  True, False,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True,  True,  True,  True, False,  True])},\n",
       " 4: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])},\n",
       " 5: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])},\n",
       " 6: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True, False,  True, False,  True,  True])},\n",
       " 7: {'W_Q': tensor([ True, False,  True, False,  True,  True,  True,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True,  True,  True, False,  True,  True])},\n",
       " 8: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])},\n",
       " 9: {'W_Q': tensor([ True,  True,  True,  True, False,  True,  True,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True, False, False, False,  True,  True,  True])},\n",
       " 10: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True,  True,  True, False,  True,  True])},\n",
       " 11: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False,  True,  True,  True,  True,  True, False, False])},\n",
       " 12: {'W_Q': tensor([ True,  True, False,  True,  True,  True,  True,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False, False, False, False, False, False,  True,  True])},\n",
       " 13: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False, False,  True, False, False,  True,  True,  True])},\n",
       " 14: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False,  True,  True,  True,  True, False,  True,  True])},\n",
       " 15: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])},\n",
       " 16: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True,  True, False,  True,  True,  True])},\n",
       " 17: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.weight_mask_attn_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = torch.cat(\n",
    "    [\n",
    "        mask.flatten() \n",
    "        for m in mask.masks.values()\n",
    "\n",
    "        if component in mask.attention_masks[layer]\n",
    "        for component in [\"W_Q\", \"W_K\", \"W_V\", \"W_O\"]\n",
    "        for layer in range(mask.tl_transformer.cfg.n_layers)\n",
    "    ], \n",
    "    dim=0\n",
    ").cpu()\n",
    "sorted_values = all_values.sort().values\n",
    "plt.semilogx(sorted_values)\n",
    "plt.title(f\"{title} Neuron Mask Values\")\n",
    "plt.ylabel(\"Mask Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fbca8112d10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Create a histogram of mask values if W_baseline is 1\n",
    "\n",
    "hist = []\n",
    "for layer in range(mask.tl_transformer.cfg.n_layers):\n",
    "    for component in [\"W_Q\", \"W_K\", \"W_V\", \"W_O\"]:\n",
    "        if component in mask.attention_masks[layer]:\n",
    "            frozen, baseline, mask_values = mask.attention_masks[layer][component]\n",
    "            for i in range(baseline.shape[0]):\n",
    "                if baseline[i] == 1:\n",
    "                    hist.append(mask_values[i].flatten())\n",
    "\n",
    "hist = torch.cat(hist, dim=0).cpu()\n",
    "\n",
    "sorted_values = hist.sort().values\n",
    "plt.semilogx(sorted_values)\n",
    "plt.title(f\"Mask Values\")\n",
    "plt.ylabel(\"Mask Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.2212e-07,  7.0035e-07, -7.9349e-07,  ...,  7.8082e-06,\n",
      "          7.7859e-07,  4.3958e-07],\n",
      "        [-1.7658e-06,  2.6822e-07, -9.7603e-07,  ..., -7.6890e-06,\n",
      "          4.7684e-06,  6.2287e-06],\n",
      "        [-6.3330e-08, -1.3690e-07,  1.2368e-06,  ...,  1.2740e-06,\n",
      "          1.2890e-06,  9.3877e-07],\n",
      "        ...,\n",
      "        [ 2.3656e-07,  6.4820e-07, -1.7462e-09,  ..., -4.2282e-07,\n",
      "          1.7136e-06,  2.8014e-06],\n",
      "        [ 4.2617e-06, -3.8650e-08, -3.3295e-08,  ..., -1.0207e-06,\n",
      "          7.1526e-07,  2.7716e-06],\n",
      "        [ 2.6524e-06, -1.3560e-06, -3.5912e-06,  ...,  2.7120e-06,\n",
      "         -9.4622e-07,  8.1658e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(mask.attention_masks[3]['W_Q'][-1].grad[-2])\n",
    "print(mask.attention_masks[3]['W_Q'][-1][-2])\n",
    "print((mask.attention_masks[3]['W_Q'][-1] - 1).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/mechanistic-unlearning/weight_masked_transformer.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Final evals\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m final_adversarial_eval \u001b[39m=\u001b[39m adversarial_sports_eval(model, model_type\u001b[39m=\u001b[39;49mmodel_type, batch_size\u001b[39m=\u001b[39;49meval_batch_size, use_system_prompt\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSystem Prompt: adversarial evals are \u001b[39m\u001b[39m{\u001b[39;00mfinal_adversarial_eval\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m final_adversarial_eval \u001b[39m=\u001b[39m adversarial_sports_eval(model, model_type\u001b[39m=\u001b[39mmodel_type, batch_size\u001b[39m=\u001b[39meval_batch_size, use_system_prompt\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/facts/SportsTaskAdversarial.py:400\u001b[0m, in \u001b[0;36madversarial_sports_eval\u001b[0;34m(model, model_type, batch_size, n_iters, continuous, test_each_sport, include_evals, use_icl, use_system_prompt)\u001b[0m\n\u001b[1;32m    398\u001b[0m     update_accuracies(\u001b[39m\"\u001b[39m\u001b[39mCapitalized\u001b[39m\u001b[39m\"\u001b[39m, SportsTask_Capitalized)\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mDashed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m include_evals:\n\u001b[0;32m--> 400\u001b[0m     update_accuracies(\u001b[39m\"\u001b[39;49m\u001b[39mDashed\u001b[39;49m\u001b[39m\"\u001b[39;49m, SportsTask_Dashed)\n\u001b[1;32m    402\u001b[0m \u001b[39mreturn\u001b[39;00m accuracies\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/facts/SportsTaskAdversarial.py:386\u001b[0m, in \u001b[0;36madversarial_sports_eval.<locals>.update_accuracies\u001b[0;34m(eval_type, eval_constructor)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m                 temp_task \u001b[39m=\u001b[39m eval_constructor(batch_size\u001b[39m=\u001b[39mbatch_size, tokenizer\u001b[39m=\u001b[39mtokenizer, is_forget_dataset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, forget_sport_subset\u001b[39m=\u001b[39m{sport})\n\u001b[0;32m--> 386\u001b[0m             accuracies[eval_type][sport] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m temp_task\u001b[39m.\u001b[39;49mget_test_accuracy(model, continuous\u001b[39m=\u001b[39;49mcontinuous) \u001b[39m/\u001b[39m n_iters\n\u001b[1;32m    387\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     temp_task \u001b[39m=\u001b[39m eval_constructor(batch_size\u001b[39m=\u001b[39mbatch_size, tokenizer\u001b[39m=\u001b[39mtokenizer, use_icl\u001b[39m=\u001b[39muse_icl, use_system_prompt\u001b[39m=\u001b[39muse_system_prompt)\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/facts/SportsTaskAdversarial.py:315\u001b[0m, in \u001b[0;36mSportsTask_Dashed.get_test_accuracy\u001b[0;34m(self, model, use_test_data, continuous)\u001b[0m\n\u001b[1;32m    312\u001b[0m new_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(completed_prompts[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39minput_ids) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(prompts[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39minput_ids)\n\u001b[1;32m    313\u001b[0m \u001b[39m# print(new_len)\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m sports_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(completed_prompts[\u001b[39m0\u001b[39;49m], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49minput_ids[\u001b[39m0\u001b[39;49m, \u001b[39m-\u001b[39;49mnew_len:]\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m    316\u001b[0m \u001b[39m# print(f\"{sports_tokens=}\")\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m \u001b[39m# cross entropy on new_len_tokens\u001b[39;00m\n\u001b[1;32m    319\u001b[0m last_logits \u001b[39m=\u001b[39m get_final_logits(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, completed_prompts, len_final_logits\u001b[39m=\u001b[39mnew_len\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Final evals\n",
    "final_adversarial_eval = adversarial_sports_eval(model, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=True)\n",
    "print(f\"System Prompt: adversarial evals are {final_adversarial_eval}\")\n",
    "final_adversarial_eval = adversarial_sports_eval(model, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=False)\n",
    "print(f\"No System Prompt: adversarial evals are {final_adversarial_eval}\")\n",
    "\n",
    "final_side_effects = run_side_effects_evals(model, model_type=model_type, batch_size=eval_batch_size, evals_to_run=[\"Sports Answers\", \"Sports Familiarity\", \"Cross Entropy\"], verbose=True)\n",
    "print(final_side_effects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W_in': False, 'W_out': True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_mask_mlp_dict[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mask.mlp_masks[5]['W_out'] - 1).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save masks state dict to neuron_cb\n",
    "torch.save(mask.state_dict(), \"masks/neuron_cb/mlps_unlearn_basketball.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
