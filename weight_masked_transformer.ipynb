{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "import pickle\n",
    "\n",
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPTNeoXTokenizerFast, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset('monology/pile-uncopyrighted', split='train', streaming=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_TOKEN'] = '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'\n",
    "model_name = 'google/gemma-2b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    device='cuda',\n",
    "    default_padding_side=\"right\",\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    center_writing_weights=False,\n",
    "    dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key not found, will not be able to run evaluations on Sports Trivia Task\n"
     ]
    }
   ],
   "source": [
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "from tasks.facts.SportsTaskAdversarial import adversarial_sports_eval\n",
    "from tasks.facts.SportsTaskSideEffects import run_side_effects_evals\n",
    "\n",
    "\n",
    "train_batch_size = 10\n",
    "eval_batch_size = 50\n",
    "\n",
    "device = \"cuda\"\n",
    "train_loss_type = \"sports\"\n",
    "forget_sport = \"basketball\"\n",
    "maintain_sport = None\n",
    "# val_sport = \"baseball\"\n",
    "\n",
    "\n",
    "sports_1mp = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"log_1_minus_p\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "\n",
    "if maintain_sport is None:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "else:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "\n",
    "train_pile = PileTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "train_tasks = {\"sports_1mp\": (sports_1mp, .2), \"maintain_sports\": (maintain_sports, 1), \"pile\": (train_pile, 1)}\n",
    "\n",
    "# want to eval on other sports\n",
    "forget_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "test_pile = PileTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "\n",
    "induction_eval = InductionTask(batch_size=eval_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, device=device)\n",
    "if maintain_sport is None:\n",
    "    maintain_sports_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sports_eval}\n",
    "else:\n",
    "    maintain_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "    val_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={val_sport}, is_forget_dataset=True)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sport_eval, \"val_sport\": val_sport_eval}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "def create_random_weight_mask_dicts(model):\n",
    "    # Creates random weight masks for testing\n",
    "    weight_mask_attn_dict = {}\n",
    "    weight_mask_mlp_dict = {}\n",
    "\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        weight_mask_attn_dict[layer] = {}\n",
    "        # Want bool of length n_head, randomly set to True\n",
    "        weight_mask_attn_dict[layer]['W_Q'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "        weight_mask_attn_dict[layer]['W_K'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "        weight_mask_attn_dict[layer]['W_V'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "        weight_mask_attn_dict[layer]['W_O'] = torch.rand(model.cfg.n_heads) < 0.8\n",
    "\n",
    "        # Randomly set to true or false\n",
    "        weight_mask_mlp_dict[layer] = random.randint(0, 1) == 1\n",
    "\n",
    "    return weight_mask_attn_dict, weight_mask_mlp_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Masking Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def make_partly_differentiable_mask(W, frozen_heads, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    W is Parameter of shape (n_heads, ...). \n",
    "    Returns baseline and frozen (both only 1d arrays of (n_heads,)), \n",
    "    and forward pass should be W_frozen.float() + W_baseline.float() * W \n",
    "    \"\"\"\n",
    "    W_frozen = torch.nn.Parameter(torch.zeros(W.shape[0], dtype=torch.bool), requires_grad=False).to(device)\n",
    "\n",
    "    # unsqueeze to broadcast efficiently, until W_baseline has same shape as W\n",
    "    while len(W_frozen.shape) < len(W.shape):\n",
    "        W_frozen = W_frozen.unsqueeze(-1)\n",
    "    \n",
    "    W_frozen[frozen_heads] = True\n",
    "\n",
    "    W_baseline = (~W_frozen).float()\n",
    "    W_baseline = torch.nn.Parameter(W_baseline, requires_grad=True)\n",
    "    # convert into float\n",
    "    return W_frozen.float(), 0.5 * W_baseline.float()\n",
    "\n",
    "class WeightMaskedTransformer(nn.Module):\n",
    "    def __init__(self, tl_transformer, weight_mask_attn_dict=None, weight_mask_mlp_dict=None, torch_dtype=torch.bfloat16):\n",
    "        \"\"\"\n",
    "        weight_mask_attn_dict: {layer: {\"W_Q\": unfrozen_heads, \"W_K\": unfrozen_heads, \"W_V\": unfrozen_heads, \"W_O\": unfrozen_heads}} (frozen_heads is shape (n_heads,) of bools). If none, train mask over all heads\n",
    "        weight_mask_mlp_dict: {layer: bool}. If none, train mask over all mlps\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.torch_dtype = torch_dtype\n",
    "        # tl_transformer should be a HookedTransformer\n",
    "        self.tl_transformer = tl_transformer\n",
    "        # turn off gradients for tl_transformer\n",
    "        # for param in self.tl_transformer.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.weight_mask_attn_dict = weight_mask_attn_dict\n",
    "        self.weight_mask_mlp_dict = weight_mask_mlp_dict\n",
    "        # store weight masks for every component that is unfrozen\n",
    "        \n",
    "        # need to store reference weights so that you can reset W_Q, etc after a forward pass\n",
    "        self.reference_attn_weights = {}\n",
    "        self.reference_mlp_weights = {}\n",
    "\n",
    "        self.attention_masks = {}\n",
    "        self.mlp_masks = {}\n",
    "        for layer in range(tl_transformer.cfg.n_layers):\n",
    "            self.attention_masks[layer] = {}\n",
    "            self.reference_attn_weights[layer] = {}\n",
    "            self.mlp_masks[layer] = {}\n",
    "            self.reference_mlp_weights[layer] = {}\n",
    "            # Attention heads\n",
    "            for component, parameter in [(\"W_Q\", tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", tl_transformer.blocks[layer].attn.W_K), (\"W_V\", tl_transformer.blocks[layer].attn.W_V), (\"W_O\", tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None:\n",
    "                    unfrozen_heads = list(range(tl_transformer.cfg.n_heads)) # all heads are unfrozen\n",
    "                else:\n",
    "                    unfrozen_heads = self.weight_mask_attn_dict[layer][component]\n",
    "                # make frozen and baseline masks, and also a copy of the original weights\n",
    "\n",
    "                if unfrozen_heads is not None and len(unfrozen_heads) > 0:\n",
    "                    W_frozen, W_baseline = make_partly_differentiable_mask(parameter, unfrozen_heads)\n",
    "                    weight_mask = nn.Parameter(torch.ones_like(parameter).type(torch_dtype), requires_grad=True)\n",
    "                    \n",
    "                    self.attention_masks[layer][component] = (W_frozen, W_baseline, weight_mask)\n",
    "                    self.reference_attn_weights[layer][component] = parameter.clone()\n",
    "\n",
    "            # MLPs\n",
    "\n",
    "            for component, parameter in [(\"W_in\", tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = nn.Parameter(torch.ones_like(parameter).type(torch_dtype), requires_grad=True)\n",
    "\n",
    "                    self.mlp_masks[layer][component] = weight_mask\n",
    "                    self.reference_mlp_weights[layer][component] = parameter.clone()\n",
    "\n",
    "                \n",
    "    def forward(self, *args, **kwargs):\n",
    "        for layer in range(self.tl_transformer.cfg.n_layers):\n",
    "            for component, parameter in [(\"W_Q\", self.tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", self.tl_transformer.blocks[layer].attn.W_K), (\"W_V\", self.tl_transformer.blocks[layer].attn.W_V), (\"W_O\", self.tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None or component in self.attention_masks[layer]:\n",
    "                    W_frozen, W_baseline, weight_mask = self.attention_masks[layer][component]\n",
    "                    reference_data = self.reference_attn_weights[layer][component]\n",
    "                    mask = W_frozen + W_baseline * weight_mask\n",
    "                    self.tl_transformer.blocks[layer].attn.__dict__['_parameters'][component] = reference_data * mask\n",
    "\n",
    "            for component, parameter in [(\"W_in\", self.tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", self.tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = self.mlp_masks[layer][component]\n",
    "                    reference_data = self.reference_mlp_weights[layer][component]\n",
    "                    self.tl_transformer.blocks[layer].mlp.__dict__['_parameters'][component] = reference_data * weight_mask\n",
    "\n",
    "        return self.tl_transformer(*args, **kwargs)\n",
    "\n",
    "    def generate(self, *args, **kwargs):\n",
    "        return self.tl_transformer.generate(*args, **kwargs)\n",
    "\n",
    "    def regularization_loss(self):\n",
    "        # Compute the L1 sparsity penalty using the masks\n",
    "        loss = 0\n",
    "        for layer in range(self.tl_transformer.cfg.n_layers):\n",
    "            for component, parameter in [(\"W_Q\", self.tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", self.tl_transformer.blocks[layer].attn.W_K), (\"W_V\", self.tl_transformer.blocks[layer].attn.W_V), (\"W_O\", self.tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None or component in self.attention_masks[layer]:\n",
    "                    W_frozen, W_baseline, weight_mask = self.attention_masks[layer][component]\n",
    "                    mask = W_frozen + (W_baseline * weight_mask) # 1s for frozen, heads\n",
    "                    # Add (weights away from 1) / (total weights * percent_masks_active)\n",
    "                    # loss += torch.sum(torch.abs(mask - 1)) / (mask.numel() * (W_baseline.sum() / W_baseline.numel()) + 1e-5)\n",
    "                    \n",
    "                    # Loss: -4(x-0.5)^{2}+1\n",
    "                    loss += (-4 * (mask - 0.5 ** 2) + 1).sum() / (mask.numel() * (W_baseline.sum() / W_baseline.numel()) + 1e-5)\n",
    "\n",
    "            for component, parameter in [(\"W_in\", self.tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", self.tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = self.mlp_masks[layer][component]\n",
    "                    # loss += torch.sum(torch.abs(weight_mask - 1)) / weight_mask.numel()\n",
    "                    # Loss: -4(x-0.5)^{2}+1\n",
    "                    loss += (-4 * ((weight_mask - 0.5) ** 2) + 1).sum() / weight_mask.numel()\n",
    "        return loss\n",
    "    \n",
    "    def on_step_end(self):\n",
    "        # Clip all the masks\n",
    "\n",
    "        for layer in range(self.tl_transformer.cfg.n_layers):\n",
    "            for component, parameter in [(\"W_Q\", self.tl_transformer.blocks[layer].attn.W_Q), (\"W_K\", self.tl_transformer.blocks[layer].attn.W_K), (\"W_V\", self.tl_transformer.blocks[layer].attn.W_V), (\"W_O\", self.tl_transformer.blocks[layer].attn.W_O)]:\n",
    "                if self.weight_mask_attn_dict is None or component in self.attention_masks[layer]:\n",
    "                    W_frozen, W_baseline, weight_mask = self.attention_masks[layer][component]\n",
    "                    weight_mask.data = torch.clamp(weight_mask.data, 0, 1)\n",
    "\n",
    "            for component, parameter in [(\"W_in\", self.tl_transformer.blocks[layer].mlp.W_in), (\"W_out\", self.tl_transformer.blocks[layer].mlp.W_out)]:\n",
    "                if self.weight_mask_mlp_dict is None or self.weight_mask_mlp_dict[layer][component]:\n",
    "                    weight_mask = self.mlp_masks[layer][component]\n",
    "                    weight_mask.data = torch.clamp(weight_mask.data, 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Weight Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_mask_from_ap_graph(model, ap_graph, threshold):\n",
    "    # Attention masks are of form:\n",
    "    # {layer: {\"W_Q\": frozen_heads, \"W_K\": frozen_heads, \"W_V\": frozen_heads, \"W_O\": frozen_heads}}\n",
    "    # TRUE for the heads we want to FREEZE, FALSE for heads we want to MASK over\n",
    "    # MLP masks are of form:\n",
    "    # {layer: bool}\n",
    "\n",
    "    # Localizations are of form:\n",
    "    # {alayer.head_{q,k,v,result}:int, mlayer_{in,out}: int}\n",
    "\n",
    "    weight_mask_attn_dict = {}\n",
    "    weight_mask_mlp_dict = {}\n",
    "\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        weight_mask_attn_dict[layer] = {}\n",
    "        weight_mask_mlp_dict[layer] = {}\n",
    "\n",
    "        if 'a0.0_q' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_Q'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_q\"]) < threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_Q'] = None\n",
    "\n",
    "        if 'a0.0_k' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_K'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_k\"]) < threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_K'] = None\n",
    "        \n",
    "        if 'a0.0_v' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_V'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_v\"]) < threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_V'] = None\n",
    "        \n",
    "        if 'a0.0_result' in ap_graph:\n",
    "            weight_mask_attn_dict[layer]['W_O'] = torch.tensor(\n",
    "                [\n",
    "                    abs(ap_graph[f\"a{layer}.{head}_result\"]) < threshold \n",
    "                    for head in range(model.cfg.n_heads)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            weight_mask_attn_dict[layer]['W_O'] = None\n",
    "            \n",
    "        if 'm0_in' in ap_graph:\n",
    "            weight_mask_mlp_dict[layer]['W_in'] = abs(ap_graph[f\"m{layer}_in\"]) < threshold\n",
    "        else:\n",
    "            weight_mask_mlp_dict[layer]['W_in'] = None\n",
    "        \n",
    "        if 'm0_out' in ap_graph:\n",
    "            weight_mask_mlp_dict[layer]['W_out'] = abs(ap_graph[f\"m{layer}_out\"]) < threshold\n",
    "        else:\n",
    "            weight_mask_mlp_dict[layer]['W_out'] = None\n",
    "\n",
    "    return weight_mask_attn_dict, weight_mask_mlp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"models/google_gemma-2b_sports_baseball_ap_graph.pkl\", \"rb\") as f:\n",
    "    ap_graph = pickle.load(f)\n",
    "\n",
    "weight_mask_attn_dict, weight_mask_mlp_dict = get_mask_from_ap_graph(model, ap_graph, 0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mask = WeightMaskedTransformer(\n",
    "    model, \n",
    "    weight_mask_attn_dict=weight_mask_attn_dict, \n",
    "    weight_mask_mlp_dict=weight_mask_mlp_dict\n",
    ")\n",
    "# for n, param in mask.tl_transformer.named_parameters():\n",
    "#     param.requires_grad = False\n",
    "sports_train = SportsTask(batch_size=8, tokenizer=tokenizer)\n",
    "with torch.autocast(device_type=\"cuda\"):\n",
    "    loss = sports_train.get_train_loss(mask, 1)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "\n",
    "print(mask.attention_masks[3]['W_Q'][-1].grad[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maaquib111\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/mechanistic-unlearning/wandb/run-20240508_014736-by2fhrk3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aaquib111/mech-unlearning/runs/by2fhrk3' target=\"_blank\">gemma-2b-basketball</a></strong> to <a href='https://wandb.ai/aaquib111/mech-unlearning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aaquib111/mech-unlearning' target=\"_blank\">https://wandb.ai/aaquib111/mech-unlearning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aaquib111/mech-unlearning/runs/by2fhrk3' target=\"_blank\">https://wandb.ai/aaquib111/mech-unlearning/runs/by2fhrk3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/mechanistic-unlearning/weight_masked_transformer.ipynb Cell 15\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m task_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m loss \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m task_weight\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import wandb\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "mask = WeightMaskedTransformer(\n",
    "    model, \n",
    "    weight_mask_attn_dict=weight_mask_attn_dict, \n",
    "    weight_mask_mlp_dict=weight_mask_mlp_dict\n",
    ")\n",
    "for param in mask.tl_transformer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_type = 'gemma'\n",
    "learning_rate = 1e-2\n",
    "n_epochs = 50\n",
    "grad_accum_steps = 5\n",
    "# max_gpu_batch_size=8\n",
    "alpha = 0.2\n",
    "beta = 5\n",
    "clip_grad = 1\n",
    "\n",
    "evaluate_every = 5\n",
    "n_eval_iters = 5\n",
    "do_adversarial_evals = True \n",
    "do_side_effects_evals = True \n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"mech-unlearning\",\n",
    "    name=f\"{model_name.split('/')[-1]}-{forget_sport}\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"model_type\": model_type,\n",
    "        \"model_name\": model_name,\n",
    "        \"forget_sport\": forget_sport,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"grad_accum_steps\": grad_accum_steps,\n",
    "        \"alpha\": alpha,\n",
    "        \"beta\": beta,\n",
    "        \"clip_grad\": clip_grad,\n",
    "        \"evaluate_every\": evaluate_every,\n",
    "        \"n_eval_iters\": n_eval_iters,\n",
    "        \"do_adversarial_evals\": do_adversarial_evals,\n",
    "        \"do_side_effects_evals\": do_side_effects_evals,\n",
    "        \"train_task_weights\": {k:v[1] for k, v in train_tasks.items()}\n",
    "    }\n",
    ")\n",
    "\n",
    "from collections import defaultdict\n",
    "all_train_losses = defaultdict(list)\n",
    "all_test_losses = defaultdict(list)\n",
    "adversarial_evals = []\n",
    "side_effect_evals = []\n",
    "\n",
    "# Initialize optimizer\n",
    "mask = mask.cuda()\n",
    "mask_params = [\n",
    "    v[-1]\n",
    "    for layer, layer_mask_weights in mask.attention_masks.items()\n",
    "    for k, v in layer_mask_weights.items()\n",
    "] + \\\n",
    "[\n",
    "    v\n",
    "    for layer, layer_mask_weights in mask.mlp_masks.items()\n",
    "    for k, v in layer_mask_weights.items()\n",
    "]\n",
    "optimizer = torch.optim.AdamW(mask_params, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=n_epochs)\n",
    "# Cycle dataloaders\n",
    "# Train a sparse mask\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    # Sample batches\n",
    "    # Reset grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.autocast(device_type=\"cuda\"):\n",
    "        # Compute normal loss over retain\n",
    "        for task_name, (task, task_weight) in train_tasks.items():\n",
    "            task_loss = 0\n",
    "            # print(task_name)\n",
    "            for i in range(grad_accum_steps):\n",
    "                loss = task.get_train_loss(mask) / grad_accum_steps\n",
    "                task_loss += loss.item()\n",
    "                loss *= task_weight\n",
    "                loss.backward()\n",
    "\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            all_train_losses[task_name].append(task_loss)\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        # Add sparsity loss and backprop\n",
    "        loss = beta * mask.regularization_loss()\n",
    "        loss.backward()\n",
    "        all_train_losses[\"reg\"].append(loss.item())\n",
    "        # Step and log\n",
    "        if clip_grad is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(mask.parameters(), clip_grad)\n",
    "        # zero_nan_grads(mask)\n",
    "        optimizer.step()\n",
    "        mask.on_step_end()\n",
    "        scheduler.step()\n",
    "\n",
    "        print(mask.attention_masks[3]['W_Q'][-1].grad[4])\n",
    "        print(mask.attention_masks[3]['W_Q'][-1])\n",
    "        print((mask.attention_masks[3]['W_Q'][-1] - 1).sum())\n",
    "\n",
    "        if epoch % evaluate_every == 0 or epoch == n_epochs - 1:\n",
    "            for task_name, task in eval_tasks.items():\n",
    "                task_loss = 0\n",
    "                for i in range(n_eval_iters):\n",
    "                    task_loss += task.get_test_loss(mask).item()\n",
    "                all_test_losses[task_name].append(task_loss / n_eval_iters)\n",
    "            if do_adversarial_evals:\n",
    "                print(\"Running adversarial evals\")\n",
    "                adversarial_evals.append(adversarial_sports_eval(mask, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=True))\n",
    "            if do_side_effects_evals:\n",
    "                print(\"Running side effects evals\")\n",
    "                side_effect_evals.append(run_side_effects_evals(mask, model_type=model_type, batch_size=eval_batch_size, evals_to_run=[\"Sports Answers\"]))\n",
    "        \n",
    "        # log_dict = {}\n",
    "        # for k, v in all_train_losses.items():\n",
    "        #     log_dict[f\"train_loss_{k}\"] = v[-1]\n",
    "        # for k, v in all_test_losses.items():\n",
    "        #     log_dict[f\"test_loss_{k}\"] = v[-1]\n",
    "        # for k, v in adversarial_evals[-1].items():\n",
    "        #     log_dict[f\"adversarial_{k}\"] = v\n",
    "        # for k, v in side_effect_evals[-1].items():\n",
    "        #     log_dict[f\"side_effects_{k}\"] = v\n",
    "        # wandb.log(log_dict)\n",
    "    \n",
    "wandb.finish()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'W_Q': tensor([ True, False,  True,  True,  True,  True,  True,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False,  True,  True,  True,  True,  True,  True,  True])},\n",
       " 1: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True, False,  True,  True,  True,  True,  True])},\n",
       " 2: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True, False,  True,  True,  True,  True,  True,  True])},\n",
       " 3: {'W_Q': tensor([ True,  True,  True,  True,  True,  True, False,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True,  True,  True,  True, False,  True])},\n",
       " 4: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])},\n",
       " 5: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])},\n",
       " 6: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True, False,  True, False,  True,  True])},\n",
       " 7: {'W_Q': tensor([ True, False,  True, False,  True,  True,  True,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True,  True,  True, False,  True,  True])},\n",
       " 8: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])},\n",
       " 9: {'W_Q': tensor([ True,  True,  True,  True, False,  True,  True,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True, False, False, False,  True,  True,  True])},\n",
       " 10: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True,  True,  True, False,  True,  True])},\n",
       " 11: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False,  True,  True,  True,  True,  True, False, False])},\n",
       " 12: {'W_Q': tensor([ True,  True, False,  True,  True,  True,  True,  True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False, False, False, False, False, False,  True,  True])},\n",
       " 13: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False, False,  True, False, False,  True,  True,  True])},\n",
       " 14: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([False,  True,  True,  True,  True, False,  True,  True])},\n",
       " 15: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])},\n",
       " 16: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([ True,  True,  True,  True, False,  True,  True,  True])},\n",
       " 17: {'W_Q': tensor([True, True, True, True, True, True, True, True]),\n",
       "  'W_K': None,\n",
       "  'W_V': None,\n",
       "  'W_O': tensor([True, True, True, True, True, True, True, True])}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.weight_mask_attn_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = torch.cat(\n",
    "    [\n",
    "        mask.flatten() \n",
    "        for m in mask.masks.values()\n",
    "\n",
    "        if component in mask.attention_masks[layer]\n",
    "        for component in [\"W_Q\", \"W_K\", \"W_V\", \"W_O\"]\n",
    "        for layer in range(mask.tl_transformer.cfg.n_layers)\n",
    "    ], \n",
    "    dim=0\n",
    ").cpu()\n",
    "sorted_values = all_values.sort().values\n",
    "plt.semilogx(sorted_values)\n",
    "plt.title(f\"{title} Neuron Mask Values\")\n",
    "plt.ylabel(\"Mask Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fbca8112d10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Create a histogram of mask values if W_baseline is 1\n",
    "\n",
    "hist = []\n",
    "for layer in range(mask.tl_transformer.cfg.n_layers):\n",
    "    for component in [\"W_Q\", \"W_K\", \"W_V\", \"W_O\"]:\n",
    "        if component in mask.attention_masks[layer]:\n",
    "            frozen, baseline, mask_values = mask.attention_masks[layer][component]\n",
    "            for i in range(baseline.shape[0]):\n",
    "                if baseline[i] == 1:\n",
    "                    hist.append(mask_values[i].flatten())\n",
    "\n",
    "hist = torch.cat(hist, dim=0).cpu()\n",
    "\n",
    "sorted_values = hist.sort().values\n",
    "plt.semilogx(sorted_values)\n",
    "plt.title(f\"Mask Values\")\n",
    "plt.ylabel(\"Mask Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.2212e-07,  7.0035e-07, -7.9349e-07,  ...,  7.8082e-06,\n",
      "          7.7859e-07,  4.3958e-07],\n",
      "        [-1.7658e-06,  2.6822e-07, -9.7603e-07,  ..., -7.6890e-06,\n",
      "          4.7684e-06,  6.2287e-06],\n",
      "        [-6.3330e-08, -1.3690e-07,  1.2368e-06,  ...,  1.2740e-06,\n",
      "          1.2890e-06,  9.3877e-07],\n",
      "        ...,\n",
      "        [ 2.3656e-07,  6.4820e-07, -1.7462e-09,  ..., -4.2282e-07,\n",
      "          1.7136e-06,  2.8014e-06],\n",
      "        [ 4.2617e-06, -3.8650e-08, -3.3295e-08,  ..., -1.0207e-06,\n",
      "          7.1526e-07,  2.7716e-06],\n",
      "        [ 2.6524e-06, -1.3560e-06, -3.5912e-06,  ...,  2.7120e-06,\n",
      "         -9.4622e-07,  8.1658e-06]], device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(mask.attention_masks[3]['W_Q'][-1].grad[-2])\n",
    "print(mask.attention_masks[3]['W_Q'][-1][-2])\n",
    "print((mask.attention_masks[3]['W_Q'][-1] - 1).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/mechanistic-unlearning/weight_masked_transformer.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Final evals\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m final_adversarial_eval \u001b[39m=\u001b[39m adversarial_sports_eval(model, model_type\u001b[39m=\u001b[39;49mmodel_type, batch_size\u001b[39m=\u001b[39;49meval_batch_size, use_system_prompt\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSystem Prompt: adversarial evals are \u001b[39m\u001b[39m{\u001b[39;00mfinal_adversarial_eval\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvast/root/mechanistic-unlearning/weight_masked_transformer.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m final_adversarial_eval \u001b[39m=\u001b[39m adversarial_sports_eval(model, model_type\u001b[39m=\u001b[39mmodel_type, batch_size\u001b[39m=\u001b[39meval_batch_size, use_system_prompt\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/facts/SportsTaskAdversarial.py:400\u001b[0m, in \u001b[0;36madversarial_sports_eval\u001b[0;34m(model, model_type, batch_size, n_iters, continuous, test_each_sport, include_evals, use_icl, use_system_prompt)\u001b[0m\n\u001b[1;32m    398\u001b[0m     update_accuracies(\u001b[39m\"\u001b[39m\u001b[39mCapitalized\u001b[39m\u001b[39m\"\u001b[39m, SportsTask_Capitalized)\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mDashed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m include_evals:\n\u001b[0;32m--> 400\u001b[0m     update_accuracies(\u001b[39m\"\u001b[39;49m\u001b[39mDashed\u001b[39;49m\u001b[39m\"\u001b[39;49m, SportsTask_Dashed)\n\u001b[1;32m    402\u001b[0m \u001b[39mreturn\u001b[39;00m accuracies\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/facts/SportsTaskAdversarial.py:386\u001b[0m, in \u001b[0;36madversarial_sports_eval.<locals>.update_accuracies\u001b[0;34m(eval_type, eval_constructor)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m                 temp_task \u001b[39m=\u001b[39m eval_constructor(batch_size\u001b[39m=\u001b[39mbatch_size, tokenizer\u001b[39m=\u001b[39mtokenizer, is_forget_dataset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, forget_sport_subset\u001b[39m=\u001b[39m{sport})\n\u001b[0;32m--> 386\u001b[0m             accuracies[eval_type][sport] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m temp_task\u001b[39m.\u001b[39;49mget_test_accuracy(model, continuous\u001b[39m=\u001b[39;49mcontinuous) \u001b[39m/\u001b[39m n_iters\n\u001b[1;32m    387\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     temp_task \u001b[39m=\u001b[39m eval_constructor(batch_size\u001b[39m=\u001b[39mbatch_size, tokenizer\u001b[39m=\u001b[39mtokenizer, use_icl\u001b[39m=\u001b[39muse_icl, use_system_prompt\u001b[39m=\u001b[39muse_system_prompt)\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/facts/SportsTaskAdversarial.py:315\u001b[0m, in \u001b[0;36mSportsTask_Dashed.get_test_accuracy\u001b[0;34m(self, model, use_test_data, continuous)\u001b[0m\n\u001b[1;32m    312\u001b[0m new_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(completed_prompts[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39minput_ids) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(prompts[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39minput_ids)\n\u001b[1;32m    313\u001b[0m \u001b[39m# print(new_len)\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m sports_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(completed_prompts[\u001b[39m0\u001b[39;49m], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49minput_ids[\u001b[39m0\u001b[39;49m, \u001b[39m-\u001b[39;49mnew_len:]\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m    316\u001b[0m \u001b[39m# print(f\"{sports_tokens=}\")\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m \u001b[39m# cross entropy on new_len_tokens\u001b[39;00m\n\u001b[1;32m    319\u001b[0m last_logits \u001b[39m=\u001b[39m get_final_logits(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, completed_prompts, len_final_logits\u001b[39m=\u001b[39mnew_len\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Final evals\n",
    "final_adversarial_eval = adversarial_sports_eval(model, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=True)\n",
    "print(f\"System Prompt: adversarial evals are {final_adversarial_eval}\")\n",
    "final_adversarial_eval = adversarial_sports_eval(model, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=False)\n",
    "print(f\"No System Prompt: adversarial evals are {final_adversarial_eval}\")\n",
    "\n",
    "final_side_effects = run_side_effects_evals(model, model_type=model_type, batch_size=eval_batch_size, evals_to_run=[\"Sports Answers\", \"Sports Familiarity\", \"Cross Entropy\"], verbose=True)\n",
    "print(final_side_effects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W_in': False, 'W_out': True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_mask_mlp_dict[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', dtype=torch.bfloat16, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mask.mlp_masks[5]['W_out'] - 1).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save masks state dict to neuron_cb\n",
    "torch.save(mask.state_dict(), \"masks/neuron_cb/mlps_unlearn_basketball.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
