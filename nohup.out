Gemma's activation function should be approximate GeLU and not exact GeLU.
Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.
OpenAI API key not found, will not be able to run evaluations on Sports Trivia Task
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.23it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.29it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.72it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]
/root/mechanistic-unlearning/weight_mask.py:140: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index
  weight_mask_attn_dict[layer]['W_Q'] = torch.tensor(
/root/mechanistic-unlearning/weight_mask.py:150: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index
  weight_mask_attn_dict[layer]['W_K'] = torch.tensor(
/root/mechanistic-unlearning/weight_mask.py:160: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index
  weight_mask_attn_dict[layer]['W_V'] = torch.tensor(
/root/mechanistic-unlearning/weight_mask.py:170: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index
  weight_mask_attn_dict[layer]['W_O'] = torch.tensor(
wandb: Currently logged in as: aaquib111. Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /root/mechanistic-unlearning/wandb/run-20240519_195757-9ygnh89o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gemma-7b-athlete-ct
wandb: ⭐️ View project at https://wandb.ai/aaquib111/mech-unlearning
wandb: 🚀 View run at https://wandb.ai/aaquib111/mech-unlearning/runs/9ygnh89o
Loaded pretrained model google/gemma-7b into HookedTransformer
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:43<35:50, 43.88s/it]  4%|▍         | 2/50 [01:20<31:52, 39.84s/it]  6%|▌         | 3/50 [01:58<30:16, 38.65s/it]  8%|▊         | 4/50 [02:34<29:04, 37.92s/it] 10%|█         | 5/50 [03:11<28:11, 37.60s/it] 12%|█▏        | 6/50 [03:56<29:23, 40.08s/it] 14%|█▍        | 7/50 [04:35<28:20, 39.54s/it] 16%|█▌        | 8/50 [05:12<27:04, 38.67s/it] 18%|█▊        | 9/50 [05:49<26:05, 38.19s/it] 20%|██        | 10/50 [06:26<25:13, 37.83s/it] 22%|██▏       | 11/50 [07:11<25:58, 39.97s/it] 24%|██▍       | 12/50 [07:48<24:45, 39.08s/it] 26%|██▌       | 13/50 [08:25<23:41, 38.43s/it] 28%|██▊       | 14/50 [09:01<22:45, 37.94s/it] 30%|███       | 15/50 [09:38<21:55, 37.59s/it] 32%|███▏      | 16/50 [10:23<22:35, 39.87s/it] 34%|███▍      | 17/50 [11:00<21:27, 39.00s/it] 36%|███▌      | 18/50 [11:37<20:28, 38.40s/it] 38%|███▊      | 19/50 [12:14<19:37, 37.97s/it] 40%|████      | 20/50 [12:51<18:48, 37.61s/it] 42%|████▏     | 21/50 [13:35<19:09, 39.65s/it] 44%|████▍     | 22/50 [14:12<18:04, 38.74s/it] 46%|████▌     | 23/50 [14:49<17:10, 38.16s/it] 48%|████▊     | 24/50 [15:26<16:22, 37.79s/it] 50%|█████     | 25/50 [16:03<15:39, 37.58s/it] 52%|█████▏    | 26/50 [16:48<15:54, 39.77s/it] 54%|█████▍    | 27/50 [17:25<14:55, 38.92s/it] 56%|█████▌    | 28/50 [18:02<14:02, 38.29s/it] 58%|█████▊    | 29/50 [18:38<13:14, 37.84s/it] 60%|██████    | 30/50 [19:15<12:31, 37.57s/it] 62%|██████▏   | 31/50 [20:00<12:34, 39.73s/it] 64%|██████▍   | 32/50 [20:38<11:46, 39.26s/it] 66%|██████▌   | 33/50 [21:15<10:54, 38.51s/it] 68%|██████▊   | 34/50 [21:51<10:06, 37.92s/it] 70%|███████   | 35/50 [22:28<09:24, 37.61s/it] 72%|███████▏  | 36/50 [23:13<09:16, 39.76s/it] 74%|███████▍  | 37/50 [23:50<08:25, 38.89s/it] 76%|███████▌  | 38/50 [24:27<07:38, 38.18s/it] 78%|███████▊  | 39/50 [25:04<06:56, 37.86s/it] 80%|████████  | 40/50 [25:41<06:16, 37.62s/it] 82%|████████▏ | 41/50 [26:25<05:56, 39.63s/it] 84%|████████▍ | 42/50 [27:02<05:10, 38.81s/it] 86%|████████▌ | 43/50 [27:39<04:27, 38.21s/it] 88%|████████▊ | 44/50 [28:17<03:49, 38.20s/it] 90%|█████████ | 45/50 [28:54<03:09, 37.81s/it] 92%|█████████▏| 46/50 [29:41<02:42, 40.63s/it] 94%|█████████▍| 47/50 [30:18<01:58, 39.55s/it] 96%|█████████▌| 48/50 [30:55<01:17, 38.77s/it] 98%|█████████▊| 49/50 [31:32<00:38, 38.20s/it]100%|██████████| 50/50 [32:16<00:00, 40.11s/it]100%|██████████| 50/50 [32:16<00:00, 38.74s/it]
wandb: - 0.014 MB of 0.014 MB uploadedwandb: \ 0.014 MB of 0.018 MB uploadedwandb: | 0.018 MB of 0.024 MB uploadedwandb: / 0.018 MB of 0.024 MB uploadedwandb: - 0.018 MB of 0.024 MB uploadedwandb: \ 0.018 MB of 0.024 MB uploadedwandb: | 0.018 MB of 0.024 MB uploadedwandb: / 0.018 MB of 0.024 MB uploadedwandb: - 0.018 MB of 0.024 MB uploadedwandb: \ 0.018 MB of 0.024 MB uploadedwandb: | 0.018 MB of 0.024 MB uploadedwandb: / 0.018 MB of 0.024 MB uploadedwandb: - 0.018 MB of 0.024 MB uploadedwandb: \ 0.018 MB of 0.024 MB uploadedwandb: | 0.018 MB of 0.024 MB uploadedwandb: / 0.018 MB of 0.024 MB uploadedwandb: - 0.018 MB of 0.024 MB uploadedwandb: \ 0.018 MB of 0.024 MB uploadedwandb: | 0.018 MB of 0.024 MB uploadedwandb: / 0.018 MB of 0.024 MB uploadedwandb: - 0.018 MB of 0.024 MB uploadedwandb: \ 0.018 MB of 0.024 MB uploadedwandb: | 0.018 MB of 0.024 MB uploadedwandb: / 0.018 MB of 0.024 MB uploadedwandb: - 0.024 MB of 0.024 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:     test_loss_forget_sport ████▁▁▁▁████▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:        test_loss_induction ▁▁▁▁▃▃▃▃████▃▃▃▃▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▂
wandb:   test_loss_maintain_sport ████▁▁▁▁████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:             test_loss_pile ▂▂▂▂▅▅▅▅████▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train_loss_maintain_sports ▁█▃▁▁▁▁▁▁█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            train_loss_pile ▁▂▂▂▂▄█▄▂█▆▅▄▃▄▃▃▃▃▂▃▂▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁
wandb:             train_loss_reg ████▇▇▆▆▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:      train_loss_sports_1mp ▅▁▁▁▂██▇▄▁▂▂▃▂▃▃▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     test_loss_forget_sport 5.41543
wandb:        test_loss_induction 1.82043
wandb:   test_loss_maintain_sport 0.03828
wandb:             test_loss_pile 2.57358
wandb: train_loss_maintain_sports 0.00739
wandb:            train_loss_pile 2.61685
wandb:             train_loss_reg 0.97376
wandb:      train_loss_sports_1mp 0.01789
wandb: 
wandb: 🚀 View run gemma-7b-athlete-ct at: https://wandb.ai/aaquib111/mech-unlearning/runs/9ygnh89o
wandb: ⭐️ View project at: https://wandb.ai/aaquib111/mech-unlearning
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240519_195757-9ygnh89o/logs
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737816452980042
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737811088562012
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737808108329773
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737802147865295
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737790822982788
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737777709960938
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737765192985535
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737753868103027
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737743735313416
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737732410430908
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737721681594849
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737712740898132
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737700819969177
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737687110900879
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737676382064819
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737666845321655
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737656712532043
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.973764955997467
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737642407417297
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737632274627686
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.973762571811676
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737620949745178
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737614393234253
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737610220909119
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737604856491089
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.973760187625885
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737597703933716
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737594127655029
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737590551376343
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737588167190552
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737586975097656
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737585186958313
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737582802772522
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737581014633179
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737581014633179
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737579226493835
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737579226493835
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.973757803440094
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737577438354492
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737577438354492
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737577438354492
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737577438354492
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737577438354492
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737577438354492
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737576842308044
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737576842308044
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737576842308044
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737576842308044
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737576842308044
Running sports_1mp
Running maintain_sports
Running pile
reg loss, 0.9737576842308044
