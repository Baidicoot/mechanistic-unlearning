{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from circuit_breaking.src import *\n",
    "import torch\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from circuit_breaking.src.utils import load_model_from_transformers, from_hf_to_tlens\n",
    "from circuit_breaking.src.masks import MLPHiddenMask\n",
    "from tqdm.auto import tqdm\n",
    "#torch.autograd.set_detect_anomaly(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946fa08156524365b693753b05f8d8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-7b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPTNeoXTokenizerFast, AutoModelForCausalLM, AutoTokenizer\n",
    "model_name_or_path = \"google/gemma-7b\"\n",
    "model_type = \"gemma\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    'google/gemma-7b',\n",
    "    tokenizer=tokenizer,\n",
    "    device='cuda',\n",
    "    default_padding_side=\"right\",\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    center_writing_weights=False,\n",
    "    dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a0.0_q', 'a0.1_q', 'a0.2_q', 'a0.3_q', 'a0.4_q', 'a0.5_q', 'a0.6_q', 'a0.7_q', 'a0.8_q', 'a0.9_q', 'a0.10_q', 'a0.11_q', 'a0.12_q', 'a0.13_q', 'a0.14_q', 'a0.15_q', 'a0.0_k', 'a0.1_k', 'a0.2_k', 'a0.3_k', 'a0.4_k', 'a0.5_k', 'a0.6_k', 'a0.7_k', 'a0.8_k', 'a0.9_k', 'a0.10_k', 'a0.11_k', 'a0.12_k', 'a0.13_k', 'a0.14_k', 'a0.15_k', 'a0.0_v', 'a0.1_v', 'a0.2_v', 'a0.3_v', 'a0.4_v', 'a0.5_v', 'a0.6_v', 'a0.7_v', 'a0.8_v', 'a0.9_v', 'a0.10_v', 'a0.11_v', 'a0.12_v', 'a0.13_v', 'a0.14_v', 'a0.15_v', 'a0.0_result', 'a0.1_result', 'a0.2_result', 'a0.3_result', 'a0.4_result', 'a0.5_result', 'a0.6_result', 'a0.7_result', 'a0.8_result', 'a0.9_result', 'a0.10_result', 'a0.11_result', 'a0.12_result', 'a0.13_result', 'a0.14_result', 'a0.15_result', 'a1.0_q', 'a1.1_q', 'a1.2_q', 'a1.3_q', 'a1.4_q', 'a1.5_q', 'a1.6_q', 'a1.7_q', 'a1.8_q', 'a1.9_q', 'a1.10_q', 'a1.11_q', 'a1.12_q', 'a1.13_q', 'a1.14_q', 'a1.15_q', 'a1.0_k', 'a1.1_k', 'a1.2_k', 'a1.3_k', 'a1.4_k', 'a1.5_k', 'a1.6_k', 'a1.7_k', 'a1.8_k', 'a1.9_k', 'a1.10_k', 'a1.11_k', 'a1.12_k', 'a1.13_k', 'a1.14_k', 'a1.15_k', 'a1.0_v', 'a1.1_v', 'a1.2_v', 'a1.3_v', 'a1.4_v', 'a1.5_v', 'a1.6_v', 'a1.7_v', 'a1.8_v', 'a1.9_v', 'a1.10_v', 'a1.11_v', 'a1.12_v', 'a1.13_v', 'a1.14_v', 'a1.15_v', 'a1.0_result', 'a1.1_result', 'a1.2_result', 'a1.3_result', 'a1.4_result', 'a1.5_result', 'a1.6_result', 'a1.7_result', 'a1.8_result', 'a1.9_result', 'a1.10_result', 'a1.11_result', 'a1.12_result', 'a1.13_result', 'a1.14_result', 'a1.15_result', 'a2.0_q', 'a2.1_q', 'a2.2_q', 'a2.3_q', 'a2.4_q', 'a2.5_q', 'a2.6_q', 'a2.7_q', 'a2.8_q', 'a2.9_q', 'a2.10_q', 'a2.11_q', 'a2.12_q', 'a2.13_q', 'a2.14_q', 'a2.15_q', 'a2.0_k', 'a2.1_k', 'a2.2_k', 'a2.3_k', 'a2.4_k', 'a2.5_k', 'a2.6_k', 'a2.7_k', 'a2.8_k', 'a2.9_k', 'a2.10_k', 'a2.11_k', 'a2.12_k', 'a2.13_k', 'a2.14_k', 'a2.15_k', 'a2.0_v', 'a2.1_v', 'a2.2_v', 'a2.3_v', 'a2.4_v', 'a2.5_v', 'a2.6_v', 'a2.7_v', 'a2.8_v', 'a2.9_v', 'a2.10_v', 'a2.11_v', 'a2.12_v', 'a2.13_v', 'a2.14_v', 'a2.15_v', 'a2.0_result', 'a2.1_result', 'a2.2_result', 'a2.3_result', 'a2.4_result', 'a2.5_result', 'a2.6_result', 'a2.7_result', 'a2.8_result', 'a2.9_result', 'a2.10_result', 'a2.11_result', 'a2.12_result', 'a2.13_result', 'a2.14_result', 'a2.15_result', 'a3.0_q', 'a3.1_q', 'a3.2_q', 'a3.3_q', 'a3.4_q', 'a3.5_q', 'a3.6_q', 'a3.7_q', 'a3.8_q', 'a3.9_q', 'a3.10_q', 'a3.11_q', 'a3.12_q', 'a3.13_q', 'a3.14_q', 'a3.15_q', 'a3.0_k', 'a3.1_k', 'a3.2_k', 'a3.3_k', 'a3.4_k', 'a3.5_k', 'a3.6_k', 'a3.7_k', 'a3.8_k', 'a3.9_k', 'a3.10_k', 'a3.11_k', 'a3.12_k', 'a3.13_k', 'a3.14_k', 'a3.15_k', 'a3.0_v', 'a3.1_v', 'a3.2_v', 'a3.3_v', 'a3.4_v', 'a3.5_v', 'a3.6_v', 'a3.7_v', 'a3.8_v', 'a3.9_v', 'a3.10_v', 'a3.11_v', 'a3.12_v', 'a3.13_v', 'a3.14_v', 'a3.15_v', 'a3.0_result', 'a3.1_result', 'a3.2_result', 'a3.3_result', 'a3.4_result', 'a3.5_result', 'a3.6_result', 'a3.7_result', 'a3.8_result', 'a3.9_result', 'a3.10_result', 'a3.11_result', 'a3.12_result', 'a3.13_result', 'a3.14_result', 'a3.15_result', 'a4.0_q', 'a4.1_q', 'a4.2_q', 'a4.3_q', 'a4.4_q', 'a4.5_q', 'a4.6_q', 'a4.7_q', 'a4.8_q', 'a4.9_q', 'a4.10_q', 'a4.11_q', 'a4.12_q', 'a4.13_q', 'a4.14_q', 'a4.15_q', 'a4.0_k', 'a4.1_k', 'a4.2_k', 'a4.3_k', 'a4.4_k', 'a4.5_k', 'a4.6_k', 'a4.7_k', 'a4.8_k', 'a4.9_k', 'a4.10_k', 'a4.11_k', 'a4.12_k', 'a4.13_k', 'a4.14_k', 'a4.15_k', 'a4.0_v', 'a4.1_v', 'a4.2_v', 'a4.3_v', 'a4.4_v', 'a4.5_v', 'a4.6_v', 'a4.7_v', 'a4.8_v', 'a4.9_v', 'a4.10_v', 'a4.11_v', 'a4.12_v', 'a4.13_v', 'a4.14_v', 'a4.15_v', 'a4.0_result', 'a4.1_result', 'a4.2_result', 'a4.3_result', 'a4.4_result', 'a4.5_result', 'a4.6_result', 'a4.7_result', 'a4.8_result', 'a4.9_result', 'a4.10_result', 'a4.11_result', 'a4.12_result', 'a4.13_result', 'a4.14_result', 'a4.15_result', 'a5.0_q', 'a5.1_q', 'a5.2_q', 'a5.3_q', 'a5.4_q', 'a5.5_q', 'a5.6_q', 'a5.7_q', 'a5.8_q', 'a5.9_q', 'a5.10_q', 'a5.11_q', 'a5.12_q', 'a5.13_q', 'a5.14_q', 'a5.15_q', 'a5.0_k', 'a5.1_k', 'a5.2_k', 'a5.3_k', 'a5.4_k', 'a5.5_k', 'a5.6_k', 'a5.7_k', 'a5.8_k', 'a5.9_k', 'a5.10_k', 'a5.11_k', 'a5.12_k', 'a5.13_k', 'a5.14_k', 'a5.15_k', 'a5.0_v', 'a5.1_v', 'a5.2_v', 'a5.3_v', 'a5.4_v', 'a5.5_v', 'a5.6_v', 'a5.7_v', 'a5.8_v', 'a5.9_v', 'a5.10_v', 'a5.11_v', 'a5.12_v', 'a5.13_v', 'a5.14_v', 'a5.15_v', 'a5.0_result', 'a5.1_result', 'a5.2_result', 'a5.3_result', 'a5.4_result', 'a5.5_result', 'a5.6_result', 'a5.7_result', 'a5.8_result', 'a5.9_result', 'a5.10_result', 'a5.11_result', 'a5.12_result', 'a5.13_result', 'a5.14_result', 'a5.15_result', 'a6.0_q', 'a6.1_q', 'a6.2_q', 'a6.3_q', 'a6.4_q', 'a6.5_q', 'a6.6_q', 'a6.7_q', 'a6.8_q', 'a6.9_q', 'a6.10_q', 'a6.11_q', 'a6.12_q', 'a6.13_q', 'a6.14_q', 'a6.15_q', 'a6.0_k', 'a6.1_k', 'a6.2_k', 'a6.3_k', 'a6.4_k', 'a6.5_k', 'a6.6_k', 'a6.7_k', 'a6.8_k', 'a6.9_k', 'a6.10_k', 'a6.11_k', 'a6.12_k', 'a6.13_k', 'a6.14_k', 'a6.15_k', 'a6.0_v', 'a6.1_v', 'a6.2_v', 'a6.3_v', 'a6.4_v', 'a6.5_v', 'a6.6_v', 'a6.7_v', 'a6.8_v', 'a6.9_v', 'a6.10_v', 'a6.11_v', 'a6.12_v', 'a6.13_v', 'a6.14_v', 'a6.15_v', 'a6.0_result', 'a6.1_result', 'a6.2_result', 'a6.3_result', 'a6.4_result', 'a6.5_result', 'a6.6_result', 'a6.7_result', 'a6.8_result', 'a6.9_result', 'a6.10_result', 'a6.11_result', 'a6.12_result', 'a6.13_result', 'a6.14_result', 'a6.15_result', 'a7.0_q', 'a7.1_q', 'a7.2_q', 'a7.3_q', 'a7.4_q', 'a7.5_q', 'a7.6_q', 'a7.7_q', 'a7.8_q', 'a7.9_q', 'a7.10_q', 'a7.11_q', 'a7.12_q', 'a7.13_q', 'a7.14_q', 'a7.15_q', 'a7.0_k', 'a7.1_k', 'a7.2_k', 'a7.3_k', 'a7.4_k', 'a7.5_k', 'a7.6_k', 'a7.7_k', 'a7.8_k', 'a7.9_k', 'a7.10_k', 'a7.11_k', 'a7.12_k', 'a7.13_k', 'a7.14_k', 'a7.15_k', 'a7.0_v', 'a7.1_v', 'a7.2_v', 'a7.3_v', 'a7.4_v', 'a7.5_v', 'a7.6_v', 'a7.7_v', 'a7.8_v', 'a7.9_v', 'a7.10_v', 'a7.11_v', 'a7.12_v', 'a7.13_v', 'a7.14_v', 'a7.15_v', 'a7.0_result', 'a7.1_result', 'a7.2_result', 'a7.3_result', 'a7.4_result', 'a7.5_result', 'a7.6_result', 'a7.7_result', 'a7.8_result', 'a7.9_result', 'a7.10_result', 'a7.11_result', 'a7.12_result', 'a7.13_result', 'a7.14_result', 'a7.15_result', 'a8.0_q', 'a8.1_q', 'a8.2_q', 'a8.3_q', 'a8.4_q', 'a8.5_q', 'a8.6_q', 'a8.7_q', 'a8.8_q', 'a8.9_q', 'a8.10_q', 'a8.11_q', 'a8.12_q', 'a8.13_q', 'a8.14_q', 'a8.15_q', 'a8.0_k', 'a8.1_k', 'a8.2_k', 'a8.3_k', 'a8.4_k', 'a8.5_k', 'a8.6_k', 'a8.7_k', 'a8.8_k', 'a8.9_k', 'a8.10_k', 'a8.11_k', 'a8.12_k', 'a8.13_k', 'a8.14_k', 'a8.15_k', 'a8.0_v', 'a8.1_v', 'a8.2_v', 'a8.3_v', 'a8.4_v', 'a8.5_v', 'a8.6_v', 'a8.7_v', 'a8.8_v', 'a8.9_v', 'a8.10_v', 'a8.11_v', 'a8.12_v', 'a8.13_v', 'a8.14_v', 'a8.15_v', 'a8.0_result', 'a8.1_result', 'a8.2_result', 'a8.3_result', 'a8.4_result', 'a8.5_result', 'a8.6_result', 'a8.7_result', 'a8.8_result', 'a8.9_result', 'a8.10_result', 'a8.11_result', 'a8.12_result', 'a8.13_result', 'a8.14_result', 'a8.15_result', 'a9.0_q', 'a9.1_q', 'a9.2_q', 'a9.3_q', 'a9.4_q', 'a9.5_q', 'a9.6_q', 'a9.7_q', 'a9.8_q', 'a9.9_q', 'a9.10_q', 'a9.11_q', 'a9.12_q', 'a9.13_q', 'a9.14_q', 'a9.15_q', 'a9.0_k', 'a9.1_k', 'a9.2_k', 'a9.3_k', 'a9.4_k', 'a9.5_k', 'a9.6_k', 'a9.7_k', 'a9.8_k', 'a9.9_k', 'a9.10_k', 'a9.11_k', 'a9.12_k', 'a9.13_k', 'a9.14_k', 'a9.15_k', 'a9.0_v', 'a9.1_v', 'a9.2_v', 'a9.3_v', 'a9.4_v', 'a9.5_v', 'a9.6_v', 'a9.7_v', 'a9.8_v', 'a9.9_v', 'a9.10_v', 'a9.11_v', 'a9.12_v', 'a9.13_v', 'a9.14_v', 'a9.15_v', 'a9.0_result', 'a9.1_result', 'a9.2_result', 'a9.3_result', 'a9.4_result', 'a9.5_result', 'a9.6_result', 'a9.7_result', 'a9.8_result', 'a9.9_result', 'a9.10_result', 'a9.11_result', 'a9.12_result', 'a9.13_result', 'a9.14_result', 'a9.15_result', 'a10.0_q', 'a10.1_q', 'a10.2_q', 'a10.3_q', 'a10.4_q', 'a10.5_q', 'a10.6_q', 'a10.7_q', 'a10.8_q', 'a10.9_q', 'a10.10_q', 'a10.11_q', 'a10.12_q', 'a10.13_q', 'a10.14_q', 'a10.15_q', 'a10.0_k', 'a10.1_k', 'a10.2_k', 'a10.3_k', 'a10.4_k', 'a10.5_k', 'a10.6_k', 'a10.7_k', 'a10.8_k', 'a10.9_k', 'a10.10_k', 'a10.11_k', 'a10.12_k', 'a10.13_k', 'a10.14_k', 'a10.15_k', 'a10.0_v', 'a10.1_v', 'a10.2_v', 'a10.3_v', 'a10.4_v', 'a10.5_v', 'a10.6_v', 'a10.7_v', 'a10.8_v', 'a10.9_v', 'a10.10_v', 'a10.11_v', 'a10.12_v', 'a10.13_v', 'a10.14_v', 'a10.15_v', 'a10.0_result', 'a10.1_result', 'a10.2_result', 'a10.3_result', 'a10.4_result', 'a10.5_result', 'a10.6_result', 'a10.7_result', 'a10.8_result', 'a10.9_result', 'a10.10_result', 'a10.11_result', 'a10.12_result', 'a10.13_result', 'a10.14_result', 'a10.15_result', 'a11.0_q', 'a11.1_q', 'a11.2_q', 'a11.3_q', 'a11.4_q', 'a11.5_q', 'a11.6_q', 'a11.7_q', 'a11.8_q', 'a11.9_q', 'a11.10_q', 'a11.11_q', 'a11.12_q', 'a11.13_q', 'a11.14_q', 'a11.15_q', 'a11.0_k', 'a11.1_k', 'a11.2_k', 'a11.3_k', 'a11.4_k', 'a11.5_k', 'a11.6_k', 'a11.7_k', 'a11.8_k', 'a11.9_k', 'a11.10_k', 'a11.11_k', 'a11.12_k', 'a11.13_k', 'a11.14_k', 'a11.15_k', 'a11.0_v', 'a11.1_v', 'a11.2_v', 'a11.3_v', 'a11.4_v', 'a11.5_v', 'a11.6_v', 'a11.7_v', 'a11.8_v', 'a11.9_v', 'a11.10_v', 'a11.11_v', 'a11.12_v', 'a11.13_v', 'a11.14_v', 'a11.15_v', 'a11.0_result', 'a11.1_result', 'a11.2_result', 'a11.3_result', 'a11.4_result', 'a11.5_result', 'a11.6_result', 'a11.7_result', 'a11.8_result', 'a11.9_result', 'a11.10_result', 'a11.11_result', 'a11.12_result', 'a11.13_result', 'a11.14_result', 'a11.15_result', 'a12.0_q', 'a12.1_q', 'a12.2_q', 'a12.3_q', 'a12.4_q', 'a12.5_q', 'a12.6_q', 'a12.7_q', 'a12.8_q', 'a12.9_q', 'a12.10_q', 'a12.11_q', 'a12.12_q', 'a12.13_q', 'a12.14_q', 'a12.15_q', 'a12.0_k', 'a12.1_k', 'a12.2_k', 'a12.3_k', 'a12.4_k', 'a12.5_k', 'a12.6_k', 'a12.7_k', 'a12.8_k', 'a12.9_k', 'a12.10_k', 'a12.11_k', 'a12.12_k', 'a12.13_k', 'a12.14_k', 'a12.15_k', 'a12.0_v', 'a12.1_v', 'a12.2_v', 'a12.3_v', 'a12.4_v', 'a12.5_v', 'a12.6_v', 'a12.7_v', 'a12.8_v', 'a12.9_v', 'a12.10_v', 'a12.11_v', 'a12.12_v', 'a12.13_v', 'a12.14_v', 'a12.15_v', 'a12.0_result', 'a12.1_result', 'a12.2_result', 'a12.3_result', 'a12.4_result', 'a12.5_result', 'a12.6_result', 'a12.7_result', 'a12.8_result', 'a12.9_result', 'a12.10_result', 'a12.11_result', 'a12.12_result', 'a12.13_result', 'a12.14_result', 'a12.15_result', 'a13.0_q', 'a13.1_q', 'a13.2_q', 'a13.3_q', 'a13.4_q', 'a13.5_q', 'a13.6_q', 'a13.7_q', 'a13.8_q', 'a13.9_q', 'a13.10_q', 'a13.11_q', 'a13.12_q', 'a13.13_q', 'a13.14_q', 'a13.15_q', 'a13.0_k', 'a13.1_k', 'a13.2_k', 'a13.3_k', 'a13.4_k', 'a13.5_k', 'a13.6_k', 'a13.7_k', 'a13.8_k', 'a13.9_k', 'a13.10_k', 'a13.11_k', 'a13.12_k', 'a13.13_k', 'a13.14_k', 'a13.15_k', 'a13.0_v', 'a13.1_v', 'a13.2_v', 'a13.3_v', 'a13.4_v', 'a13.5_v', 'a13.6_v', 'a13.7_v', 'a13.8_v', 'a13.9_v', 'a13.10_v', 'a13.11_v', 'a13.12_v', 'a13.13_v', 'a13.14_v', 'a13.15_v', 'a13.0_result', 'a13.1_result', 'a13.2_result', 'a13.3_result', 'a13.4_result', 'a13.5_result', 'a13.6_result', 'a13.7_result', 'a13.8_result', 'a13.9_result', 'a13.10_result', 'a13.11_result', 'a13.12_result', 'a13.13_result', 'a13.14_result', 'a13.15_result', 'a14.0_q', 'a14.1_q', 'a14.2_q', 'a14.3_q', 'a14.4_q', 'a14.5_q', 'a14.6_q', 'a14.7_q', 'a14.8_q', 'a14.9_q', 'a14.10_q', 'a14.11_q', 'a14.12_q', 'a14.13_q', 'a14.14_q', 'a14.15_q', 'a14.0_k', 'a14.1_k', 'a14.2_k', 'a14.3_k', 'a14.4_k', 'a14.5_k', 'a14.6_k', 'a14.7_k', 'a14.8_k', 'a14.9_k', 'a14.10_k', 'a14.11_k', 'a14.12_k', 'a14.13_k', 'a14.14_k', 'a14.15_k', 'a14.0_v', 'a14.1_v', 'a14.2_v', 'a14.3_v', 'a14.4_v', 'a14.5_v', 'a14.6_v', 'a14.7_v', 'a14.8_v', 'a14.9_v', 'a14.10_v', 'a14.11_v', 'a14.12_v', 'a14.13_v', 'a14.14_v', 'a14.15_v', 'a14.0_result', 'a14.1_result', 'a14.2_result', 'a14.3_result', 'a14.4_result', 'a14.5_result', 'a14.6_result', 'a14.7_result', 'a14.8_result', 'a14.9_result', 'a14.10_result', 'a14.11_result', 'a14.12_result', 'a14.13_result', 'a14.14_result', 'a14.15_result', 'a15.0_q', 'a15.1_q', 'a15.2_q', 'a15.3_q', 'a15.4_q', 'a15.5_q', 'a15.6_q', 'a15.7_q', 'a15.8_q', 'a15.9_q', 'a15.10_q', 'a15.11_q', 'a15.12_q', 'a15.13_q', 'a15.14_q', 'a15.15_q', 'a15.0_k', 'a15.1_k', 'a15.2_k', 'a15.3_k', 'a15.4_k', 'a15.5_k', 'a15.6_k', 'a15.7_k', 'a15.8_k', 'a15.9_k', 'a15.10_k', 'a15.11_k', 'a15.12_k', 'a15.13_k', 'a15.14_k', 'a15.15_k', 'a15.0_v', 'a15.1_v', 'a15.2_v', 'a15.3_v', 'a15.4_v', 'a15.5_v', 'a15.6_v', 'a15.7_v', 'a15.8_v', 'a15.9_v', 'a15.10_v', 'a15.11_v', 'a15.12_v', 'a15.13_v', 'a15.14_v', 'a15.15_v', 'a15.0_result', 'a15.1_result', 'a15.2_result', 'a15.3_result', 'a15.4_result', 'a15.5_result', 'a15.6_result', 'a15.7_result', 'a15.8_result', 'a15.9_result', 'a15.10_result', 'a15.11_result', 'a15.12_result', 'a15.13_result', 'a15.14_result', 'a15.15_result', 'a16.0_q', 'a16.1_q', 'a16.2_q', 'a16.3_q', 'a16.4_q', 'a16.5_q', 'a16.6_q', 'a16.7_q', 'a16.8_q', 'a16.9_q', 'a16.10_q', 'a16.11_q', 'a16.12_q', 'a16.13_q', 'a16.14_q', 'a16.15_q', 'a16.0_k', 'a16.1_k', 'a16.2_k', 'a16.3_k', 'a16.4_k', 'a16.5_k', 'a16.6_k', 'a16.7_k', 'a16.8_k', 'a16.9_k', 'a16.10_k', 'a16.11_k', 'a16.12_k', 'a16.13_k', 'a16.14_k', 'a16.15_k', 'a16.0_v', 'a16.1_v', 'a16.2_v', 'a16.3_v', 'a16.4_v', 'a16.5_v', 'a16.6_v', 'a16.7_v', 'a16.8_v', 'a16.9_v', 'a16.10_v', 'a16.11_v', 'a16.12_v', 'a16.13_v', 'a16.14_v', 'a16.15_v', 'a16.0_result', 'a16.1_result', 'a16.2_result', 'a16.3_result', 'a16.4_result', 'a16.5_result', 'a16.6_result', 'a16.7_result', 'a16.8_result', 'a16.9_result', 'a16.10_result', 'a16.11_result', 'a16.12_result', 'a16.13_result', 'a16.14_result', 'a16.15_result', 'a17.0_q', 'a17.1_q', 'a17.2_q', 'a17.3_q', 'a17.4_q', 'a17.5_q', 'a17.6_q', 'a17.7_q', 'a17.8_q', 'a17.9_q', 'a17.10_q', 'a17.11_q', 'a17.12_q', 'a17.13_q', 'a17.14_q', 'a17.15_q', 'a17.0_k', 'a17.1_k', 'a17.2_k', 'a17.3_k', 'a17.4_k', 'a17.5_k', 'a17.6_k', 'a17.7_k', 'a17.8_k', 'a17.9_k', 'a17.10_k', 'a17.11_k', 'a17.12_k', 'a17.13_k', 'a17.14_k', 'a17.15_k', 'a17.0_v', 'a17.1_v', 'a17.2_v', 'a17.3_v', 'a17.4_v', 'a17.5_v', 'a17.6_v', 'a17.7_v', 'a17.8_v', 'a17.9_v', 'a17.10_v', 'a17.11_v', 'a17.12_v', 'a17.13_v', 'a17.14_v', 'a17.15_v', 'a17.0_result', 'a17.1_result', 'a17.2_result', 'a17.3_result', 'a17.4_result', 'a17.5_result', 'a17.6_result', 'a17.7_result', 'a17.8_result', 'a17.9_result', 'a17.10_result', 'a17.11_result', 'a17.12_result', 'a17.13_result', 'a17.14_result', 'a17.15_result', 'a18.0_q', 'a18.1_q', 'a18.2_q', 'a18.3_q', 'a18.4_q', 'a18.5_q', 'a18.6_q', 'a18.7_q', 'a18.8_q', 'a18.9_q', 'a18.10_q', 'a18.11_q', 'a18.12_q', 'a18.13_q', 'a18.14_q', 'a18.15_q', 'a18.0_k', 'a18.1_k', 'a18.2_k', 'a18.3_k', 'a18.4_k', 'a18.5_k', 'a18.6_k', 'a18.7_k', 'a18.8_k', 'a18.9_k', 'a18.10_k', 'a18.11_k', 'a18.12_k', 'a18.13_k', 'a18.14_k', 'a18.15_k', 'a18.0_v', 'a18.1_v', 'a18.2_v', 'a18.3_v', 'a18.4_v', 'a18.5_v', 'a18.6_v', 'a18.7_v', 'a18.8_v', 'a18.9_v', 'a18.10_v', 'a18.11_v', 'a18.12_v', 'a18.13_v', 'a18.14_v', 'a18.15_v', 'a18.0_result', 'a18.1_result', 'a18.2_result', 'a18.3_result', 'a18.4_result', 'a18.5_result', 'a18.6_result', 'a18.7_result', 'a18.8_result', 'a18.9_result', 'a18.10_result', 'a18.11_result', 'a18.12_result', 'a18.13_result', 'a18.14_result', 'a18.15_result', 'a19.0_q', 'a19.1_q', 'a19.2_q', 'a19.3_q', 'a19.4_q', 'a19.5_q', 'a19.6_q', 'a19.7_q', 'a19.8_q', 'a19.9_q', 'a19.10_q', 'a19.11_q', 'a19.12_q', 'a19.13_q', 'a19.14_q', 'a19.15_q', 'a19.0_k', 'a19.1_k', 'a19.2_k', 'a19.3_k', 'a19.4_k', 'a19.5_k', 'a19.6_k', 'a19.7_k', 'a19.8_k', 'a19.9_k', 'a19.10_k', 'a19.11_k', 'a19.12_k', 'a19.13_k', 'a19.14_k', 'a19.15_k', 'a19.0_v', 'a19.1_v', 'a19.2_v', 'a19.3_v', 'a19.4_v', 'a19.5_v', 'a19.6_v', 'a19.7_v', 'a19.8_v', 'a19.9_v', 'a19.10_v', 'a19.11_v', 'a19.12_v', 'a19.13_v', 'a19.14_v', 'a19.15_v', 'a19.0_result', 'a19.1_result', 'a19.2_result', 'a19.3_result', 'a19.4_result', 'a19.5_result', 'a19.6_result', 'a19.7_result', 'a19.8_result', 'a19.9_result', 'a19.10_result', 'a19.11_result', 'a19.12_result', 'a19.13_result', 'a19.14_result', 'a19.15_result', 'a20.0_q', 'a20.1_q', 'a20.2_q', 'a20.3_q', 'a20.4_q', 'a20.5_q', 'a20.6_q', 'a20.7_q', 'a20.8_q', 'a20.9_q', 'a20.10_q', 'a20.11_q', 'a20.12_q', 'a20.13_q', 'a20.14_q', 'a20.15_q', 'a20.0_k', 'a20.1_k', 'a20.2_k', 'a20.3_k', 'a20.4_k', 'a20.5_k', 'a20.6_k', 'a20.7_k', 'a20.8_k', 'a20.9_k', 'a20.10_k', 'a20.11_k', 'a20.12_k', 'a20.13_k', 'a20.14_k', 'a20.15_k', 'a20.0_v', 'a20.1_v', 'a20.2_v', 'a20.3_v', 'a20.4_v', 'a20.5_v', 'a20.6_v', 'a20.7_v', 'a20.8_v', 'a20.9_v', 'a20.10_v', 'a20.11_v', 'a20.12_v', 'a20.13_v', 'a20.14_v', 'a20.15_v', 'a20.0_result', 'a20.1_result', 'a20.2_result', 'a20.3_result', 'a20.4_result', 'a20.5_result', 'a20.6_result', 'a20.7_result', 'a20.8_result', 'a20.9_result', 'a20.10_result', 'a20.11_result', 'a20.12_result', 'a20.13_result', 'a20.14_result', 'a20.15_result', 'a21.0_q', 'a21.1_q', 'a21.2_q', 'a21.3_q', 'a21.4_q', 'a21.5_q', 'a21.6_q', 'a21.7_q', 'a21.8_q', 'a21.9_q', 'a21.10_q', 'a21.11_q', 'a21.12_q', 'a21.13_q', 'a21.14_q', 'a21.15_q', 'a21.0_k', 'a21.1_k', 'a21.2_k', 'a21.3_k', 'a21.4_k', 'a21.5_k', 'a21.6_k', 'a21.7_k', 'a21.8_k', 'a21.9_k', 'a21.10_k', 'a21.11_k', 'a21.12_k', 'a21.13_k', 'a21.14_k', 'a21.15_k', 'a21.0_v', 'a21.1_v', 'a21.2_v', 'a21.3_v', 'a21.4_v', 'a21.5_v', 'a21.6_v', 'a21.7_v', 'a21.8_v', 'a21.9_v', 'a21.10_v', 'a21.11_v', 'a21.12_v', 'a21.13_v', 'a21.14_v', 'a21.15_v', 'a21.0_result', 'a21.1_result', 'a21.2_result', 'a21.3_result', 'a21.4_result', 'a21.5_result', 'a21.6_result', 'a21.7_result', 'a21.8_result', 'a21.9_result', 'a21.10_result', 'a21.11_result', 'a21.12_result', 'a21.13_result', 'a21.14_result', 'a21.15_result', 'a22.0_q', 'a22.1_q', 'a22.2_q', 'a22.3_q', 'a22.4_q', 'a22.5_q', 'a22.6_q', 'a22.7_q', 'a22.8_q', 'a22.9_q', 'a22.10_q', 'a22.11_q', 'a22.12_q', 'a22.13_q', 'a22.14_q', 'a22.15_q', 'a22.0_k', 'a22.1_k', 'a22.2_k', 'a22.3_k', 'a22.4_k', 'a22.5_k', 'a22.6_k', 'a22.7_k', 'a22.8_k', 'a22.9_k', 'a22.10_k', 'a22.11_k', 'a22.12_k', 'a22.13_k', 'a22.14_k', 'a22.15_k', 'a22.0_v', 'a22.1_v', 'a22.2_v', 'a22.3_v', 'a22.4_v', 'a22.5_v', 'a22.6_v', 'a22.7_v', 'a22.8_v', 'a22.9_v', 'a22.10_v', 'a22.11_v', 'a22.12_v', 'a22.13_v', 'a22.14_v', 'a22.15_v', 'a22.0_result', 'a22.1_result', 'a22.2_result', 'a22.3_result', 'a22.4_result', 'a22.5_result', 'a22.6_result', 'a22.7_result', 'a22.8_result', 'a22.9_result', 'a22.10_result', 'a22.11_result', 'a22.12_result', 'a22.13_result', 'a22.14_result', 'a22.15_result', 'a23.0_q', 'a23.1_q', 'a23.2_q', 'a23.3_q', 'a23.4_q', 'a23.5_q', 'a23.6_q', 'a23.7_q', 'a23.8_q', 'a23.9_q', 'a23.10_q', 'a23.11_q', 'a23.12_q', 'a23.13_q', 'a23.14_q', 'a23.15_q', 'a23.0_k', 'a23.1_k', 'a23.2_k', 'a23.3_k', 'a23.4_k', 'a23.5_k', 'a23.6_k', 'a23.7_k', 'a23.8_k', 'a23.9_k', 'a23.10_k', 'a23.11_k', 'a23.12_k', 'a23.13_k', 'a23.14_k', 'a23.15_k', 'a23.0_v', 'a23.1_v', 'a23.2_v', 'a23.3_v', 'a23.4_v', 'a23.5_v', 'a23.6_v', 'a23.7_v', 'a23.8_v', 'a23.9_v', 'a23.10_v', 'a23.11_v', 'a23.12_v', 'a23.13_v', 'a23.14_v', 'a23.15_v', 'a23.0_result', 'a23.1_result', 'a23.2_result', 'a23.3_result', 'a23.4_result', 'a23.5_result', 'a23.6_result', 'a23.7_result', 'a23.8_result', 'a23.9_result', 'a23.10_result', 'a23.11_result', 'a23.12_result', 'a23.13_result', 'a23.14_result', 'a23.15_result', 'a24.0_q', 'a24.1_q', 'a24.2_q', 'a24.3_q', 'a24.4_q', 'a24.5_q', 'a24.6_q', 'a24.7_q', 'a24.8_q', 'a24.9_q', 'a24.10_q', 'a24.11_q', 'a24.12_q', 'a24.13_q', 'a24.14_q', 'a24.15_q', 'a24.0_k', 'a24.1_k', 'a24.2_k', 'a24.3_k', 'a24.4_k', 'a24.5_k', 'a24.6_k', 'a24.7_k', 'a24.8_k', 'a24.9_k', 'a24.10_k', 'a24.11_k', 'a24.12_k', 'a24.13_k', 'a24.14_k', 'a24.15_k', 'a24.0_v', 'a24.1_v', 'a24.2_v', 'a24.3_v', 'a24.4_v', 'a24.5_v', 'a24.6_v', 'a24.7_v', 'a24.8_v', 'a24.9_v', 'a24.10_v', 'a24.11_v', 'a24.12_v', 'a24.13_v', 'a24.14_v', 'a24.15_v', 'a24.0_result', 'a24.1_result', 'a24.2_result', 'a24.3_result', 'a24.4_result', 'a24.5_result', 'a24.6_result', 'a24.7_result', 'a24.8_result', 'a24.9_result', 'a24.10_result', 'a24.11_result', 'a24.12_result', 'a24.13_result', 'a24.14_result', 'a24.15_result', 'a25.0_q', 'a25.1_q', 'a25.2_q', 'a25.3_q', 'a25.4_q', 'a25.5_q', 'a25.6_q', 'a25.7_q', 'a25.8_q', 'a25.9_q', 'a25.10_q', 'a25.11_q', 'a25.12_q', 'a25.13_q', 'a25.14_q', 'a25.15_q', 'a25.0_k', 'a25.1_k', 'a25.2_k', 'a25.3_k', 'a25.4_k', 'a25.5_k', 'a25.6_k', 'a25.7_k', 'a25.8_k', 'a25.9_k', 'a25.10_k', 'a25.11_k', 'a25.12_k', 'a25.13_k', 'a25.14_k', 'a25.15_k', 'a25.0_v', 'a25.1_v', 'a25.2_v', 'a25.3_v', 'a25.4_v', 'a25.5_v', 'a25.6_v', 'a25.7_v', 'a25.8_v', 'a25.9_v', 'a25.10_v', 'a25.11_v', 'a25.12_v', 'a25.13_v', 'a25.14_v', 'a25.15_v', 'a25.0_result', 'a25.1_result', 'a25.2_result', 'a25.3_result', 'a25.4_result', 'a25.5_result', 'a25.6_result', 'a25.7_result', 'a25.8_result', 'a25.9_result', 'a25.10_result', 'a25.11_result', 'a25.12_result', 'a25.13_result', 'a25.14_result', 'a25.15_result', 'a26.0_q', 'a26.1_q', 'a26.2_q', 'a26.3_q', 'a26.4_q', 'a26.5_q', 'a26.6_q', 'a26.7_q', 'a26.8_q', 'a26.9_q', 'a26.10_q', 'a26.11_q', 'a26.12_q', 'a26.13_q', 'a26.14_q', 'a26.15_q', 'a26.0_k', 'a26.1_k', 'a26.2_k', 'a26.3_k', 'a26.4_k', 'a26.5_k', 'a26.6_k', 'a26.7_k', 'a26.8_k', 'a26.9_k', 'a26.10_k', 'a26.11_k', 'a26.12_k', 'a26.13_k', 'a26.14_k', 'a26.15_k', 'a26.0_v', 'a26.1_v', 'a26.2_v', 'a26.3_v', 'a26.4_v', 'a26.5_v', 'a26.6_v', 'a26.7_v', 'a26.8_v', 'a26.9_v', 'a26.10_v', 'a26.11_v', 'a26.12_v', 'a26.13_v', 'a26.14_v', 'a26.15_v', 'a26.0_result', 'a26.1_result', 'a26.2_result', 'a26.3_result', 'a26.4_result', 'a26.5_result', 'a26.6_result', 'a26.7_result', 'a26.8_result', 'a26.9_result', 'a26.10_result', 'a26.11_result', 'a26.12_result', 'a26.13_result', 'a26.14_result', 'a26.15_result', 'a27.0_q', 'a27.1_q', 'a27.2_q', 'a27.3_q', 'a27.4_q', 'a27.5_q', 'a27.6_q', 'a27.7_q', 'a27.8_q', 'a27.9_q', 'a27.10_q', 'a27.11_q', 'a27.12_q', 'a27.13_q', 'a27.14_q', 'a27.15_q', 'a27.0_k', 'a27.1_k', 'a27.2_k', 'a27.3_k', 'a27.4_k', 'a27.5_k', 'a27.6_k', 'a27.7_k', 'a27.8_k', 'a27.9_k', 'a27.10_k', 'a27.11_k', 'a27.12_k', 'a27.13_k', 'a27.14_k', 'a27.15_k', 'a27.0_v', 'a27.1_v', 'a27.2_v', 'a27.3_v', 'a27.4_v', 'a27.5_v', 'a27.6_v', 'a27.7_v', 'a27.8_v', 'a27.9_v', 'a27.10_v', 'a27.11_v', 'a27.12_v', 'a27.13_v', 'a27.14_v', 'a27.15_v', 'a27.0_result', 'a27.1_result', 'a27.2_result', 'a27.3_result', 'a27.4_result', 'a27.5_result', 'a27.6_result', 'a27.7_result', 'a27.8_result', 'a27.9_result', 'a27.10_result', 'a27.11_result', 'a27.12_result', 'a27.13_result', 'a27.14_result', 'a27.15_result', 'm0_in', 'm0_out', 'm1_in', 'm1_out', 'm2_in', 'm2_out', 'm3_in', 'm3_out', 'm4_in', 'm4_out', 'm5_in', 'm5_out', 'm6_in', 'm6_out', 'm7_in', 'm7_out', 'm8_in', 'm8_out', 'm9_in', 'm9_out', 'm10_in', 'm10_out', 'm11_in', 'm11_out', 'm12_in', 'm12_out', 'm13_in', 'm13_out', 'm14_in', 'm14_out', 'm15_in', 'm15_out', 'm16_in', 'm16_out', 'm17_in', 'm17_out', 'm18_in', 'm18_out', 'm19_in', 'm19_out', 'm20_in', 'm20_out', 'm21_in', 'm21_out', 'm22_in', 'm22_out', 'm23_in', 'm23_out', 'm24_in', 'm24_out', 'm25_in', 'm25_out', 'm26_in', 'm26_out', 'm27_in', 'm27_out'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"models/google_gemma-7b_sports_all_ap_graph.pkl\", \"rb\") as f:\n",
    "    ap_graph = pickle.load(f)\n",
    "ap_graph.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55685bbc93d4c0fa4f4be8ab8b1a513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad4f66b2f424777a5473864d4727c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test dataset available. Using train dataset for testing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001270f808264a7b9f98b24fa7f6370d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f085c02aca404d887d10a7d3dc6422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test dataset available. Using train dataset for testing.\n"
     ]
    }
   ],
   "source": [
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "from tasks.facts.SportsTaskAdversarial import adversarial_sports_eval\n",
    "from tasks.facts.SportsTaskSideEffects import run_side_effects_evals\n",
    "\n",
    "\n",
    "train_batch_size = 8\n",
    "eval_batch_size=64\n",
    "\n",
    "device = \"cuda\"\n",
    "train_loss_type = \"sports\"\n",
    "forget_sport = \"basketball\"\n",
    "maintain_sport = None\n",
    "# val_sport = \"baseball\"\n",
    "\n",
    "\n",
    "sports_1mp = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"log_1_minus_p\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "\n",
    "if maintain_sport is None:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "else:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "\n",
    "train_pile = PileTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, ctx_length=256, shuffle=True, buffer_size=50000)\n",
    "train_tasks = {\"sports_1mp\": (sports_1mp, .2), \"maintain_sports\": (maintain_sports, 1), \"pile\": (train_pile, 1)}\n",
    "\n",
    "# want to eval on other sports\n",
    "forget_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=True)\n",
    "test_pile = PileTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "\n",
    "induction_eval = InductionTask(batch_size=eval_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, device=device)\n",
    "if maintain_sport is None:\n",
    "    maintain_sports_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={forget_sport}, is_forget_dataset=False)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sports_eval}\n",
    "else:\n",
    "    maintain_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "    val_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={val_sport}, is_forget_dataset=True)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": \n",
    "                  forget_sport_eval, \"maintain_sport\": maintain_sport_eval, \"val_sport\": val_sport_eval}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(all_attr_values)=168\n",
      "Thresholding importance at 0.20463522672653203\n",
      "(['blocks.18.attn.hook_result', 'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_post', 'blocks.23.mlp.hook_post', 'blocks.25.attn.hook_result', 'blocks.25.mlp.hook_pre', 'blocks.27.attn.hook_q', 'blocks.27.attn.hook_k', 'blocks.27.mlp.hook_post'], defaultdict(<class 'list'>, {'blocks.18.attn.hook_result': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'blocks.25.attn.hook_result': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'blocks.27.attn.hook_q': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'blocks.27.attn.hook_k': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}))\n",
      "Thresholding importance at 0.11414513221153846\n",
      "(['blocks.0.mlp.hook_pre', 'blocks.13.mlp.hook_pre', 'blocks.19.mlp.hook_pre', 'blocks.20.mlp.hook_post', 'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_post', 'blocks.22.mlp.hook_post', 'blocks.23.mlp.hook_pre', 'blocks.23.mlp.hook_post', 'blocks.25.mlp.hook_pre', 'blocks.25.mlp.hook_post', 'blocks.26.mlp.hook_post', 'blocks.27.mlp.hook_post', 'blocks.17.attn.hook_v', 'blocks.18.attn.hook_v', 'blocks.18.attn.hook_result', 'blocks.20.attn.hook_v', 'blocks.20.attn.hook_result', 'blocks.27.attn.hook_q', 'blocks.27.attn.hook_k'], defaultdict(<class 'list'>, {'blocks.17.attn.hook_v': [7], 'blocks.18.attn.hook_v': [11], 'blocks.18.attn.hook_result': [11], 'blocks.20.attn.hook_v': [5], 'blocks.20.attn.hook_result': [5], 'blocks.27.attn.hook_q': [1], 'blocks.27.attn.hook_k': [1]}))\n"
     ]
    }
   ],
   "source": [
    "def convert_attrs_to_components(attrs, combine_heads=False, n_layers=model.cfg.n_layers, n_heads=model.cfg.n_heads):\n",
    "    \"\"\"\n",
    "    attrs is dictionary of e.g. {'a0.0_q': float, 'm27_in': float}\n",
    "\n",
    "    If combine_heads, then it will combine all 'a0.0_q', 'a0.1_q', ..., 'a0.15_q', etc into one component.\n",
    "    \"\"\"\n",
    "\n",
    "    component_dict = defaultdict(int)\n",
    "    attn_head_dict = defaultdict(dict)\n",
    "    for layer in range(n_layers):\n",
    "        for attn_type, component_name in [(\"q\", f\"blocks.{layer}.attn.hook_q\"), (\"k\", f\"blocks.{layer}.attn.hook_k\"), (\"v\", f\"blocks.{layer}.attn.hook_v\"), (\"result\", f\"blocks.{layer}.attn.hook_result\")]:\n",
    "            for head in range(n_heads):    \n",
    "                if combine_heads:\n",
    "                    component_dict[component_name] += attrs[f\"a{layer}.{head}_{attn_type}\"]\n",
    "                else:\n",
    "                    attn_head_dict[component_name][head] = attrs[f\"a{layer}.{head}_{attn_type}\"]\n",
    "        for mlp_type, component_name in [(\"in\", f\"blocks.{layer}.mlp.hook_pre\"), (\"out\", f\"blocks.{layer}.mlp.hook_post\")]:\n",
    "            component_dict[component_name] += attrs[f\"m{layer}_{mlp_type}\"]\n",
    "    if combine_heads:\n",
    "        return (component_dict,)\n",
    "    return (component_dict, attn_head_dict,)\n",
    "\n",
    "\n",
    "def get_top_components(component_dict, attn_head_dict=None, threshold=None, top_p=None, top_k=None, use_abs=True, n_layers=model.cfg.n_layers, n_heads=model.cfg.n_heads):\n",
    "    \"\"\"\n",
    "    component_dict is a dictionary of components to their importance values. If attn_head_dict is not None, then component_dict and attn_head_dict should not overlap in values.\n",
    "\n",
    "    Can either use a threshold, top_p, or top_k to determine the top components to return (can only specify one). top_p should be a value ranging from 0 to 100. If use_abs is True, then it will take the absolute value of the importance values. \n",
    "    \"\"\"\n",
    "    if attn_head_dict is not None:\n",
    "        assert (component_dict.keys() & attn_head_dict.keys()) == set(), \"Overlapping keys between component_dict and attn_head_dict\"\n",
    "    \n",
    "    # assert only one of threshold, top_p, top_k is specified\n",
    "    assert sum([threshold is not None, top_p is not None, top_k is not None]) == 1, \"Can only specify one of threshold, top_p, top_k\"\n",
    "    # will calculate a threshold for top_p or top_k\n",
    "\n",
    "    if top_p is not None:\n",
    "        all_attr_values = list(component_dict.values())\n",
    "        if attn_head_dict is not None:\n",
    "            all_attr_values += [val for head_dict in attn_head_dict.values() for val in head_dict.values()]\n",
    "\n",
    "        all_attr_values = np.array(all_attr_values)\n",
    "        if use_abs:\n",
    "            all_attr_values = np.abs(all_attr_values)\n",
    "        print(f\"{len(all_attr_values)=}\")\n",
    "        threshold = np.percentile(all_attr_values, 100 - top_p)\n",
    "    elif top_k is not None:\n",
    "        all_attr_values = list(component_dict.values())\n",
    "        if attn_head_dict is not None:\n",
    "            all_attr_values += [val for head_dict in attn_head_dict.values() for val in head_dict.values()]\n",
    "\n",
    "        all_attr_values = np.array(all_attr_values)\n",
    "        if use_abs:\n",
    "            all_attr_values = np.abs(all_attr_values)\n",
    "        threshold = np.sort(all_attr_values)[-top_k]\n",
    "    \n",
    "    print(f\"Thresholding importance at {threshold}\")\n",
    "    final_components = []\n",
    "    final_attn_heads = defaultdict(list)\n",
    "\n",
    "    for component, importance in component_dict.items():\n",
    "        if use_abs:\n",
    "            importance = abs(importance)\n",
    "        if importance >= threshold:\n",
    "            final_components.append(component)    \n",
    "\n",
    "    if attn_head_dict is not None:\n",
    "        for component, head_dict in attn_head_dict.items():\n",
    "            head_list = []\n",
    "            for head, importance in head_dict.items():\n",
    "                if use_abs:\n",
    "                    importance = abs(importance)\n",
    "                if importance >= threshold:\n",
    "                    head_list.append(head)\n",
    "            if len(head_list) > 0:\n",
    "                final_attn_heads[component] = head_list\n",
    "                final_components.append(component)\n",
    "    else:\n",
    "        for component in final_components:\n",
    "            if \"attn\" in component:\n",
    "                # want to mask over all possible heads\n",
    "                final_attn_heads[component] = list(range(n_heads))\n",
    "    \n",
    "    return final_components, final_attn_heads\n",
    "print(get_top_components(*convert_attrs_to_components(ap_graph, combine_heads=True), top_p=5))\n",
    "print(get_top_components(*convert_attrs_to_components(ap_graph, combine_heads=False), top_k=20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(all_attr_values)=1848\n",
      "Thresholding importance at 5.498310177004622e-15\n",
      "168\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "use_localized_mask = False\n",
    "\n",
    "combine_heads = False\n",
    "top_p = 5\n",
    "\n",
    "if use_localized_mask:\n",
    "    final_components, final_attn_heads = get_top_components(*convert_attrs_to_components(ap_graph, combine_heads=combine_heads), top_p=top_p)\n",
    "\n",
    "    print(final_components)\n",
    "    print(final_attn_heads)\n",
    "\n",
    "    mask = NeuronLevelMask(model, components=final_components, component_heads=final_attn_heads)\n",
    "\n",
    "else:\n",
    "    all_components, all_attn_heads = get_top_components(*convert_attrs_to_components(ap_graph, combine_heads=combine_heads), top_p=100)\n",
    "    print(len(all_components))\n",
    "    print(len(all_attn_heads))\n",
    "    assert (torch.tensor([len(x) for x in all_attn_heads.values()]) == model.cfg.n_heads).all()\n",
    "\n",
    "    mask = NeuronLevelMask(model, components=all_components, component_heads=all_attn_heads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dda8c40a27c45d4ae4233ff8bd32e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running adversarial evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running adversarial evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running adversarial evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running adversarial evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running adversarial evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running adversarial evals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# mask = MLPHiddenMask(model).cuda()\n",
    "\n",
    "learning_rate = 5e-2\n",
    "n_epochs = 50\n",
    "grad_accum_steps = 16\n",
    "# max_gpu_batch_size=8\n",
    "beta = 10\n",
    "clip_grad = 1\n",
    "\n",
    "evaluate_every = 5\n",
    "n_eval_iters = 5\n",
    "deep_evaluate_every = 10\n",
    "do_adversarial_evals = True\n",
    "do_side_effects_evals = False\n",
    "\n",
    "from collections import defaultdict\n",
    "all_train_losses = defaultdict(list)\n",
    "all_test_losses = defaultdict(list)\n",
    "adversarial_evals = []\n",
    "side_effect_evals = []\n",
    "mask.cuda()\n",
    "\n",
    "# Initialize optimizer\n",
    "\n",
    "optimizer = torch.optim.AdamW(mask.parameters(), lr=learning_rate, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=n_epochs)\n",
    "# Cycle dataloaders\n",
    "# Train a sparse mask\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    # Sample batches\n",
    "    # Reset grad\n",
    "    optimizer.zero_grad()\n",
    "    # Compute normal loss over retain\n",
    "    for task_name, (task, task_weight) in train_tasks.items():\n",
    "        task_loss = 0\n",
    "        for i in range(grad_accum_steps):\n",
    "            loss = task.get_train_loss(model) / grad_accum_steps\n",
    "            task_loss += loss.item()\n",
    "            loss *= task_weight\n",
    "            loss.backward()\n",
    "        all_train_losses[task_name].append(task_loss)\n",
    "        \n",
    "    # Add sparsity loss and backprop\n",
    "    loss = beta * mask.regularization_loss()\n",
    "    loss.backward()\n",
    "    all_train_losses[\"reg\"].append(loss.item())\n",
    "    # Step and log\n",
    "    if clip_grad is not None:\n",
    "        torch.nn.utils.clip_grad_norm_(mask.parameters(), clip_grad)\n",
    "    # zero_nan_grads(mask)\n",
    "    optimizer.step()\n",
    "    mask.on_step_end()\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % evaluate_every == 0 or epoch == n_epochs - 1:\n",
    "        for task_name, task in eval_tasks.items():\n",
    "            task_loss = 0\n",
    "            for i in range(n_eval_iters):\n",
    "                task_loss += task.get_test_loss(model).item()\n",
    "            all_test_losses[task_name].append(task_loss / n_eval_iters)\n",
    "    if epoch % deep_evaluate_every == 0 or epoch == n_epochs - 1:\n",
    "        if do_adversarial_evals:\n",
    "            print(\"Running adversarial evals\")\n",
    "            adversarial_evals.append(adversarial_sports_eval(model, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=True))\n",
    "        if do_side_effects_evals:\n",
    "            print(\"Running side effects evals\")\n",
    "            side_effect_evals.append(run_side_effects_evals(model, model_type=model_type, batch_size=eval_batch_size, evals_to_run=[\"Sports Answers\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save masks state dict to neuron_cb\n",
    "import pickle\n",
    "torch.save(mask.state_dict(), f\"masks/neuron_cb/{model_type}_{'localized' if use_localized_mask else 'nonlocalized'}_{combine_heads=}_unlearn_{forget_sport}.pt\")\n",
    "\n",
    "with open(f\"masks/neuron_cb/{model_type}_{'localized' if use_localized_mask else 'nonlocalized'}_{combine_heads=}_unlearn_{forget_sport}_metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"train_losses\": all_train_losses, \"test_losses\": all_test_losses, \"adversarial_evals\": adversarial_evals, \"side_effect_evals\": side_effect_evals}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9e07bfa7be498580c6267050263ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-7b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "localized_model = model\n",
    "nonlocalized_model = HookedTransformer.from_pretrained(\n",
    "    'google/gemma-7b',\n",
    "    tokenizer=tokenizer,\n",
    "    device='cuda',\n",
    "    default_padding_side=\"right\",\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    center_writing_weights=False,\n",
    "    dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "nonlocalized_model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(all_attr_values)=1848\n",
      "Thresholding importance at 0.0332934452937199\n",
      "['blocks.0.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.2.mlp.hook_post', 'blocks.4.mlp.hook_pre', 'blocks.5.mlp.hook_pre', 'blocks.10.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.12.mlp.hook_pre', 'blocks.12.mlp.hook_post', 'blocks.13.mlp.hook_pre', 'blocks.13.mlp.hook_post', 'blocks.14.mlp.hook_pre', 'blocks.14.mlp.hook_post', 'blocks.15.mlp.hook_pre', 'blocks.15.mlp.hook_post', 'blocks.16.mlp.hook_pre', 'blocks.17.mlp.hook_post', 'blocks.18.mlp.hook_pre', 'blocks.18.mlp.hook_post', 'blocks.19.mlp.hook_pre', 'blocks.20.mlp.hook_pre', 'blocks.20.mlp.hook_post', 'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_post', 'blocks.22.mlp.hook_pre', 'blocks.22.mlp.hook_post', 'blocks.23.mlp.hook_pre', 'blocks.23.mlp.hook_post', 'blocks.24.mlp.hook_pre', 'blocks.24.mlp.hook_post', 'blocks.25.mlp.hook_pre', 'blocks.25.mlp.hook_post', 'blocks.26.mlp.hook_pre', 'blocks.26.mlp.hook_post', 'blocks.27.mlp.hook_pre', 'blocks.27.mlp.hook_post', 'blocks.14.attn.hook_q', 'blocks.14.attn.hook_k', 'blocks.15.attn.hook_v', 'blocks.15.attn.hook_result', 'blocks.16.attn.hook_v', 'blocks.16.attn.hook_result', 'blocks.17.attn.hook_k', 'blocks.17.attn.hook_v', 'blocks.17.attn.hook_result', 'blocks.18.attn.hook_k', 'blocks.18.attn.hook_v', 'blocks.18.attn.hook_result', 'blocks.19.attn.hook_k', 'blocks.19.attn.hook_v', 'blocks.19.attn.hook_result', 'blocks.20.attn.hook_k', 'blocks.20.attn.hook_v', 'blocks.20.attn.hook_result', 'blocks.21.attn.hook_q', 'blocks.21.attn.hook_v', 'blocks.21.attn.hook_result', 'blocks.22.attn.hook_k', 'blocks.22.attn.hook_v', 'blocks.22.attn.hook_result', 'blocks.23.attn.hook_v', 'blocks.24.attn.hook_v', 'blocks.24.attn.hook_result', 'blocks.25.attn.hook_v', 'blocks.25.attn.hook_result', 'blocks.26.attn.hook_v', 'blocks.27.attn.hook_q', 'blocks.27.attn.hook_k', 'blocks.27.attn.hook_v', 'blocks.27.attn.hook_result']\n",
      "defaultdict(<class 'list'>, {'blocks.14.attn.hook_q': [8], 'blocks.14.attn.hook_k': [14], 'blocks.15.attn.hook_v': [10], 'blocks.15.attn.hook_result': [10], 'blocks.16.attn.hook_v': [0, 8], 'blocks.16.attn.hook_result': [0, 5, 8], 'blocks.17.attn.hook_k': [7, 13], 'blocks.17.attn.hook_v': [2, 7, 8, 9], 'blocks.17.attn.hook_result': [7, 8], 'blocks.18.attn.hook_k': [4, 9], 'blocks.18.attn.hook_v': [4, 9, 11], 'blocks.18.attn.hook_result': [4, 11], 'blocks.19.attn.hook_k': [1], 'blocks.19.attn.hook_v': [1, 3, 10], 'blocks.19.attn.hook_result': [1, 3, 10], 'blocks.20.attn.hook_k': [2], 'blocks.20.attn.hook_v': [2, 5], 'blocks.20.attn.hook_result': [2, 5], 'blocks.21.attn.hook_q': [4], 'blocks.21.attn.hook_v': [4], 'blocks.21.attn.hook_result': [4], 'blocks.22.attn.hook_k': [15], 'blocks.22.attn.hook_v': [15], 'blocks.22.attn.hook_result': [15], 'blocks.23.attn.hook_v': [2], 'blocks.24.attn.hook_v': [12], 'blocks.24.attn.hook_result': [12], 'blocks.25.attn.hook_v': [8, 9], 'blocks.25.attn.hook_result': [8, 9], 'blocks.26.attn.hook_v': [7], 'blocks.27.attn.hook_q': [1], 'blocks.27.attn.hook_k': [1], 'blocks.27.attn.hook_v': [1, 3, 10], 'blocks.27.attn.hook_result': [3, 10]})\n",
      "len(all_attr_values)=1848\n",
      "Thresholding importance at 5.498310177004622e-15\n",
      "168\n",
      "112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuronLevelMask(\n",
       "  (masks): ParameterDict(\n",
       "      (blocks&0&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&0&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&1&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&1&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&2&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&2&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&3&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&3&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&4&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&4&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&5&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&5&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&6&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&6&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&7&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&7&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&8&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&8&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&9&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&9&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&10&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&10&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&11&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&11&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&12&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&12&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&13&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&13&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&14&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&14&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&15&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&15&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&16&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&16&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&17&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&17&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&18&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&18&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&19&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&19&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&20&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&20&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&21&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&21&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&22&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&22&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&23&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&23&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&24&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&24&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&25&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&25&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&26&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&26&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&27&mlp&hook_pre): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&27&mlp&hook_post): Parameter containing: [torch.cuda.FloatTensor of size 24576 (cuda:0)]\n",
       "      (blocks&0&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&0&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&0&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&0&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&1&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&1&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&1&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&1&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&2&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&2&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&2&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&2&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&3&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&3&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&3&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&3&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&4&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&4&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&4&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&4&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&5&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&5&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&5&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&5&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&6&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&6&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&6&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&6&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&7&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&7&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&7&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&7&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&8&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&8&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&8&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&8&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&9&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&9&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&9&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&9&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&10&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&10&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&10&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&10&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&11&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&11&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&11&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&11&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&12&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&12&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&12&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&12&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&13&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&13&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&13&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&13&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&14&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&14&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&14&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&14&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&15&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&15&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&15&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&15&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&16&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&16&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&16&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&16&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&17&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&17&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&17&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&17&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&18&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&18&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&18&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&18&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&19&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&19&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&19&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&19&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&20&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&20&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&20&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&20&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&21&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&21&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&21&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&21&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&22&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&22&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&22&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&22&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&23&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&23&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&23&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&23&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&24&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&24&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&24&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&24&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&25&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&25&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&25&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&25&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&26&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&26&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&26&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&26&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "      (blocks&27&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&27&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&27&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x256 (cuda:0)]\n",
       "      (blocks&27&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x3072 (cuda:0)]\n",
       "  )\n",
       "  (attn_mask_frozen): ParameterDict(\n",
       "      (blocks&0&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&0&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&0&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&0&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&1&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&1&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&1&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&1&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&2&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&2&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&2&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&2&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&3&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&3&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&3&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&3&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&4&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&4&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&4&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&4&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&5&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&5&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&5&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&5&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&6&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&6&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&6&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&6&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&7&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&7&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&7&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&7&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&8&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&8&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&8&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&8&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&9&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&9&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&9&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&9&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&10&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&10&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&10&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&10&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&11&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&11&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&11&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&11&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&12&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&12&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&12&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&12&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&13&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&13&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&13&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&13&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&14&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&14&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&14&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&14&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&15&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&15&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&15&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&15&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&16&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&16&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&16&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&16&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&17&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&17&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&17&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&17&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&18&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&18&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&18&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&18&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&19&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&19&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&19&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&19&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&20&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&20&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&20&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&20&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&21&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&21&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&21&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&21&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&22&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&22&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&22&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&22&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&23&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&23&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&23&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&23&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&24&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&24&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&24&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&24&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&25&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&25&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&25&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&25&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&26&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&26&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&26&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&26&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&27&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&27&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&27&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&27&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "  )\n",
       "  (attn_mask_unfrozen): ParameterDict(\n",
       "      (blocks&0&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&0&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&0&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&0&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&1&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&1&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&1&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&1&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&2&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&2&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&2&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&2&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&3&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&3&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&3&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&3&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&4&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&4&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&4&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&4&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&5&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&5&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&5&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&5&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&6&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&6&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&6&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&6&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&7&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&7&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&7&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&7&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&8&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&8&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&8&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&8&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&9&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&9&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&9&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&9&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&10&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&10&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&10&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&10&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&11&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&11&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&11&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&11&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&12&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&12&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&12&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&12&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&13&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&13&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&13&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&13&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&14&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&14&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&14&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&14&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&15&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&15&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&15&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&15&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&16&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&16&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&16&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&16&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&17&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&17&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&17&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&17&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&18&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&18&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&18&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&18&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&19&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&19&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&19&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&19&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&20&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&20&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&20&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&20&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&21&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&21&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&21&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&21&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&22&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&22&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&22&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&22&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&23&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&23&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&23&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&23&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&24&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&24&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&24&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&24&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&25&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&25&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&25&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&25&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&26&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&26&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&26&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&26&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&27&attn&hook_q): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&27&attn&hook_k): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&27&attn&hook_v): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "      (blocks&27&attn&hook_result): Parameter containing: [torch.cuda.FloatTensor of size 16x1 (cuda:0)]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use_localized_mask = False\n",
    "\n",
    "combine_heads = False\n",
    "top_p = 5\n",
    "\n",
    "# if use_localized_mask:\n",
    "final_components, final_attn_heads = get_top_components(*convert_attrs_to_components(ap_graph, combine_heads=combine_heads), top_p=top_p)\n",
    "\n",
    "print(final_components)\n",
    "print(final_attn_heads)\n",
    "\n",
    "localized_mask = NeuronLevelMask(localized_model, components=final_components, component_heads=final_attn_heads)\n",
    "\n",
    "\n",
    "all_components, all_attn_heads = get_top_components(*convert_attrs_to_components(ap_graph, combine_heads=combine_heads), top_p=100)\n",
    "print(len(all_components))\n",
    "print(len(all_attn_heads))\n",
    "assert (torch.tensor([len(x) for x in all_attn_heads.values()]) == model.cfg.n_heads).all()\n",
    "\n",
    "nonlocalized_mask = NeuronLevelMask(nonlocalized_model, components=all_components, component_heads=all_attn_heads)\n",
    "\n",
    "# mask.load_state_dict(torch.load(f\"masks/neuron_cb/{model_type}_{'localized' if use_localized_mask else 'nonlocalized'}_{combine_heads=}_unlearn_{forget_sport}.pt\"))\n",
    "localized_mask.load_state_dict(torch.load(f\"masks/neuron_cb/{model_type}_localized_{combine_heads=}_unlearn_{forget_sport}.pt\"))\n",
    "nonlocalized_mask.load_state_dict(torch.load(f\"masks/neuron_cb/{model_type}_nonlocalized_{combine_heads=}_unlearn_{forget_sport}.pt\"))\n",
    "\n",
    "localized_mask.cuda()\n",
    "nonlocalized_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masks.blocks&0&mlp&hook_pre torch.Size([24576]) True 24555.44921875\n",
      "masks.blocks&1&mlp&hook_post torch.Size([24576]) True 24563.9921875\n",
      "masks.blocks&2&mlp&hook_post torch.Size([24576]) True 24575.3671875\n",
      "masks.blocks&4&mlp&hook_pre torch.Size([24576]) True 24570.87890625\n",
      "masks.blocks&5&mlp&hook_pre torch.Size([24576]) True 24573.849609375\n",
      "masks.blocks&10&mlp&hook_pre torch.Size([24576]) True 24575.71875\n",
      "masks.blocks&11&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&12&mlp&hook_pre torch.Size([24576]) True 24575.431640625\n",
      "masks.blocks&12&mlp&hook_post torch.Size([24576]) True 24575.763671875\n",
      "masks.blocks&13&mlp&hook_pre torch.Size([24576]) True 24575.66796875\n",
      "masks.blocks&13&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&14&mlp&hook_pre torch.Size([24576]) True 24575.7265625\n",
      "masks.blocks&14&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&15&mlp&hook_pre torch.Size([24576]) True 24575.94140625\n",
      "masks.blocks&15&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&16&mlp&hook_pre torch.Size([24576]) True 24575.1796875\n",
      "masks.blocks&17&mlp&hook_post torch.Size([24576]) True 24574.5390625\n",
      "masks.blocks&18&mlp&hook_pre torch.Size([24576]) True 24574.09375\n",
      "masks.blocks&18&mlp&hook_post torch.Size([24576]) True 24575.21875\n",
      "masks.blocks&19&mlp&hook_pre torch.Size([24576]) True 24573.9140625\n",
      "masks.blocks&20&mlp&hook_pre torch.Size([24576]) True 24572.76171875\n",
      "masks.blocks&20&mlp&hook_post torch.Size([24576]) True 24574.765625\n",
      "masks.blocks&21&mlp&hook_pre torch.Size([24576]) True 24569.05078125\n",
      "masks.blocks&21&mlp&hook_post torch.Size([24576]) True 24571.86328125\n",
      "masks.blocks&22&mlp&hook_pre torch.Size([24576]) True 24572.796875\n",
      "masks.blocks&22&mlp&hook_post torch.Size([24576]) True 24573.974609375\n",
      "masks.blocks&23&mlp&hook_pre torch.Size([24576]) True 24571.02734375\n",
      "masks.blocks&23&mlp&hook_post torch.Size([24576]) True 24572.37890625\n",
      "masks.blocks&24&mlp&hook_pre torch.Size([24576]) True 24571.73046875\n",
      "masks.blocks&24&mlp&hook_post torch.Size([24576]) True 24574.66015625\n",
      "masks.blocks&25&mlp&hook_pre torch.Size([24576]) True 24571.173828125\n",
      "masks.blocks&25&mlp&hook_post torch.Size([24576]) True 24573.42578125\n",
      "masks.blocks&26&mlp&hook_pre torch.Size([24576]) True 24572.04296875\n",
      "masks.blocks&26&mlp&hook_post torch.Size([24576]) True 24572.52734375\n",
      "masks.blocks&27&mlp&hook_pre torch.Size([24576]) True 24569.52734375\n",
      "masks.blocks&27&mlp&hook_post torch.Size([24576]) True 24570.16015625\n",
      "masks.blocks&14&attn&hook_q torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&14&attn&hook_k torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&15&attn&hook_v torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&15&attn&hook_result torch.Size([16, 3072]) True 48002.8359375\n",
      "masks.blocks&16&attn&hook_v torch.Size([16, 256]) True 4006.62109375\n",
      "masks.blocks&16&attn&hook_result torch.Size([16, 3072]) True 48155.6875\n",
      "masks.blocks&17&attn&hook_k torch.Size([16, 256]) True 4006.62109375\n",
      "masks.blocks&17&attn&hook_v torch.Size([16, 256]) True 4019.389404296875\n",
      "masks.blocks&17&attn&hook_result torch.Size([16, 3072]) True 48078.421875\n",
      "masks.blocks&18&attn&hook_k torch.Size([16, 256]) True 4006.62109375\n",
      "masks.blocks&18&attn&hook_v torch.Size([16, 256]) True 4013.00537109375\n",
      "masks.blocks&18&attn&hook_result torch.Size([16, 3072]) True 48079.4453125\n",
      "masks.blocks&19&attn&hook_k torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&19&attn&hook_v torch.Size([16, 256]) True 4013.00537109375\n",
      "masks.blocks&19&attn&hook_result torch.Size([16, 3072]) True 48156.0546875\n",
      "masks.blocks&20&attn&hook_k torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&20&attn&hook_v torch.Size([16, 256]) True 4006.62109375\n",
      "masks.blocks&20&attn&hook_result torch.Size([16, 3072]) True 48079.4453125\n",
      "masks.blocks&21&attn&hook_q torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&21&attn&hook_v torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&21&attn&hook_result torch.Size([16, 3072]) True 48002.8359375\n",
      "masks.blocks&22&attn&hook_k torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&22&attn&hook_v torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&22&attn&hook_result torch.Size([16, 3072]) True 48002.8359375\n",
      "masks.blocks&23&attn&hook_v torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&24&attn&hook_v torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&24&attn&hook_result torch.Size([16, 3072]) True 48002.609375\n",
      "masks.blocks&25&attn&hook_v torch.Size([16, 256]) True 4006.62109375\n",
      "masks.blocks&25&attn&hook_result torch.Size([16, 3072]) True 48076.421875\n",
      "masks.blocks&26&attn&hook_v torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&27&attn&hook_q torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&27&attn&hook_k torch.Size([16, 256]) True 4000.23681640625\n",
      "masks.blocks&27&attn&hook_v torch.Size([16, 256]) True 4013.00537109375\n",
      "masks.blocks&27&attn&hook_result torch.Size([16, 3072]) True 48077.1640625\n",
      "attn_mask_frozen.blocks&14&attn&hook_q torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&14&attn&hook_k torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&15&attn&hook_v torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&15&attn&hook_result torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&16&attn&hook_v torch.Size([16, 1]) False 14.0\n",
      "attn_mask_frozen.blocks&16&attn&hook_result torch.Size([16, 1]) False 13.0\n",
      "attn_mask_frozen.blocks&17&attn&hook_k torch.Size([16, 1]) False 14.0\n",
      "attn_mask_frozen.blocks&17&attn&hook_v torch.Size([16, 1]) False 12.0\n",
      "attn_mask_frozen.blocks&17&attn&hook_result torch.Size([16, 1]) False 14.0\n",
      "attn_mask_frozen.blocks&18&attn&hook_k torch.Size([16, 1]) False 14.0\n",
      "attn_mask_frozen.blocks&18&attn&hook_v torch.Size([16, 1]) False 13.0\n",
      "attn_mask_frozen.blocks&18&attn&hook_result torch.Size([16, 1]) False 14.0\n",
      "attn_mask_frozen.blocks&19&attn&hook_k torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&19&attn&hook_v torch.Size([16, 1]) False 13.0\n",
      "attn_mask_frozen.blocks&19&attn&hook_result torch.Size([16, 1]) False 13.0\n",
      "attn_mask_frozen.blocks&20&attn&hook_k torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&20&attn&hook_v torch.Size([16, 1]) False 14.0\n",
      "attn_mask_frozen.blocks&20&attn&hook_result torch.Size([16, 1]) False 14.0\n",
      "attn_mask_frozen.blocks&21&attn&hook_q torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&21&attn&hook_v torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&21&attn&hook_result torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&22&attn&hook_k torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&22&attn&hook_v torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&22&attn&hook_result torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&23&attn&hook_v torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&24&attn&hook_v torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&24&attn&hook_result torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&25&attn&hook_v torch.Size([16, 1]) False 14.0\n",
      "attn_mask_frozen.blocks&25&attn&hook_result torch.Size([16, 1]) False 14.0\n",
      "attn_mask_frozen.blocks&26&attn&hook_v torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&27&attn&hook_q torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&27&attn&hook_k torch.Size([16, 1]) False 15.0\n",
      "attn_mask_frozen.blocks&27&attn&hook_v torch.Size([16, 1]) False 13.0\n",
      "attn_mask_frozen.blocks&27&attn&hook_result torch.Size([16, 1]) False 14.0\n",
      "attn_mask_unfrozen.blocks&14&attn&hook_q torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&14&attn&hook_k torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&15&attn&hook_v torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&15&attn&hook_result torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&16&attn&hook_v torch.Size([16, 1]) False 2.0\n",
      "attn_mask_unfrozen.blocks&16&attn&hook_result torch.Size([16, 1]) False 3.0\n",
      "attn_mask_unfrozen.blocks&17&attn&hook_k torch.Size([16, 1]) False 2.0\n",
      "attn_mask_unfrozen.blocks&17&attn&hook_v torch.Size([16, 1]) False 4.0\n",
      "attn_mask_unfrozen.blocks&17&attn&hook_result torch.Size([16, 1]) False 2.0\n",
      "attn_mask_unfrozen.blocks&18&attn&hook_k torch.Size([16, 1]) False 2.0\n",
      "attn_mask_unfrozen.blocks&18&attn&hook_v torch.Size([16, 1]) False 3.0\n",
      "attn_mask_unfrozen.blocks&18&attn&hook_result torch.Size([16, 1]) False 2.0\n",
      "attn_mask_unfrozen.blocks&19&attn&hook_k torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&19&attn&hook_v torch.Size([16, 1]) False 3.0\n",
      "attn_mask_unfrozen.blocks&19&attn&hook_result torch.Size([16, 1]) False 3.0\n",
      "attn_mask_unfrozen.blocks&20&attn&hook_k torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&20&attn&hook_v torch.Size([16, 1]) False 2.0\n",
      "attn_mask_unfrozen.blocks&20&attn&hook_result torch.Size([16, 1]) False 2.0\n",
      "attn_mask_unfrozen.blocks&21&attn&hook_q torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&21&attn&hook_v torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&21&attn&hook_result torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&22&attn&hook_k torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&22&attn&hook_v torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&22&attn&hook_result torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&23&attn&hook_v torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&24&attn&hook_v torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&24&attn&hook_result torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&25&attn&hook_v torch.Size([16, 1]) False 2.0\n",
      "attn_mask_unfrozen.blocks&25&attn&hook_result torch.Size([16, 1]) False 2.0\n",
      "attn_mask_unfrozen.blocks&26&attn&hook_v torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&27&attn&hook_q torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&27&attn&hook_k torch.Size([16, 1]) False 1.0\n",
      "attn_mask_unfrozen.blocks&27&attn&hook_v torch.Size([16, 1]) False 3.0\n",
      "attn_mask_unfrozen.blocks&27&attn&hook_result torch.Size([16, 1]) False 2.0\n",
      "\n",
      "\n",
      "\n",
      "masks.blocks&0&mlp&hook_pre torch.Size([24576]) True 24571.431640625\n",
      "masks.blocks&0&mlp&hook_post torch.Size([24576]) True 24575.03125\n",
      "masks.blocks&1&mlp&hook_pre torch.Size([24576]) True 24572.13671875\n",
      "masks.blocks&1&mlp&hook_post torch.Size([24576]) True 24573.4609375\n",
      "masks.blocks&2&mlp&hook_pre torch.Size([24576]) True 24575.33984375\n",
      "masks.blocks&2&mlp&hook_post torch.Size([24576]) True 24575.71484375\n",
      "masks.blocks&3&mlp&hook_pre torch.Size([24576]) True 24575.36328125\n",
      "masks.blocks&3&mlp&hook_post torch.Size([24576]) True 24575.76171875\n",
      "masks.blocks&4&mlp&hook_pre torch.Size([24576]) True 24573.13671875\n",
      "masks.blocks&4&mlp&hook_post torch.Size([24576]) True 24574.10546875\n",
      "masks.blocks&5&mlp&hook_pre torch.Size([24576]) True 24575.044921875\n",
      "masks.blocks&5&mlp&hook_post torch.Size([24576]) True 24575.80078125\n",
      "masks.blocks&6&mlp&hook_pre torch.Size([24576]) True 24574.138671875\n",
      "masks.blocks&6&mlp&hook_post torch.Size([24576]) True 24575.42578125\n",
      "masks.blocks&7&mlp&hook_pre torch.Size([24576]) True 24575.462890625\n",
      "masks.blocks&7&mlp&hook_post torch.Size([24576]) True 24575.341796875\n",
      "masks.blocks&8&mlp&hook_pre torch.Size([24576]) True 24574.9921875\n",
      "masks.blocks&8&mlp&hook_post torch.Size([24576]) True 24575.146484375\n",
      "masks.blocks&9&mlp&hook_pre torch.Size([24576]) True 24575.9609375\n",
      "masks.blocks&9&mlp&hook_post torch.Size([24576]) True 24575.99609375\n",
      "masks.blocks&10&mlp&hook_pre torch.Size([24576]) True 24575.994140625\n",
      "masks.blocks&10&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&11&mlp&hook_pre torch.Size([24576]) True 24576.0\n",
      "masks.blocks&11&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&12&mlp&hook_pre torch.Size([24576]) True 24575.75\n",
      "masks.blocks&12&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&13&mlp&hook_pre torch.Size([24576]) True 24576.0\n",
      "masks.blocks&13&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&14&mlp&hook_pre torch.Size([24576]) True 24575.814453125\n",
      "masks.blocks&14&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&15&mlp&hook_pre torch.Size([24576]) True 24575.974609375\n",
      "masks.blocks&15&mlp&hook_post torch.Size([24576]) True 24575.994140625\n",
      "masks.blocks&16&mlp&hook_pre torch.Size([24576]) True 24576.0\n",
      "masks.blocks&16&mlp&hook_post torch.Size([24576]) True 24576.0\n",
      "masks.blocks&17&mlp&hook_pre torch.Size([24576]) True 24575.3203125\n",
      "masks.blocks&17&mlp&hook_post torch.Size([24576]) True 24575.44140625\n",
      "masks.blocks&18&mlp&hook_pre torch.Size([24576]) True 24575.3671875\n",
      "masks.blocks&18&mlp&hook_post torch.Size([24576]) True 24575.9375\n",
      "masks.blocks&19&mlp&hook_pre torch.Size([24576]) True 24575.63671875\n",
      "masks.blocks&19&mlp&hook_post torch.Size([24576]) True 24575.96875\n",
      "masks.blocks&20&mlp&hook_pre torch.Size([24576]) True 24575.82421875\n",
      "masks.blocks&20&mlp&hook_post torch.Size([24576]) True 24575.96484375\n",
      "masks.blocks&21&mlp&hook_pre torch.Size([24576]) True 24575.2109375\n",
      "masks.blocks&21&mlp&hook_post torch.Size([24576]) True 24575.693359375\n",
      "masks.blocks&22&mlp&hook_pre torch.Size([24576]) True 24573.59765625\n",
      "masks.blocks&22&mlp&hook_post torch.Size([24576]) True 24574.166015625\n",
      "masks.blocks&23&mlp&hook_pre torch.Size([24576]) True 24573.94921875\n",
      "masks.blocks&23&mlp&hook_post torch.Size([24576]) True 24574.5859375\n",
      "masks.blocks&24&mlp&hook_pre torch.Size([24576]) True 24574.8984375\n",
      "masks.blocks&24&mlp&hook_post torch.Size([24576]) True 24575.07421875\n",
      "masks.blocks&25&mlp&hook_pre torch.Size([24576]) True 24573.9765625\n",
      "masks.blocks&25&mlp&hook_post torch.Size([24576]) True 24574.185546875\n",
      "masks.blocks&26&mlp&hook_pre torch.Size([24576]) True 24573.4375\n",
      "masks.blocks&26&mlp&hook_post torch.Size([24576]) True 24573.62109375\n",
      "masks.blocks&27&mlp&hook_pre torch.Size([24576]) True 24572.1953125\n",
      "masks.blocks&27&mlp&hook_post torch.Size([24576]) True 24572.7265625\n",
      "masks.blocks&0&attn&hook_q torch.Size([16, 256]) True 4095.99072265625\n",
      "masks.blocks&0&attn&hook_k torch.Size([16, 256]) True 4095.992431640625\n",
      "masks.blocks&0&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&0&attn&hook_result torch.Size([16, 3072]) True 49065.55859375\n",
      "masks.blocks&1&attn&hook_q torch.Size([16, 256]) True 4095.9970703125\n",
      "masks.blocks&1&attn&hook_k torch.Size([16, 256]) True 4095.996826171875\n",
      "masks.blocks&1&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&1&attn&hook_result torch.Size([16, 3072]) True 49151.1171875\n",
      "masks.blocks&2&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&2&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&2&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&2&attn&hook_result torch.Size([16, 3072]) True 49150.1953125\n",
      "masks.blocks&3&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&3&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&3&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&3&attn&hook_result torch.Size([16, 3072]) True 49151.9921875\n",
      "masks.blocks&4&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&4&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&4&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&4&attn&hook_result torch.Size([16, 3072]) True 49151.7421875\n",
      "masks.blocks&5&attn&hook_q torch.Size([16, 256]) True 4095.999267578125\n",
      "masks.blocks&5&attn&hook_k torch.Size([16, 256]) True 4095.999267578125\n",
      "masks.blocks&5&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&5&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&6&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&6&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&6&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&6&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&7&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&7&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&7&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&7&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&8&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&8&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&8&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&8&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&9&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&9&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&9&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&9&attn&hook_result torch.Size([16, 3072]) True 49151.83984375\n",
      "masks.blocks&10&attn&hook_q torch.Size([16, 256]) True 4095.99658203125\n",
      "masks.blocks&10&attn&hook_k torch.Size([16, 256]) True 4095.99658203125\n",
      "masks.blocks&10&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&10&attn&hook_result torch.Size([16, 3072]) True 49151.78125\n",
      "masks.blocks&11&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&11&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&11&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&11&attn&hook_result torch.Size([16, 3072]) True 49151.9765625\n",
      "masks.blocks&12&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&12&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&12&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&12&attn&hook_result torch.Size([16, 3072]) True 49151.828125\n",
      "masks.blocks&13&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&13&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&13&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&13&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&14&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&14&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&14&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&14&attn&hook_result torch.Size([16, 3072]) True 49151.8359375\n",
      "masks.blocks&15&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&15&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&15&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&15&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&16&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&16&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&16&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&16&attn&hook_result torch.Size([16, 3072]) True 49151.82421875\n",
      "masks.blocks&17&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&17&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&17&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&17&attn&hook_result torch.Size([16, 3072]) True 49151.29296875\n",
      "masks.blocks&18&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&18&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&18&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&18&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&19&attn&hook_q torch.Size([16, 256]) True 4095.99853515625\n",
      "masks.blocks&19&attn&hook_k torch.Size([16, 256]) True 4095.998291015625\n",
      "masks.blocks&19&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&19&attn&hook_result torch.Size([16, 3072]) True 49151.7109375\n",
      "masks.blocks&20&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&20&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&20&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&20&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&21&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&21&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&21&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&21&attn&hook_result torch.Size([16, 3072]) True 49151.796875\n",
      "masks.blocks&22&attn&hook_q torch.Size([16, 256]) True 4095.99853515625\n",
      "masks.blocks&22&attn&hook_k torch.Size([16, 256]) True 4095.99853515625\n",
      "masks.blocks&22&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&22&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&23&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&23&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&23&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&23&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&24&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&24&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&24&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&24&attn&hook_result torch.Size([16, 3072]) True 49152.0\n",
      "masks.blocks&25&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&25&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&25&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&25&attn&hook_result torch.Size([16, 3072]) True 49151.74609375\n",
      "masks.blocks&26&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&26&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&26&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&26&attn&hook_result torch.Size([16, 3072]) True 49149.05859375\n",
      "masks.blocks&27&attn&hook_q torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&27&attn&hook_k torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&27&attn&hook_v torch.Size([16, 256]) True 4096.0\n",
      "masks.blocks&27&attn&hook_result torch.Size([16, 3072]) True 49151.16796875\n",
      "attn_mask_frozen.blocks&0&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&0&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&0&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&0&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&1&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&1&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&1&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&1&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&2&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&2&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&2&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&2&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&3&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&3&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&3&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&3&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&4&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&4&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&4&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&4&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&5&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&5&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&5&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&5&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&6&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&6&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&6&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&6&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&7&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&7&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&7&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&7&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&8&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&8&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&8&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&8&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&9&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&9&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&9&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&9&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&10&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&10&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&10&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&10&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&11&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&11&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&11&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&11&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&12&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&12&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&12&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&12&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&13&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&13&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&13&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&13&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&14&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&14&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&14&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&14&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&15&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&15&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&15&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&15&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&16&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&16&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&16&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&16&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&17&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&17&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&17&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&17&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&18&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&18&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&18&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&18&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&19&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&19&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&19&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&19&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&20&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&20&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&20&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&20&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&21&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&21&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&21&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&21&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&22&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&22&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&22&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&22&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&23&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&23&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&23&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&23&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&24&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&24&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&24&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&24&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&25&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&25&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&25&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&25&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&26&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&26&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&26&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&26&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&27&attn&hook_q torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&27&attn&hook_k torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&27&attn&hook_v torch.Size([16, 1]) False 0.0\n",
      "attn_mask_frozen.blocks&27&attn&hook_result torch.Size([16, 1]) False 0.0\n",
      "attn_mask_unfrozen.blocks&0&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&0&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&0&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&0&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&1&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&1&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&1&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&1&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&2&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&2&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&2&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&2&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&3&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&3&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&3&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&3&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&4&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&4&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&4&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&4&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&5&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&5&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&5&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&5&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&6&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&6&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&6&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&6&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&7&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&7&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&7&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&7&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&8&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&8&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&8&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&8&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&9&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&9&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&9&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&9&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&10&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&10&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&10&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&10&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&11&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&11&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&11&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&11&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&12&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&12&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&12&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&12&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&13&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&13&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&13&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&13&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&14&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&14&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&14&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&14&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&15&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&15&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&15&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&15&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&16&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&16&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&16&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&16&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&17&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&17&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&17&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&17&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&18&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&18&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&18&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&18&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&19&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&19&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&19&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&19&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&20&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&20&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&20&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&20&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&21&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&21&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&21&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&21&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&22&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&22&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&22&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&22&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&23&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&23&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&23&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&23&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&24&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&24&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&24&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&24&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&25&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&25&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&25&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&25&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&26&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&26&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&26&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&26&attn&hook_result torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&27&attn&hook_q torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&27&attn&hook_k torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&27&attn&hook_v torch.Size([16, 1]) False 16.0\n",
      "attn_mask_unfrozen.blocks&27&attn&hook_result torch.Size([16, 1]) False 16.0\n"
     ]
    }
   ],
   "source": [
    "for name, param in localized_mask.named_parameters():\n",
    "    print(name, param.shape, param.requires_grad, param.sum().item())\n",
    "print(\"\\n\\n\")\n",
    "for name, param in nonlocalized_mask.named_parameters():\n",
    "    print(name, param.shape, param.requires_grad, param.sum().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751, 0.9751,\n",
      "         0.9751, 0.9751, 0.9751, 0.9751],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(localized_mask.masks['blocks&16&attn&hook_v'][[0, 1, 8]])\n",
    "print(localized_mask.attn_mask_unfrozen['blocks&16&attn&hook_v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.409375,\n",
       " 2.484375,\n",
       " 2.31875,\n",
       " 2.284375,\n",
       " 2.346875,\n",
       " 2.228125,\n",
       " 2.375,\n",
       " 2.265625,\n",
       " 2.265625,\n",
       " 2.309375,\n",
       " 2.371875,\n",
       " 2.3625,\n",
       " 2.346875,\n",
       " 2.321875,\n",
       " 2.290625,\n",
       " 2.228125,\n",
       " 2.278125,\n",
       " 2.284375,\n",
       " 2.340625,\n",
       " 2.321875,\n",
       " 2.234375]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# with open(f\"masks/neuron_cb/{model_type}_{'localized' if use_localized_mask else 'nonlocalized'}_{combine_heads=}_unlearn_{forget_sport}_metrics.pkl\", \"rb\") as f:\n",
    "#     metrics = pickle.load(f)\n",
    "\n",
    "# metrics['test_losses']['pile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the neuron coefficients\n",
    "all_values = torch.cat([m.data.flatten() for m in mask.masks.values()], dim=0).cpu()\n",
    "sorted = all_values.sort().values\n",
    "plt.semilogx(sorted)\n",
    "plt.title(\"Neuron Mask Values\")\n",
    "plt.ylabel(\"Mask Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks&0&mlp&hook_pre', 'blocks&0&mlp&hook_post', 'blocks&1&mlp&hook_pre', 'blocks&1&mlp&hook_post', 'blocks&2&mlp&hook_pre', 'blocks&2&mlp&hook_post', 'blocks&3&mlp&hook_pre', 'blocks&3&mlp&hook_post', 'blocks&4&mlp&hook_pre', 'blocks&4&mlp&hook_post', 'blocks&5&mlp&hook_pre', 'blocks&5&mlp&hook_post', 'blocks&6&mlp&hook_pre', 'blocks&6&mlp&hook_post', 'blocks&7&mlp&hook_pre', 'blocks&7&mlp&hook_post', 'blocks&8&mlp&hook_pre', 'blocks&8&mlp&hook_post', 'blocks&9&mlp&hook_pre', 'blocks&9&mlp&hook_post', 'blocks&10&mlp&hook_pre', 'blocks&10&mlp&hook_post', 'blocks&11&mlp&hook_pre', 'blocks&11&mlp&hook_post', 'blocks&12&mlp&hook_pre', 'blocks&12&mlp&hook_post', 'blocks&13&mlp&hook_pre', 'blocks&13&mlp&hook_post', 'blocks&14&mlp&hook_pre', 'blocks&14&mlp&hook_post', 'blocks&15&mlp&hook_pre', 'blocks&15&mlp&hook_post', 'blocks&16&mlp&hook_pre', 'blocks&16&mlp&hook_post', 'blocks&17&mlp&hook_pre', 'blocks&17&mlp&hook_post', 'blocks&18&mlp&hook_pre', 'blocks&18&mlp&hook_post', 'blocks&19&mlp&hook_pre', 'blocks&19&mlp&hook_post', 'blocks&20&mlp&hook_pre', 'blocks&20&mlp&hook_post', 'blocks&21&mlp&hook_pre', 'blocks&21&mlp&hook_post', 'blocks&22&mlp&hook_pre', 'blocks&22&mlp&hook_post', 'blocks&23&mlp&hook_pre', 'blocks&23&mlp&hook_post', 'blocks&24&mlp&hook_pre', 'blocks&24&mlp&hook_post', 'blocks&25&mlp&hook_pre', 'blocks&25&mlp&hook_post', 'blocks&26&mlp&hook_pre', 'blocks&26&mlp&hook_post', 'blocks&27&mlp&hook_pre', 'blocks&27&mlp&hook_post', 'blocks&0&attn&hook_q', 'blocks&0&attn&hook_k', 'blocks&0&attn&hook_v', 'blocks&0&attn&hook_result', 'blocks&1&attn&hook_q', 'blocks&1&attn&hook_k', 'blocks&1&attn&hook_v', 'blocks&1&attn&hook_result', 'blocks&2&attn&hook_q', 'blocks&2&attn&hook_k', 'blocks&2&attn&hook_v', 'blocks&2&attn&hook_result', 'blocks&3&attn&hook_q', 'blocks&3&attn&hook_k', 'blocks&3&attn&hook_v', 'blocks&3&attn&hook_result', 'blocks&4&attn&hook_q', 'blocks&4&attn&hook_k', 'blocks&4&attn&hook_v', 'blocks&4&attn&hook_result', 'blocks&5&attn&hook_q', 'blocks&5&attn&hook_k', 'blocks&5&attn&hook_v', 'blocks&5&attn&hook_result', 'blocks&6&attn&hook_q', 'blocks&6&attn&hook_k', 'blocks&6&attn&hook_v', 'blocks&6&attn&hook_result', 'blocks&7&attn&hook_q', 'blocks&7&attn&hook_k', 'blocks&7&attn&hook_v', 'blocks&7&attn&hook_result', 'blocks&8&attn&hook_q', 'blocks&8&attn&hook_k', 'blocks&8&attn&hook_v', 'blocks&8&attn&hook_result', 'blocks&9&attn&hook_q', 'blocks&9&attn&hook_k', 'blocks&9&attn&hook_v', 'blocks&9&attn&hook_result', 'blocks&10&attn&hook_q', 'blocks&10&attn&hook_k', 'blocks&10&attn&hook_v', 'blocks&10&attn&hook_result', 'blocks&11&attn&hook_q', 'blocks&11&attn&hook_k', 'blocks&11&attn&hook_v', 'blocks&11&attn&hook_result', 'blocks&12&attn&hook_q', 'blocks&12&attn&hook_k', 'blocks&12&attn&hook_v', 'blocks&12&attn&hook_result', 'blocks&13&attn&hook_q', 'blocks&13&attn&hook_k', 'blocks&13&attn&hook_v', 'blocks&13&attn&hook_result', 'blocks&14&attn&hook_q', 'blocks&14&attn&hook_k', 'blocks&14&attn&hook_v', 'blocks&14&attn&hook_result', 'blocks&15&attn&hook_q', 'blocks&15&attn&hook_k', 'blocks&15&attn&hook_v', 'blocks&15&attn&hook_result', 'blocks&16&attn&hook_q', 'blocks&16&attn&hook_k', 'blocks&16&attn&hook_v', 'blocks&16&attn&hook_result', 'blocks&17&attn&hook_q', 'blocks&17&attn&hook_k', 'blocks&17&attn&hook_v', 'blocks&17&attn&hook_result', 'blocks&18&attn&hook_q', 'blocks&18&attn&hook_k', 'blocks&18&attn&hook_v', 'blocks&18&attn&hook_result', 'blocks&19&attn&hook_q', 'blocks&19&attn&hook_k', 'blocks&19&attn&hook_v', 'blocks&19&attn&hook_result', 'blocks&20&attn&hook_q', 'blocks&20&attn&hook_k', 'blocks&20&attn&hook_v', 'blocks&20&attn&hook_result', 'blocks&21&attn&hook_q', 'blocks&21&attn&hook_k', 'blocks&21&attn&hook_v', 'blocks&21&attn&hook_result', 'blocks&22&attn&hook_q', 'blocks&22&attn&hook_k', 'blocks&22&attn&hook_v', 'blocks&22&attn&hook_result', 'blocks&23&attn&hook_q', 'blocks&23&attn&hook_k', 'blocks&23&attn&hook_v', 'blocks&23&attn&hook_result', 'blocks&24&attn&hook_q', 'blocks&24&attn&hook_k', 'blocks&24&attn&hook_v', 'blocks&24&attn&hook_result', 'blocks&25&attn&hook_q', 'blocks&25&attn&hook_k', 'blocks&25&attn&hook_v', 'blocks&25&attn&hook_result', 'blocks&26&attn&hook_q', 'blocks&26&attn&hook_k', 'blocks&26&attn&hook_v', 'blocks&26&attn&hook_result', 'blocks&27&attn&hook_q', 'blocks&27&attn&hook_k', 'blocks&27&attn&hook_v', 'blocks&27&attn&hook_result'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.mask_masks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the neuron coefficients\n",
    "mask.undiscretize()\n",
    "mask.discretize_topk(1000)\n",
    "all_values = {layer: 0 for layer in range(model.cfg.n_layers)}\n",
    "for component in mask.mask_masks:\n",
    "    layer = int(component.split(\"&\")[1])\n",
    "    all_values[layer] += (mask.mask_masks[component].data == 1).sum().item()\n",
    "\n",
    "# all_values = [(m.data == 1).sum().item() for m in mask.mask_masks.values()]\n",
    "plt.plot(all_values.values())\n",
    "plt.title(\"Where the Top-1000 Masked Neurons Are\")\n",
    "plt.ylabel(\"# Of Neurons at Layer\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt: adversarial evals are {'Normal': {'football': 1.0, 'baseball': 1.0, 'basketball': 0.065625}, 'MC': {'football': 1.0, 'baseball': 1.0, 'basketball': 0.30000000000000004}, 'Capitalized': {'football': 1.0, 'baseball': 1.0, 'basketball': 0.040625}, 'Dashed': {'football': 0.8875, 'baseball': 1.0, 'basketball': 0.07812499999999999}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No System Prompt: adversarial evals are {'Normal': {'football': 1.0, 'baseball': 1.0, 'basketball': 0.009375000000000001}, 'MC': {'football': 1.0, 'baseball': 1.0, 'basketball': 0.26875}, 'Capitalized': {'football': 1.0, 'baseball': 1.0, 'basketball': 0.018750000000000003}, 'Dashed': {'football': 1.0, 'baseball': 1.0, 'basketball': 0.00625}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308ba72d02d44c24afd3a62f0a790ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports Answers:\n",
      "football: 50/50\n",
      "baseball: 49/50\n",
      "basketball: 29/50\n",
      "tennis: 44/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d87e2dafa674dfa9162803edda80ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd13de999ba43119a18a5621dd28489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test dataset available. Using train dataset for testing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for Skylion007/openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Skylion007/openwebtext\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a4f05816b42c5bcf9935738c52964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f1b26853274e4693feceaffbee2f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pile Cross Entropy: tensor(2.2969, device='cuda:0', dtype=torch.bfloat16)\n",
      "OWT Cross Entropy: tensor(2.5156, device='cuda:0', dtype=torch.bfloat16)\n",
      "{'Sports Answers': {'football': 1.0, 'baseball': 0.98, 'basketball': 0.58, 'tennis': 0.88}, 'Cross Entropy': {'Pile': tensor(2.2969, device='cuda:0', dtype=torch.bfloat16), 'OWT': tensor(2.5156, device='cuda:0', dtype=torch.bfloat16)}}\n"
     ]
    }
   ],
   "source": [
    "# Final evals\n",
    "mask.undiscretize()\n",
    "final_adversarial_eval = adversarial_sports_eval(model, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=True, continuous=False)\n",
    "print(f\"System Prompt: adversarial evals are {final_adversarial_eval}\")\n",
    "final_adversarial_eval = adversarial_sports_eval(model, model_type=model_type, batch_size=eval_batch_size, use_system_prompt=False, continuous=False)\n",
    "print(f\"No System Prompt: adversarial evals are {final_adversarial_eval}\")\n",
    "\n",
    "final_side_effects = run_side_effects_evals(model, model_type=model_type, batch_size=eval_batch_size, evals_to_run=[\"Sports Answers\", \"Cross Entropy\"], verbose=True)\n",
    "print(final_side_effects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pareto Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlrn",
   "language": "python",
   "name": "unlrn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
