{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aaquibsyed/Documents/Python/mechanistic-unlearning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaquibsyed/.pyenv/versions/3.10.0/envs/env/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "%cd ../../\n",
    "from dataset.custom_dataset import PairedInstructionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaquibsyed/.pyenv/versions/3.10.0/envs/env/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/aaquibsyed/.pyenv/versions/3.10.0/envs/env/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"instruction_templates\": [\n",
    "        \"Tell me how to make a {object}\"\n",
    "    ],\n",
    "    \"harmful_substitution_map\": {\n",
    "        \"{object}\": [\n",
    "            \"bomb\",\n",
    "            \"gun\",\n",
    "            \"virus\",\n",
    "            \"poison\",\n",
    "            \"machine gun\"\n",
    "        ]\n",
    "    },\n",
    "    \"harmless_substitution_map\": {\n",
    "        \"{object}\": [\n",
    "            \"pie\",\n",
    "            \"poem\",\n",
    "            \"blog\",\n",
    "            \"hat\",\n",
    "            \"cute flower\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "harmful_substitution_map = data['harmful_substitution_map']\n",
    "harmless_substitution_map = data['harmless_substitution_map']\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    'gpt2-small',\n",
    "    device='mps:0',\n",
    "    fold_ln=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False\n",
    ")\n",
    "tokenizer=model.tokenizer\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "\n",
    "def tokenize_instructions(tokenizer, instructions):\n",
    "    # Use this to put the text into INST tokens or add a system prompt\n",
    "    return tokenizer(\n",
    "        instructions,\n",
    "        padding=True,\n",
    "        truncation=False,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids\n",
    "\n",
    "dataset = PairedInstructionDataset(\n",
    "    N=4,\n",
    "    instruction_templates=data['instruction_templates'],\n",
    "    harmful_substitution_map=harmful_substitution_map,\n",
    "    harmless_substitution_map=harmless_substitution_map,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenize_instructions=tokenize_instructions, \n",
    "    device='mps:0'\n",
    ")\n",
    "\n",
    "corr_dataset = dataset.harmful_dataset\n",
    "clean_dataset = dataset.harmless_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tell me how to make a blog<|endoftext|>', 'Tell me how to make a poem<|endoftext|>', 'Tell me how to make a cute flower', 'Tell me how to make a pie<|endoftext|>']\n",
      "['Tell me how to make a bomb<|endoftext|>', 'Tell me how to make a gun<|endoftext|>', 'Tell me how to make a machine gun', 'Tell me how to make a bomb<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "print(clean_dataset.str_prompts)\n",
    "print(corr_dataset.str_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean direction: 2.273561477661133, Corrupt direction: 1.801055908203125\n",
      "Clean metric: 1.0, Corrupt metric: 0.0\n",
      "Saving activations requires 0.0004 GB of memory per token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mlp.0', 'mlp.6', -0.30079543590545654), ('mlp.0', 'mlp.2', -0.26566070318222046), ('mlp.0', 'mlp.1', 0.25759780406951904), ('mlp.0', 'mlp.7', -0.2388867735862732), ('mlp.7', 'mlp.10', 0.22613169252872467), ('mlp.8', 'mlp.11', 0.17818890511989594), ('mlp.3', 'mlp.9', -0.17513982951641083), ('mlp.0', 'mlp.10', 0.1729465276002884), ('head.0.8', 'mlp.0', 0.16686570644378662), ('mlp.5', 'mlp.9', 0.15997149050235748), ('mlp.6', 'mlp.9', 0.15992607176303864), ('mlp.0', 'mlp.3', 0.15680891275405884), ('mlp.3', 'mlp.11', 0.1522006392478943), ('mlp.7', 'mlp.8', 0.14764274656772614), ('mlp.4', 'mlp.7', -0.14575673639774323), ('mlp.3', 'mlp.7', 0.14337307214736938), ('mlp.2', 'mlp.5', -0.14324265718460083), ('mlp.1', 'mlp.5', -0.13329672813415527), ('mlp.4', 'mlp.10', -0.11239660531282425), ('mlp.4', 'mlp.8', 0.10873423516750336), ('mlp.7', 'mlp.11', -0.1080850213766098), ('mlp.5', 'mlp.10', 0.10247562825679779), ('head.0.6', 'mlp.0', -0.10046084970235825), ('mlp.2', 'mlp.9', 0.09721911698579788), ('mlp.8', 'mlp.10', -0.09635031223297119), ('head.3.3', 'mlp.4', 0.09076373279094696), ('mlp.1', 'mlp.4', -0.08986853808164597), ('head.6.2', 'mlp.11', 0.08458516746759415), ('head.0.6', 'mlp.11', -0.08177153021097183), ('head.1.11', 'mlp.2', 0.07631265372037888), ('mlp.3', 'mlp.10', -0.07527850568294525), ('mlp.0', 'mlp.11', -0.07361754029989243), ('mlp.0', 'mlp.4', 0.07298064231872559), ('mlp.4', 'head.8.3.q', 0.06907261162996292), ('head.11.0', 'mlp.11', -0.06654593348503113), ('mlp.3', 'mlp.8', -0.0649419054389), ('mlp.10', 'mlp.11', 0.06412873417139053), ('head.0.4', 'mlp.1', 0.06324644386768341), ('mlp.4', 'head.8.9.q', 0.06317255645990372), ('head.1.7', 'mlp.3', -0.06300954520702362), ('mlp.5', 'mlp.7', -0.06190260499715805), ('head.0.5', 'mlp.0', -0.06181787699460983), ('head.1.7', 'mlp.6', 0.061559468507766724), ('mlp.1', 'mlp.10', 0.06071709841489792), ('head.10.7', 'mlp.10', -0.06013841554522514), ('mlp.1', 'mlp.11', -0.057992517948150635), ('mlp.3', 'mlp.4', 0.05591428652405739), ('head.8.10', 'mlp.9', -0.05494092032313347), ('head.5.11', 'mlp.7', 0.0544724240899086), ('head.4.8', 'mlp.6', -0.05429772660136223), ('head.3.3', 'mlp.3', -0.05408009886741638), ('head.5.11', 'mlp.6', -0.051227230578660965), ('head.0.5', 'mlp.5', -0.05087301507592201), ('head.1.7', 'mlp.11', -0.05018455535173416), ('mlp.0', 'head.11.2.v', -0.0498824380338192), ('mlp.1', 'mlp.2', 0.04982754960656166), ('mlp.1', 'head.8.7.q', -0.048971787095069885), ('mlp.2', 'mlp.8', 0.04873398691415787), ('head.0.5', 'mlp.2', -0.0486171618103981), ('mlp.0', 'head.5.10.k', -0.048610299825668335), ('mlp.2', 'mlp.10', -0.04831521958112717), ('mlp.2', 'mlp.7', 0.04722286015748978), ('head.4.8', 'mlp.5', 0.046947263181209564), ('mlp.2', 'mlp.6', 0.04690329730510712), ('head.1.5', 'mlp.2', -0.04687895253300667), ('head.9.2', 'mlp.9', -0.046841468662023544), ('mlp.0', 'head.5.7.q', -0.04653668776154518), ('head.0.4', 'head.8.7.q', -0.046146512031555176), ('head.1.8', 'head.8.7.q', 0.045880552381277084), ('head.4.5', 'mlp.11', 0.045550353825092316), ('head.1.11', 'mlp.3', 0.04514802247285843), ('head.0.1', 'mlp.0', -0.0450563058257103), ('head.2.4', 'mlp.10', 0.04482338950037956), ('mlp.4', 'head.5.10.q', 0.04478120803833008), ('head.8.10', 'mlp.8', 0.044780928641557693), ('head.2.4', 'mlp.3', -0.04473164305090904), ('head.4.7', 'mlp.7', -0.04465049132704735), ('mlp.0', 'head.1.6.q', 0.044356558471918106), ('mlp.7', 'head.11.2.v', 0.04419264197349548), ('head.1.5', 'mlp.10', -0.04413546249270439), ('mlp.5', 'head.8.10.v', -0.043909743428230286), ('mlp.0', 'head.11.10.v', 0.04341590777039528), ('head.2.4', 'mlp.8', -0.04336727410554886), ('mlp.4', 'mlp.6', -0.043278295546770096), ('head.7.3', 'mlp.7', -0.04206611588597298), ('mlp.2', 'head.8.7.q', -0.04202841594815254), ('head.5.11', 'mlp.8', 0.041901443153619766), ('head.0.3', 'mlp.0', 0.04185298830270767), ('mlp.5', 'head.8.7.v', 0.0417138896882534), ('mlp.6', 'mlp.11', 0.04132312536239624), ('head.9.3', 'mlp.10', -0.041126854717731476), ('head.4.8', 'mlp.11', 0.04106970876455307), ('mlp.10', 'head.11.10.v', 0.04054475203156471), ('head.11.10', 'mlp.11', -0.04038778692483902), ('head.0.1', 'mlp.10', -0.04021089896559715), ('mlp.0', 'head.1.6.k', 0.04017740115523338), ('head.0.8', 'mlp.11', 0.039659157395362854), ('head.7.1', 'mlp.7', 0.03960573300719261), ('head.2.9', 'mlp.8', -0.039462000131607056), ('head.0.8', 'mlp.3', -0.039065755903720856)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygraphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/aaquibsyed/Documents/Python/mechanistic-unlearning/localizations/eap/eap_demo.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aaquibsyed/Documents/Python/mechanistic-unlearning/localizations/eap/eap_demo.ipynb#W4sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mprint\u001b[39m(top_edges)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aaquibsyed/Documents/Python/mechanistic-unlearning/localizations/eap/eap_demo.ipynb#W4sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aaquibsyed/Documents/Python/mechanistic-unlearning/localizations/eap/eap_demo.ipynb#W4sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m graph\u001b[39m.\u001b[39;49mshow(threshold\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, abs_scores\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, fname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39meap_subgraph_bs=100.png\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Python/mechanistic-unlearning/localizations/eap/eap_graph.py:316\u001b[0m, in \u001b[0;36mEAPGraph.show\u001b[0;34m(self, threshold, abs_scores, fname)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow\u001b[39m(\n\u001b[1;32m    311\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    312\u001b[0m     threshold\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    313\u001b[0m     abs_scores\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m     fname: \u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meap_graph.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m ):\n\u001b[0;32m--> 316\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpygraphviz\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpgv\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     minimum_penwidth \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[1;32m    319\u001b[0m     edges \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtop_edges(threshold\u001b[39m=\u001b[39mthreshold, abs_scores\u001b[39m=\u001b[39mabs_scores)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'"
     ]
    }
   ],
   "source": [
    "from localizations.eap.eap_wrapper import EAP\n",
    "\n",
    "def ave_logit_diff(\n",
    "    logits,\n",
    "    per_prompt: bool = False\n",
    "):\n",
    "    '''\n",
    "        Return average logit difference between correct and incorrect answers\n",
    "    '''\n",
    "    # Get logits for indirect objects\n",
    "    yes_logits = logits[range(logits.size(0)), -1, 18585]\n",
    "    no_logits = logits[range(logits.size(0)), -1, 8221]\n",
    "    #print(io_logits)\n",
    "    #print(s_logits)\n",
    "    # Get logits for subject\n",
    "    logit_diff = no_logits - yes_logits \n",
    "    return logit_diff if per_prompt else logit_diff.mean()\n",
    "\n",
    "with torch.no_grad():\n",
    "    clean_logits = model(clean_dataset.toks)\n",
    "    corrupt_logits = model(corr_dataset.toks)\n",
    "    clean_logit_diff = ave_logit_diff(clean_logits).item()\n",
    "    corrupt_logit_diff = ave_logit_diff(corrupt_logits).item()\n",
    "\n",
    "def refusals_metric(\n",
    "    logits,\n",
    "    corrupted_logit_diff: float = corrupt_logit_diff,\n",
    "    clean_logit_diff: float = clean_logit_diff,\n",
    " ):\n",
    "    patched_logit_diff = ave_logit_diff(logits)\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (clean_logit_diff - corrupted_logit_diff)\n",
    "\n",
    "# Get clean and corrupt logit differences\n",
    "with torch.no_grad():\n",
    "    clean_metric = refusals_metric(clean_logits, corrupt_logit_diff, clean_logit_diff)\n",
    "    corrupt_metric = refusals_metric(corrupt_logits, corrupt_logit_diff, clean_logit_diff)\n",
    "\n",
    "print(f'Clean direction: {clean_logit_diff}, Corrupt direction: {corrupt_logit_diff}')\n",
    "print(f'Clean metric: {clean_metric}, Corrupt metric: {corrupt_metric}')\n",
    "\n",
    "# %%\n",
    "\n",
    "model.reset_hooks()\n",
    "\n",
    "#%%\n",
    "from eap_wrapper import EAP\n",
    "\n",
    "graph = EAP(\n",
    "    model,\n",
    "    clean_dataset.toks,\n",
    "    corr_dataset.toks,\n",
    "    refusals_metric,\n",
    "    upstream_nodes=[\"mlp\", \"head\"],\n",
    "    downstream_nodes=[\"mlp\", \"head\"],\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "# %%\n",
    "\n",
    "top_edges = graph.top_edges(n=100, abs_scores=True)\n",
    "print(top_edges)\n",
    "\n",
    "# %%\n",
    "\n",
    "graph.show(threshold=0.01, abs_scores=True, fname=\"eap_subgraph_bs=100.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
