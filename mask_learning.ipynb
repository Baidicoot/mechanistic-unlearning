{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up models for edge or weight masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow:\n",
    "- Load model\n",
    "- Use Task with clean and corrupt data, use ACDCPP and get the ACDCPP-style edges\n",
    "- Convert ACDCPP-style edges to edge mask, get either edge superset of node superset\n",
    "- Apply these masks to the mask training, either by limiting edge mask to only edge superset, node superset, or by limiting weight mask to node superset\n",
    "\n",
    "- Also need to test other baselines, like regular finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append('acdcpp/Automatic-Circuit-Discovery/')\n",
    "sys.path.append('acdcpp/')\n",
    "from acdc import TLACDCExperiment\n",
    "from acdcpp.ACDCPPExperiment import ACDCPPExperiment\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "from acdc.acdc_utils import TorchIndex, EdgeType\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import itertools\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "import tqdm.notebook as tqdm\n",
    "import plotly\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from jaxtyping import Float, Bool\n",
    "from typing import Callable, Tuple, Union, Dict, Optional\n",
    "import torch\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(f'Device: {device}')\n",
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "from cb_utils.mask_utils import get_masks_from_acdcpp_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Load the configuration file\n",
    "config_dir = \"masks/induction/weight_masks_localize=acdcpp\"\n",
    "with open(config_dir+\"/config.json\", 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "use_pythia = config.get('use_pythia', False)\n",
    "\n",
    "# Now you can use these arguments in your code\n",
    "edge_masks = config.get('edge_masks', False)\n",
    "weight_masks_attn = config.get('weight_masks_attn', False)\n",
    "weight_masks_mlp = config.get('weight_masks_mlp', False)\n",
    "train_base_weights = config.get('train_base_weights', False)\n",
    "localize_acdcpp = config.get('localize_acdcpp', False)\n",
    "localize_ct = config.get('localize_ct', False)\n",
    "\n",
    "assert not (localize_acdcpp and localize_ct), \"Cannot localize with both acdcpp and ct\"\n",
    "\n",
    "# localization_method = config.get('localization_method', None)\n",
    "# assert \"acdcpp\" == localization_method or \n",
    "localize_task = config.get('localize_task', \"induction\")\n",
    "\n",
    "use_uniform = config.get('use_uniform', False)\n",
    "uniform_type = config.get('uniform_type', \"all_tokens\")\n",
    "exclude_correct = config.get('exclude_correct', True)\n",
    "\n",
    "unlrn_task_weight = config.get('unlrn_task_weight', -0.2)\n",
    "epochs_left = config.get('epochs_left', 200)\n",
    "steps_per_epoch = config.get('steps_per_epoch', 20)\n",
    "accum_grad_steps = config.get('accum_grad_steps', 1)\n",
    "lr = config.get('lr', 0.01)\n",
    "weight_decay = config.get('weight_decay', 0)\n",
    "evaluate_every = config.get('evaluate_every', 2)\n",
    "discretize_every = config.get('discretize_every', 40)\n",
    "threshold = config.get('threshold', 0.5)\n",
    "mask_k = config.get('mask_k', None)\n",
    "\n",
    "use_wandb = config.get('use_wandb', True)\n",
    "edge_mask_reg_strength = config.get('edge_mask_reg_strength', 100)\n",
    "weight_mask_reg_strength = config.get('weight_mask_reg_strength', 100)\n",
    "num_eval_steps = config.get('num_eval_steps', 10)\n",
    "save_every = config.get('save_every', None)\n",
    "# For 'save_path', since the default is not provided in the JSON, assuming None as default\n",
    "save_path = config.get('save_path', None)\n",
    "save_efficient = config.get('save_efficient', True)\n",
    "# Assuming 'scale_reg_strength' is also a parameter you want to load with a default value\n",
    "scale_reg_strength = config.get('scale_reg_strength', False)\n",
    "localization_dir_path = config.get('localization_dir_path', None)\n",
    "# If save_path is None, set it to the directory of the config file\n",
    "if config['save_path'] is None:\n",
    "    save_path = config_dir + f\"/ckpts\"\n",
    "\n",
    "if localization_dir_path is None:\n",
    "    localization_method = None\n",
    "    if localize_acdcpp:\n",
    "        localization_method = \"acdcpp\"\n",
    "    elif localize_ct:\n",
    "        localization_method = \"ct\"\n",
    "    localization_dir_path = f\"localizations/{localize_task}/{localization_method}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Localizations and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if localize_acdcpp or localize_ct:\n",
    "    with open(f\"{localization_dir_path}\", \"rb\") as f:\n",
    "        acdcpp_nodes, acdcpp_edges, acdcpp_mask_dict, acdcpp_weight_mask_attn_dict, acdcpp_weight_mask_mlp_dict = pickle.load(f)\n",
    "\n",
    "    mask_dict_superset = acdcpp_mask_dict if edge_masks else None\n",
    "    weight_mask_attn_dict = acdcpp_weight_mask_attn_dict if weight_masks_attn else None\n",
    "    weight_mask_mlp_dict = acdcpp_weight_mask_mlp_dict if weight_masks_mlp else None\n",
    "    base_weight_attn_dict = acdcpp_weight_mask_attn_dict if train_base_weights else None\n",
    "    base_weight_mlp_dict = acdcpp_weight_mask_mlp_dict if train_base_weights else None\n",
    "\n",
    "else:\n",
    "    acdcpp_nodes = None\n",
    "    acdcpp_edges = None\n",
    "    acdcpp_mask_dict = None\n",
    "    acdcpp_weight_mask_attn_dict = None\n",
    "    acdcpp_weight_mask_mlp_dict = None\n",
    "\n",
    "    mask_dict_superset = None\n",
    "    weight_mask_attn_dict = None\n",
    "    weight_mask_mlp_dict = None\n",
    "    base_weight_attn_dict = None\n",
    "    base_weight_mlp_dict = None\n",
    "\n",
    "\n",
    "print(acdcpp_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cb_utils.transformer import DemoTransformer\n",
    "from cb_utils.models import load_demo_gpt2, tokenizer, load_demo_pythia\n",
    "\n",
    "if use_pythia:\n",
    "    if edge_masks:\n",
    "        model = load_demo_pythia(means=False, model_name=\"pythia-2.8b\", \n",
    "                                #  edge_masks=edge_masks, \n",
    "                                mask_dict_superset=mask_dict_superset,)\n",
    "    elif weight_masks_attn or weight_masks_mlp:\n",
    "        model = load_demo_pythia(means=False, model_name=\"pythia-2.8b\", edge_mask=False, weight_mask=True, \n",
    "                                #  weight_masks_attn=True, weight_masks_mlp=True, \n",
    "                                weight_mask_attn_dict=weight_mask_attn_dict, weight_mask_mlp_dict=weight_mask_mlp_dict)\n",
    "\n",
    "else:\n",
    "    if edge_masks:\n",
    "        model = load_demo_gpt2(means=False, edge_mask=True, weight_mask=False,\n",
    "                        #    edge_masks=edge_masks, \n",
    "                        mask_dict_superset=mask_dict_superset)\n",
    "    elif weight_masks_attn or weight_masks_mlp:\n",
    "        model = load_demo_gpt2(means=False, edge_mask=False, weight_mask=True,\n",
    "                        #    weight_masks_attn=weight_masks_attn, weight_masks_mlp=weight_masks_mlp, \n",
    "                        weight_mask_attn_dict=weight_mask_attn_dict, weight_mask_mlp_dict=weight_mask_mlp_dict)\n",
    "    else:\n",
    "        model = load_demo_gpt2(means=False, edge_mask=False, weight_mask=False,\n",
    "                        edge_masks=edge_masks, mask_dict_superset=mask_dict_superset, weight_masks_attn=weight_masks_attn, weight_masks_mlp=weight_masks_mlp, weight_mask_attn_dict=weight_mask_attn_dict, weight_mask_mlp_dict=weight_mask_mlp_dict, train_base_weights=train_base_weights, base_weight_attn_dict=base_weight_attn_dict, base_weight_mlp_dict=base_weight_mlp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pythia:\n",
    "    from tasks import IOITask, SportsTask, OWTTask, IOITask_Uniform, GreaterThanTask, InductionTask, InductionTask_Uniform, SportsTask_Uniform\n",
    "    test_batch_size = 32\n",
    "    sports = SportsTask(batch_size=test_batch_size, tokenizer=tokenizer, device=device)\n",
    "    owt = OWTTask(batch_size=test_batch_size, tokenizer=tokenizer, device=device, ctx_length=30)\n",
    "    ioi = IOITask(batch_size=test_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, nb_templates=4, prompt_type=\"ABBA\")\n",
    "    induction = InductionTask(batch_size=test_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15)\n",
    "\n",
    "    train_batch_size=4\n",
    "    owt_train = OWTTask(batch_size=3, tokenizer=tokenizer, device=device, ctx_length=30)\n",
    "    if localize_task == \"ioi\":\n",
    "\n",
    "        ioi_task_2 = IOITask(batch_size=test_batch_size, tokenizer=tokenizer, device=device, nb_templates=1, prompt_type=\"ABBA\", template_start_idx=4) # slightly different template\n",
    "\n",
    "        ioi_task_3 = IOITask(batch_size=test_batch_size, tokenizer=tokenizer, device=device, nb_templates=1, prompt_type=\"BABA\", template_start_idx=0) # different name format\n",
    "\n",
    "        # train_tasks = {\"ioi\": ioi, \"owt\": owt}\n",
    "        if use_uniform:\n",
    "            ioi_uniform = IOITask_Uniform(batch_size=train_batch_size, tokenizer=tokenizer, device=device, uniform_over=uniform_type, nb_templates=4, prompt_type=\"ABBA\")\n",
    "            train_tasks = {\"ioi_uniform\": ioi_uniform, \"owt\": owt_train}\n",
    "            task_weights = {\"ioi_uniform\": unlrn_task_weight, \"owt\": 1} # I think means preserve OWT, corrupt IOI\n",
    "        else: \n",
    "            ioi_train = IOITask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, nb_templates=4, prompt_type=\"ABBA\")\n",
    "            train_tasks = {\"ioi\": ioi_train, \"owt\": owt_train}\n",
    "            task_weights = {\"ioi\": unlrn_task_weight, \"owt\": 1}\n",
    "\n",
    "        eval_tasks = {\"ioi\": ioi, \"induction\": induction, \"owt\": owt, \"ioi_2\": ioi_task_2, \"ioi_3\": ioi_task_3, \"sports\": sports}\n",
    "\n",
    "    elif localize_task == \"induction\":\n",
    "        if use_uniform:\n",
    "            induction_uniform = InductionTask_Uniform(batch_size=train_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, uniform_over=uniform_type)\n",
    "            train_tasks = {\"induction_uniform\": induction_uniform, \"owt\": owt_train}\n",
    "            task_weights = {\"induction_uniform\": unlrn_task_weight, \"owt\": 1}\n",
    "\n",
    "        else:\n",
    "            induction_train = InductionTask(batch_size=train_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15)\n",
    "            train_tasks = {\"induction\": induction_train, \"owt\": owt_train}\n",
    "            task_weights = {\"induction\": unlrn_task_weight, \"owt\": 1}\n",
    "\n",
    "        eval_tasks = {\"ioi\": ioi, \"induction\": induction, \"owt\": owt, \"sports\": sports}\n",
    "\n",
    "    elif localize_task == \"sports\":\n",
    "        if use_uniform:\n",
    "            sports_uniform = SportsTask_Uniform(batch_size=train_batch_size, tokenizer=tokenizer, uniform_over=uniform_type)\n",
    "            train_tasks = {\"sports_uniform\": sports_uniform, \"owt\": owt_train}\n",
    "            task_weights = {\"sports_uniform\": unlrn_task_weight, \"owt\": 1}\n",
    "        \n",
    "        else:\n",
    "            sports_train = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer)\n",
    "            train_tasks = {\"sports\": sports_train, \"owt\": owt_train}\n",
    "            task_weights = {\"sports\": unlrn_task_weight, \"owt\": 1}\n",
    "\n",
    "        eval_tasks = {\"ioi\": ioi, \"induction\": induction, \"owt\": owt, \"sports\": sports}\n",
    "\n",
    "    elif localize_task == \"sports_limited\":\n",
    "        maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, start_index=64, stop_index=-128, train_test_split=False)\n",
    "        if use_uniform:\n",
    "            forget_sports_uniform = SportsTask_Uniform(batch_size=train_batch_size, tokenizer=tokenizer, uniform_over=uniform_type, start_index=0, stop_index=64, train_test_split=False)\n",
    "            train_tasks = {\"forget_sports_uniform\": forget_sports_uniform, \"maintain_sports\": maintain_sports, \"owt\": owt_train}\n",
    "            task_weights = {\"forget_sports_uniform\": unlrn_task_weight, \"maintain_sports\": 1, \"owt\": 1}\n",
    "\n",
    "        else:\n",
    "            forget_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, start_index=0, stop_index=64, train_test_split=False)\n",
    "            train_tasks = {\"forget_sports\": forget_sports, \"maintain_sports\": maintain_sports, \"owt\": owt_train}\n",
    "            task_weights = {\"forget_sports\": unlrn_task_weight, \"maintain_sports\": 1, \"owt\": 1}\n",
    "\n",
    "        forget_sports_eval = SportsTask(batch_size=test_batch_size, tokenizer=tokenizer, start_index=0, stop_index=64, train_test_split=False)\n",
    "        maintain_sports_eval = SportsTask(batch_size=test_batch_size, tokenizer=tokenizer, start_index=64, stop_index=-128, train_test_split=False)\n",
    "        other_sports = SportsTask(batch_size=test_batch_size, tokenizer=tokenizer, start_index=-128, train_test_split=False)\n",
    "        eval_tasks = {\"ioi\": ioi, \"induction\": induction, \"owt\": owt, \"forget_sports\": forget_sports_eval, \"maintain_sports\": maintain_sports_eval, \"other_sports\": other_sports}\n",
    "\n",
    "else:\n",
    "\n",
    "    from tasks import IOITask, SportsTask, OWTTask, IOITask_Uniform, GreaterThanTask, InductionTask, InductionTask_Uniform\n",
    "    batch_size = 80\n",
    "    # sports = SportsTask(batch_size=batch_size*2, tokenizer=tokenizer, device=device)\n",
    "    owt = OWTTask(batch_size=batch_size, tokenizer=tokenizer, device=device, ctx_length=40)\n",
    "    greaterthan = GreaterThanTask(batch_size=batch_size, tokenizer=tokenizer, device=device)\n",
    "    ioi = IOITask(batch_size=batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, nb_templates=4, prompt_type=\"ABBA\")\n",
    "    induction = InductionTask(batch_size=batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15)\n",
    "\n",
    "    if localize_task == \"ioi\":\n",
    "        ioi_uniform = IOITask_Uniform(batch_size=batch_size, tokenizer=tokenizer, device=device, uniform_over=uniform_type, nb_templates=4, prompt_type=\"ABBA\", exclude_correct=exclude_correct)\n",
    "\n",
    "        ioi_task_2 = IOITask(batch_size=batch_size*2, tokenizer=tokenizer, device=device, nb_templates=1, prompt_type=\"ABBA\", template_start_idx=4) # slightly different template\n",
    "\n",
    "        ioi_task_3 = IOITask(batch_size=batch_size*2, tokenizer=tokenizer, device=device, nb_templates=1, prompt_type=\"BABA\", template_start_idx=0) # different name format\n",
    "\n",
    "        # train_tasks = {\"ioi\": ioi, \"owt\": owt}\n",
    "        if use_uniform:\n",
    "            train_tasks = {\"ioi_uniform\": ioi_uniform, \"owt\": owt}\n",
    "            task_weights = {\"ioi_uniform\": unlrn_task_weight, \"owt\": 1} # I think means preserve OWT, corrupt IOI\n",
    "        else:\n",
    "            train_tasks = {\"ioi\": ioi, \"owt\": owt}\n",
    "            task_weights = {\"ioi\": unlrn_task_weight, \"owt\": 1}\n",
    "\n",
    "        eval_tasks = {\"ioi\": ioi, \"induction\": induction, \"owt\": owt, \"ioi_2\": ioi_task_2, \"ioi_3\": ioi_task_3, \"greaterthan\": greaterthan}\n",
    "\n",
    "    elif localize_task == \"induction\":\n",
    "        induction_uniform = InductionTask_Uniform(batch_size=batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, uniform_over=uniform_type, exclude_correct=exclude_correct)\n",
    "        \n",
    "        if use_uniform:\n",
    "            train_tasks = {\"induction_uniform\": induction_uniform, \"owt\": owt}\n",
    "            task_weights = {\"induction_uniform\": unlrn_task_weight, \"owt\": 1}\n",
    "\n",
    "        else:\n",
    "            train_tasks = {\"induction\": induction, \"owt\": owt}\n",
    "            task_weights = {\"induction\": unlrn_task_weight, \"owt\": 1}\n",
    "\n",
    "        eval_tasks = {\"ioi\": ioi, \"induction\": induction, \"owt\": owt, \"greaterthan\": greaterthan}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_params = []\n",
    "param_names = []\n",
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        param_names.append(name)\n",
    "        mask_params.append(p)\n",
    "\n",
    "print(param_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Mask Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cb_utils.learn_mask import *\n",
    "def train_masks(model, \n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                tasks: dict[str, Task],\n",
    "                task_weights: dict[str, float],\n",
    "                num_epochs: int, \n",
    "                param_names: Optional[list[str]]=None,\n",
    "                mask_params: Optional[list[torch.nn.parameter.Parameter]]=None,\n",
    "                eval_tasks: dict[str, Task]=None,\n",
    "                steps_per_epoch=100,\n",
    "                accum_grad_steps=1,\n",
    "                evaluate_every=10, \n",
    "                discretize_every=50, \n",
    "                save_every=None,\n",
    "\n",
    "                threshold=0.5, \n",
    "                mask_k=None,\n",
    "                edge_mask_reg_strength: Optional[Union[float, Callable[..., float]]]=None, \n",
    "                weight_mask_reg_strength: Optional[Union[float, Callable[..., float]]]=None,\n",
    "                \n",
    "                num_eval_steps=1,\n",
    "                verbose=False,\n",
    "                use_wandb=False,\n",
    "                wandb_config=None,\n",
    "                save_dir=None,\n",
    "                save_efficient=False,\n",
    "                refresh_memory=False,\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Train a model using tasks (weight the overall loss by task_weights). For now, planned to be training differentiable binary masks over the weights and edges of the model.\n",
    "    \n",
    "    Parameters:\n",
    "    model: DemoTransformer, the model to use for training and evaluation. If edge or weight mask should be frozen, do this to model before passing it in.\n",
    "    optimizer: torch.optim.Optimizer, the optimizer to use for training. For now, planned to be over edge mask and weight mask parameters.\n",
    "\n",
    "    accum_grad_steps: int, the number of steps to accumulate gradients over before taking a step. This is useful for large batch sizes that don't fit in memory (use a small batch size in task, increase it effectively by increasing accum_grad_steps).\n",
    "\n",
    "    param_names: list of strings, the names of the parameters of the model that should be optimized (typically everything covered by optimizer). If None, defaults to params of model that are not frozen.\n",
    "    mask_params: list of torch.nn.parameter.Parameter, the parameters of the model that should be optimized (typically everything covered by optimizer). If None, defaults to params of model that are not frozen.\n",
    "\n",
    "    tasks: dictionary of Tasks with names for keys, the tasks to train on\n",
    "    task_weights: dictionary floats, the weights to use for each task\n",
    "    num_epochs: int, the number of epochs to train for\n",
    "\n",
    "    eval_tasks: either None or a dictionary of tasks with task names. If none, evaluate on the training tasks.\n",
    "    steps_per_epoch: int, the maximum number of steps to train for each epoch\n",
    "    evaluate_every: int, the number of steps between evaluations\n",
    "    discretize_every: int, the number of steps between \"discretizeing\" weights. In this context, means setting all weights below a threshold to 0 and all weights above a threshold to 1.\n",
    "    threshold: float, the threshold to use for discretizeing weights\n",
    "\n",
    "    edge_mask_reg_strength: float or function of epoch, the strength of the regularization on the edge masks. If None, no regularization on edge mask is used. Should be None if edge masks not being optimized. Baseline can be 1\n",
    "    weight_mask_reg_strength: float or function of epoch, the strength of the regularization on the weight masks. If None, no regularization on weight mask is used. Should be None if weight masks not being optimized or if weight masks are being optimized in optimizer with some other regularization.\n",
    "\n",
    "    wandb_config: dictionary of additional things to add to wandb config\n",
    "    \"\"\"\n",
    "    if param_names is None or mask_params is None:\n",
    "        param_names = []\n",
    "        mask_params = []\n",
    "        for name, p in model.named_parameters():\n",
    "            if p.requires_grad:\n",
    "                param_names.append(name)\n",
    "                mask_params.append(p)\n",
    "\n",
    "    if eval_tasks is None:\n",
    "        eval_tasks = tasks\n",
    "    \n",
    "    if use_wandb:\n",
    "        # Initialize a config dictionary with existing configuration\n",
    "        config = {\n",
    "            \"epochs\": num_epochs,\n",
    "            \"steps_per_epoch\": steps_per_epoch,\n",
    "            \"edge_mask_reg_strength\": edge_mask_reg_strength,\n",
    "            \"weight_mask_reg_strength\": weight_mask_reg_strength,\n",
    "        }\n",
    "        if wandb_config is not None:\n",
    "            config.update(wandb_config)\n",
    "\n",
    "        # Update the config dictionary with task_weights\n",
    "        config.update(task_weights)\n",
    "\n",
    "        # Initialize wandb with the updated config\n",
    "        wandb.init(project=\"mech_unlearning\", config=config)\n",
    "\n",
    "    # model = load_demo_gpt2(means=means, weight_masks_attn=weight_masks_attn, weight_masks_mlp=weight_masks_mlp)\n",
    "    train_losses = defaultdict(list)\n",
    "    test_losses = defaultdict(list)\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs+1)):\n",
    "        model.zero_grad()\n",
    "\n",
    "        if refresh_memory:\n",
    "            print(\"refreshing cuda memory\")\n",
    "            start = time.time()\n",
    "            refresh_cuda_memory()\n",
    "            print(f\"finished refreshing, time taken: {time.time() - start}\")\n",
    "        for step in range(steps_per_epoch):\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch}, step {step}\")\n",
    "            model.zero_grad()\n",
    "            total_loss = 0\n",
    "            for task_name, task in tasks.items():\n",
    "                task_loss = 0\n",
    "                for i in range(accum_grad_steps):\n",
    "                    # print(f\"Current memory usage on {task_name}, {i}: \", torch.cuda.memory_allocated(device=\"cuda\") / 1e9)\n",
    "                    loss = task.get_train_loss(model)\n",
    "                    # add item (without gradients to avoid memory leak) to train_losses\n",
    "                    train_losses[task_name].append((epoch, step, loss.item()))\n",
    "                    total_loss += loss.item() * task_weights[task_name]\n",
    "                    task_loss += loss.item()\n",
    "                    loss.backward()\n",
    "                if use_wandb:\n",
    "                    wandb.log({f\"train_loss_{task_name}\": task_loss / accum_grad_steps}, step=epoch*steps_per_epoch + step)\n",
    "\n",
    "            # Add regularization losses for edge and weight masks, l1\n",
    "            \n",
    "            edge_reg_term = 0\n",
    "            weight_reg_term = 0\n",
    "            tot_edge_params = 0\n",
    "            tot_weight_params = 0\n",
    "            \n",
    "            if hasattr(model, \"get_edge_reg\"):\n",
    "                edge_reg_term, tot_edge_params = model.get_edge_reg()\n",
    "            \n",
    "            if hasattr(model, \"get_weight_reg\"):\n",
    "                weight_reg_term, tot_weight_params = model.get_weight_reg()\n",
    "            # for name, p in zip(param_names, mask_params):\n",
    "            #     if \"edge_mask\" in name:\n",
    "            #         # get l1 norm of edge mask\n",
    "            #         edge_reg_term += p.abs().sum()\n",
    "            #         tot_edge_params += p.numel()\n",
    "\n",
    "            #     elif \"weight_mask\" in name:\n",
    "            #         weight_reg_term += p.abs().sum()\n",
    "            #         tot_weight_params += p.numel()\n",
    "            \n",
    "            if tot_edge_params > 0:\n",
    "                edge_reg_term /= tot_edge_params\n",
    "            if tot_weight_params > 0:\n",
    "                weight_reg_term /= tot_weight_params\n",
    "\n",
    "            if edge_mask_reg_strength is not None:\n",
    "                if callable(edge_mask_reg_strength):\n",
    "                    edge_mask_reg_strength_val = edge_mask_reg_strength(epoch)\n",
    "                else:\n",
    "                    edge_mask_reg_strength_val = edge_mask_reg_strength\n",
    "                \n",
    "                # if verbose:\n",
    "                #     print(f\"{edge_reg_term=}, {tot_edge_params=}\")\n",
    "                train_losses['edge_reg_term'].append((epoch, step, edge_reg_term))\n",
    "                if use_wandb:\n",
    "                    wandb.log({\"edge_reg_term\": edge_reg_term}, step=epoch*steps_per_epoch + step)\n",
    "                edge_reg_loss = - edge_reg_term * edge_mask_reg_strength_val\n",
    "                try:\n",
    "                    total_loss += edge_reg_loss.item()\n",
    "                    edge_reg_loss.backward()\n",
    "                except:\n",
    "                    total_loss += edge_reg_loss\n",
    "\n",
    "            if weight_mask_reg_strength is not None:\n",
    "                if callable(weight_mask_reg_strength):\n",
    "                    weight_mask_reg_strength_val = weight_mask_reg_strength(epoch)\n",
    "                else:\n",
    "                    weight_mask_reg_strength_val = weight_mask_reg_strength\n",
    "\n",
    "                train_losses['weight_mask_reg'].append((epoch, step, weight_reg_term))\n",
    "                if use_wandb:\n",
    "                    wandb.log({\"weight_mask_reg\": weight_reg_term}, step=epoch*steps_per_epoch + step)\n",
    "                weight_reg_loss = -weight_reg_term * weight_mask_reg_strength_val\n",
    "                try:\n",
    "                    total_loss += weight_reg_loss.item()\n",
    "                    weight_reg_loss.backward()\n",
    "                except:\n",
    "                    total_loss += weight_reg_loss\n",
    "            \n",
    "\n",
    "            # train_losses['total'].append((epoch, step, total_loss.item()))\n",
    "            # total_loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            for p in mask_params:\n",
    "                p.data.clamp_(0,1)\n",
    "            # if use_wandb:\n",
    "            #     wandb.log({\"total_loss\": total_loss.item()}, step=epoch*steps_per_epoch + step)\n",
    "\n",
    "        if discretize_every is not None and epoch % discretize_every == 0:\n",
    "            if verbose:\n",
    "                print(f\"discretizeing edges and weights\")\n",
    "            num_ablated_edges, num_ablated_weights = discretize_weights(param_names, mask_params, edge_threshold=threshold, weight_threshold=threshold, top_k=mask_k)\n",
    "            if verbose:\n",
    "                print(f\"Number of ablated edges: {num_ablated_edges}\")\n",
    "                print(f\"Number of ablated weights: {num_ablated_weights}\")\n",
    "            if use_wandb:\n",
    "                wandb.log({\"num_ablated_edges\": num_ablated_edges}, step=epoch*steps_per_epoch + step)\n",
    "                wandb.log({\"num_ablated_weights\": num_ablated_weights}, step=epoch*steps_per_epoch + step)\n",
    "\n",
    "\n",
    "        if evaluate_every is not None and epoch % evaluate_every == 0:\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch}, step {step}: train loss {total_loss}\")\n",
    "            \n",
    "            # Save a copy of the original weights\n",
    "            original_weights = [p.data.clone() for p in mask_params]\n",
    "            \n",
    "            # Discretize weights for evaluation\n",
    "            num_ablated_edges, num_ablated_weights = discretize_weights(param_names, mask_params, edge_threshold=threshold, weight_threshold=threshold, top_k=mask_k)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{num_ablated_edges=}, {num_ablated_weights=}\")\n",
    "            if use_wandb:\n",
    "                wandb.log({\"num_ablated_edges\": num_ablated_edges}, step=epoch*steps_per_epoch + step)\n",
    "                wandb.log({\"num_ablated_weights\": num_ablated_weights}, step=epoch*steps_per_epoch + step)\n",
    "\n",
    "            model.eval()\n",
    "            step_eval_losses = evaluate_model(model, eval_tasks, num_eval_steps, verbose=verbose)\n",
    "            # for task_name, task in eval_tasks.items():\n",
    "            for task_name in step_eval_losses.keys():\n",
    "                # test_losses[task_name].append((epoch, step, step_eval_losses[task_name]))\n",
    "                test_losses[task_name].append(step_eval_losses[task_name])\n",
    "                if use_wandb:\n",
    "                    wandb.log({f\"test_loss_{task_name}\": step_eval_losses[task_name]}, step=epoch*steps_per_epoch + step)\n",
    "\n",
    "            # Restore the original weights after evaluation\n",
    "            for p, original_weight in zip(mask_params, original_weights):\n",
    "                p.data = original_weight\n",
    "\n",
    "\n",
    "        if save_every is not None and epoch % save_every == 0:\n",
    "            # save params\n",
    "            if save_dir is None:\n",
    "                # get date and time to save\n",
    "                now = datetime.now()\n",
    "                dt_string = now.strftime(\"%d_%m_%Y_%H:%M:%S\")\n",
    "                if save_efficient:\n",
    "                    model_path = f\"masks/mask_params_{dt_string}_{epoch=}.pkl\"\n",
    "                    with open(model_path, \"wb\") as f:\n",
    "                        pickle.dump((param_names, mask_params), f)\n",
    "                else:\n",
    "                    model_path = f\"masks/mask_params_{dt_string}_{epoch=}.pth\"\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "            else:\n",
    "                # make sure save_dir exists\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "                if save_efficient:\n",
    "                    model_path = f\"{save_dir}/mask_params_{epoch=}.pkl\"\n",
    "                    with open(model_path, \"wb\") as f:\n",
    "                        pickle.dump((param_names, mask_params), f)\n",
    "                else:\n",
    "                    model_path = f\"{save_dir}/mask_params_{epoch=}.pth\"\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.finish()\n",
    "    return train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check DemoTransformer Implementations Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.2482e-06, device='cuda:0')\n",
      "tensor(7.2237e-06, device='cuda:0')\n",
      "tensor(6.9957e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from cb_utils.transformers.gpt2.edge_masked_transformer import DemoTransformer as GPT2EdgeDemoTransformer, Config as GPT2Config\n",
    "\n",
    "from cb_utils.models import tl_config_to_demo_config\n",
    "with open(\"models/gpt2_weights.pkl\", \"rb\") as f:\n",
    "    gpt2_weights = pickle.load(f)\n",
    "demo_edge_gpt2 = GPT2EdgeDemoTransformer(GPT2Config(debug=False, n_layers=12, n_heads=12), means=False)\n",
    "demo_edge_gpt2.load_state_dict(gpt2_weights, strict=False)\n",
    "demo_edge_gpt2.cuda()\n",
    "\n",
    "\n",
    "from cb_utils.transformers.gpt2.weight_masked_transformer import DemoTransformer as GPT2WeightDemoTransformer, Config as GPT2Config\n",
    "demo_weight_gpt2 = GPT2WeightDemoTransformer(GPT2Config(debug=False, n_layers=12, n_heads=12))\n",
    "demo_weight_gpt2.load_state_dict(gpt2_weights, strict=False)\n",
    "demo_weight_gpt2.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_input = t.tensor(gpt2_tokenizer.encode(\"The quick brown fox jumps over the lazy\")).unsqueeze(0).cuda()\n",
    "    print((demo_edge_gpt2(test_input)[0][0, -1] - reference_gpt2(test_input)[0, -1]).std())\n",
    "    print((demo_weight_gpt2(test_input)[0][0, -1] - reference_gpt2(test_input)[0, -1]).std())\n",
    "    print((demo_edge_gpt2(test_input)[0][0, -1] - demo_weight_gpt2(test_input)[0][0, -1]).std())\n",
    "    # print((model(test_input)[0][0, -1] - edge_masked_model(test_input)[0][0, -1]).std())\n",
    "    # print((reference_pythia(test_input)[0, -1] - edge_masked_model(test_input)[0][0, -1]).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ACDCPP edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key not found, will not be able to run evaluations on HPSAQ Task\n",
      "OpenAI API key not found, will not be able to run evaluations on HPSAQ Task\n",
      "Clean logit diff: 3.040117025375366, Corrupted logit diff: 1.2651995420455933\n",
      "Clean logit diff: 3.040, Corrupt logit diff: 1.265\n"
     ]
    }
   ],
   "source": [
    "from tasks.ioi.IOITask import IOITask_old, IOITask\n",
    "# ioi_task = IOITask(batch_size=5, tokenizer=model.tokenizer, device=device, prep_acdcpp=True, acdcpp_N=25)\n",
    "ioi_task = IOITask(batch_size=5, tokenizer=model.tokenizer, device=device, prep_acdcpp=True, acdcpp_N=25, nb_templates=1, prompt_type=\"ABBA\")\n",
    "ioi_task.set_logit_diffs(model)\n",
    "\n",
    "ioi_metric = ioi_task.get_acdcpp_metric()\n",
    "def negative_abs_ioi_metric(logits: Float[Tensor, \"batch seq_len d_vocab\"]):\n",
    "    return -abs(ioi_metric(logits))\n",
    "\n",
    "with t.no_grad():\n",
    "    clean_logits = model(ioi_task.clean_data.toks)\n",
    "    corrupt_logits = model(ioi_task.corr_data.toks)\n",
    "    clean_logit_diff = ioi_task.ave_logit_diff(clean_logits, ioi_task.clean_data).item()\n",
    "    corrupt_logit_diff = ioi_task.ave_logit_diff(corrupt_logits, ioi_task.corr_data).item()\n",
    "    print(f'Clean logit diff: {clean_logit_diff:.3f}, Corrupt logit diff: {corrupt_logit_diff:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_metric(clean_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_metric(corrupt_logits, ioi_dataset=ioi_task.corr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.040117025375366, 1.2651995420455933)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_logit_diff, corrupt_logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PLACE]': ['station',\n",
       "  'restaurant',\n",
       "  'restaurant',\n",
       "  'restaurant',\n",
       "  'restaurant'],\n",
       " '[OBJECT]': ['ring', 'computer', 'necklace', 'bone', 'computer'],\n",
       " 'text': ['Then, William and Richard went to the station. William gave a ring to',\n",
       "  'Then, Charles and Jeremy went to the restaurant. Charles gave a computer to',\n",
       "  'Then, Simon and Clark went to the restaurant. Simon gave a necklace to',\n",
       "  'Then, Jacob and Scott went to the restaurant. Jacob gave a bone to',\n",
       "  'Then, Steven and Sullivan went to the restaurant. Steven gave a computer to'],\n",
       " 'IO': ['Richard', 'Jeremy', 'Clark', 'Scott', 'Sullivan'],\n",
       " 'S': ['William', 'Charles', 'Simon', 'Jacob', 'Steven'],\n",
       " 'TEMPLATE_IDX': tensor([0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ioi_task_2 = IOITask(batch_size=5, tokenizer=model.tokenizer, device=device, prep_acdcpp=True, acdcpp_N=25, nb_templates=1, prompt_type=\"BABA\", template_start_idx=0)\n",
    "ioi_task_2.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 15299.74it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:04<00:00, 258.14it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 281818.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([-1, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:08<00:08,  8.11s/it]WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 15224.87it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:04<00:00, 253.97it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 306343.88it/s]\n",
      "100%|██████████| 2/2 [00:15<00:00,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([-1, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "from cb_utils.mask_utils import get_masks_from_acdcpp_exp\n",
    "THRESHOLDS = [0.08, .15]#np.arange(0.005, 0.155, 0.005)\n",
    "RUN_NAME = 'abs_edge'\n",
    "\n",
    "acdcpp_exp = ACDCPPExperiment(\n",
    "    model=model,\n",
    "    clean_data=ioi_task.clean_data.toks,\n",
    "    corr_data=ioi_task.corr_data.toks,\n",
    "    acdc_metric=negative_abs_ioi_metric,\n",
    "    acdcpp_metric=ioi_metric,\n",
    "    thresholds=THRESHOLDS,\n",
    "    run_name=RUN_NAME,\n",
    "    verbose=False,\n",
    "    attr_absolute_val=True,\n",
    "    save_graphs_after=-100,\n",
    "    pruning_mode='edge',\n",
    "    no_pruned_nodes_attr=1,\n",
    "    run_acdc=False,\n",
    "    run_acdcpp=True,\n",
    ")\n",
    "# e=acdcpp_exp.setup_exp(0.0)\n",
    "\n",
    "# pruned_heads, num_passes, acdcpp_pruned_attrs, acdc_pruned_attrs, edges_after_acdcpp, edges_after_acdc = acdcpp_exp.run()\n",
    "acdcpp_nodes, acdcpp_edges, acdcpp_mask_dict, acdcpp_weight_mask_attn_dict, acdcpp_weight_mask_mlp_dict = get_masks_from_acdcpp_exp(acdcpp_exp, threshold=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((0, 'a0.10'), (-1, 'embed')),\n",
       " ((0, 'a0.9'), (-1, 'embed')),\n",
       " ((0, 'm0'), (-1, 'embed')),\n",
       " ((0, 'm0'), (0, 'a0.10')),\n",
       " ((1, 'm1'), (0, 'm0')),\n",
       " ((3, 'a3.0'), (0, 'm0')),\n",
       " ((3, 'm3'), (0, 'm0')),\n",
       " ((3, 'm3'), (1, 'm1')),\n",
       " ((3, 'm3'), (3, 'a3.0')),\n",
       " ((4, 'm4'), (0, 'm0')),\n",
       " ((4, 'm4'), (3, 'a3.0')),\n",
       " ((5, 'a5.9'), (0, 'm0')),\n",
       " ((5, 'a5.9'), (1, 'm1')),\n",
       " ((5, 'a5.9'), (3, 'a3.0')),\n",
       " ((5, 'a5.9'), (3, 'm3')),\n",
       " ((5, 'm5'), (3, 'a3.0')),\n",
       " ((5, 'm5'), (5, 'a5.5')),\n",
       " ((6, 'm6'), (3, 'a3.0')),\n",
       " ((6, 'm6'), (5, 'm5')),\n",
       " ((7, 'a7.9'), (0, 'm0')),\n",
       " ((7, 'm7'), (6, 'm6')),\n",
       " ((8, 'a8.10'), (4, 'm4')),\n",
       " ((8, 'a8.10'), (5, 'a5.5')),\n",
       " ((8, 'a8.10'), (5, 'a5.9')),\n",
       " ((8, 'a8.6'), (5, 'a5.5')),\n",
       " ((9, 'a9.9'), (8, 'a8.10')),\n",
       " ((10, 'a10.0'), (8, 'a8.10')),\n",
       " ((10, 'a10.7'), (0, 'm0')),\n",
       " ((10, 'a10.7'), (6, 'm6')),\n",
       " ((10, 'a10.7'), (9, 'a9.6')),\n",
       " ((10, 'a10.7'), (9, 'a9.9')),\n",
       " ((11, 'a11.10'), (0, 'm0')),\n",
       " ((11, 'a11.10'), (6, 'm6')),\n",
       " ((11, 'a11.10'), (8, 'a8.10')),\n",
       " ((11, 'a11.10'), (9, 'a9.6')),\n",
       " ((11, 'a11.10'), (9, 'a9.9')),\n",
       " ((11, 'a11.10'), (10, 'a10.0')),\n",
       " ((11, 'a11.10'), (10, 'a10.1')),\n",
       " ((11, 'a11.10'), (10, 'a10.10')),\n",
       " ((11, 'a11.10'), (10, 'a10.7')),\n",
       " ((11, 'a11.2'), (0, 'm0')),\n",
       " ((11, 'a11.2'), (8, 'a8.10')),\n",
       " ((11, 'a11.2'), (9, 'a9.8')),\n",
       " ((11, 'a11.2'), (9, 'a9.9')),\n",
       " ((11, 'a11.2'), (9, 'm9')),\n",
       " ((12, 'output'), (7, 'a7.9')),\n",
       " ((12, 'output'), (8, 'a8.10')),\n",
       " ((12, 'output'), (9, 'a9.6')),\n",
       " ((12, 'output'), (9, 'a9.8')),\n",
       " ((12, 'output'), (9, 'a9.9')),\n",
       " ((12, 'output'), (10, 'a10.0')),\n",
       " ((12, 'output'), (10, 'a10.1')),\n",
       " ((12, 'output'), (10, 'a10.10')),\n",
       " ((12, 'output'), (10, 'a10.2')),\n",
       " ((12, 'output'), (10, 'a10.6')),\n",
       " ((12, 'output'), (10, 'a10.7')),\n",
       " ((12, 'output'), (11, 'a11.10')),\n",
       " ((12, 'output'), (11, 'a11.2'))}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acdcpp_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('head.0.2', 'mlp.0', 0.009443754330277443), ('head.0.14', 'mlp.0', 0.006188404746353626), ('mlp.6', 'mlp.8', 0.00573932658880949), ('mlp.0', 'mlp.2', 0.005653967149555683), ('head.16.20', 'mlp.16', -0.005345507059246302), ('head.16.20', 'head.17.30.v', 0.005315450485795736), ('mlp.0', 'head.1.16.k', -0.005109565332531929), ('head.14.14', 'mlp.15', -0.004921694286167622), ('mlp.15', 'head.16.20.k', -0.004847021773457527), ('mlp.6', 'mlp.15', -0.004780464340001345), ('mlp.10', 'head.16.20.k', 0.004766407422721386), ('mlp.6', 'head.16.20.k', 0.004757486749440432), ('mlp.0', 'head.1.15.k', -0.004494336899369955), ('mlp.0', 'mlp.5', -0.004315529949963093), ('mlp.0', 'mlp.4', -0.004094669129699469), ('head.16.20', 'mlp.18', 0.004019735846668482), ('head.0.30', 'mlp.0', 0.0039080469869077206), ('mlp.0', 'mlp.6', -0.0038432518485933542), ('mlp.8', 'mlp.9', 0.00376768596470356), ('head.16.20', 'head.21.9.v', 0.003543522208929062), ('mlp.9', 'mlp.11', 0.003415714716538787), ('mlp.6', 'head.21.9.k', 0.0033131211530417204), ('head.15.4', 'mlp.15', -0.003284941893070936), ('head.15.20', 'head.16.20.q', -0.0032149143517017365), ('mlp.5', 'mlp.6', 0.003205507528036833), ('mlp.9', 'mlp.13', 0.003195255296304822), ('mlp.3', 'mlp.6', 0.0031151920557022095), ('mlp.5', 'mlp.8', 0.003063748823478818), ('mlp.12', 'head.16.20.k', -0.0030587592627853155), ('mlp.0', 'head.1.17.k', -0.0030355819035321474), ('mlp.11', 'head.16.20.v', 0.0030052291695028543), ('head.9.15', 'head.16.20.k', 0.002988740336149931), ('head.15.20', 'mlp.15', 0.002843316178768873), ('mlp.4', 'mlp.8', 0.002790694823488593), ('head.15.4', 'mlp.16', -0.002768619218841195), ('mlp.13', 'head.16.20.v', 0.002720218151807785), ('mlp.11', 'mlp.14', 0.0025788003113120794), ('mlp.11', 'head.16.20.k', -0.0025367813650518656), ('mlp.0', 'mlp.7', -0.002536351792514324), ('mlp.11', 'mlp.15', 0.0024518363643437624), ('mlp.8', 'head.16.20.v', 0.0023244901094585657), ('head.0.27', 'mlp.0', -0.0023238908033818007), ('mlp.6', 'mlp.11', 0.002282592235133052), ('head.17.30', 'mlp.18', 0.0022805416956543922), ('mlp.0', 'head.21.9.k', 0.0022331280633807182), ('head.0.21', 'mlp.0', 0.0022144378162920475), ('mlp.3', 'mlp.15', -0.00221416843123734), ('head.15.20', 'head.17.30.q', -0.002205037511885166), ('mlp.10', 'mlp.15', -0.0022013422567397356), ('mlp.4', 'head.16.20.k', 0.0021811285987496376), ('mlp.2', 'mlp.3', 0.0021742351818829775), ('mlp.30', 'mlp.31', -0.002144202124327421), ('mlp.5', 'head.16.20.k', 0.0021362670231610537), ('head.16.17', 'head.17.30.q', 0.002123921876773238), ('mlp.29', 'mlp.31', -0.00211007590405643), ('mlp.14', 'head.16.20.v', 0.0021046672482043505), ('mlp.10', 'mlp.11', -0.0020922652911394835), ('head.12.17', 'mlp.15', -0.0020885460544377565), ('mlp.0', 'mlp.13', -0.0020814668387174606), ('mlp.5', 'head.16.20.v', 0.0020730250980705023), ('mlp.28', 'mlp.31', -0.0020570242777466774), ('mlp.7', 'mlp.8', 0.00204459554515779), ('head.9.15', 'head.11.21.q', -0.002041686326265335), ('mlp.0', 'mlp.14', -0.002014364581555128), ('mlp.0', 'head.15.5.k', -0.002007126808166504), ('mlp.15', 'mlp.16', 0.001995496451854706), ('head.14.14', 'mlp.16', -0.001992548583075404), ('mlp.6', 'mlp.14', -0.001976989908143878), ('mlp.15', 'head.17.30.k', -0.0019326637266203761), ('head.16.20', 'head.22.15.v', 0.001931019127368927), ('mlp.6', 'mlp.12', 0.0019294897792860866), ('head.13.8', 'head.21.9.q', 0.0019150624284520745), ('mlp.0', 'mlp.11', -0.0019050340633839369), ('head.0.21', 'mlp.1', 0.0018889722414314747), ('head.7.8', 'mlp.13', -0.0018879767740145326), ('head.1.25', 'mlp.2', 0.0018849290208891034), ('head.15.4', 'head.16.20.q', 0.0018740722443908453), ('mlp.12', 'mlp.13', 0.001870404346846044), ('head.16.20', 'mlp.17', -0.0018696865299716592), ('head.10.1', 'mlp.15', -0.0018582759657874703), ('mlp.1', 'mlp.2', 0.0018570123938843608), ('mlp.2', 'mlp.5', 0.0018493117531761527), ('mlp.0', 'mlp.1', -0.001831269939430058), ('head.0.6', 'mlp.0', 0.00180960597936064), ('mlp.10', 'head.21.9.k', 0.001803320599719882), ('head.0.31', 'mlp.0', -0.0017993211513385177), ('mlp.12', 'head.15.20.k', 0.0017812863225117326), ('mlp.14', 'head.21.9.k', 0.0017715865978971124), ('head.7.8', 'head.16.20.k', 0.0017514253268018365), ('mlp.10', 'mlp.12', -0.001751400763168931), ('head.16.20', 'head.21.9.k', 0.0017360210185870528), ('mlp.5', 'mlp.15', -0.0017260626191273332), ('head.9.15', 'head.17.30.k', 0.0017186870099976659), ('head.15.4', 'head.21.9.k', 0.00171701202634722), ('mlp.5', 'mlp.9', 0.0017162136500701308), ('mlp.6', 'mlp.9', 0.001710148761048913), ('mlp.3', 'head.16.20.k', 0.0016996695194393396), ('mlp.3', 'mlp.8', 0.001693469937890768), ('mlp.0', 'head.1.11.v', 0.0016771022928878665), ('mlp.0', 'head.1.18.k', 0.001676780404523015), ('head.15.20', 'mlp.16', 0.0016647606389597058), ('mlp.2', 'mlp.4', 0.0016523718368262053), ('head.15.4', 'head.16.10.v', 0.0016409446252509952), ('mlp.4', 'mlp.5', 0.0015915663680061698), ('head.7.8', 'mlp.15', 0.001587998354807496), ('head.10.11', 'mlp.11', -0.0015877102268859744), ('head.16.20', 'head.25.1.k', -0.0015855319797992706), ('mlp.8', 'mlp.14', 0.0015662244986742735), ('head.14.14', 'head.16.20.q', 0.0015645340317860246), ('mlp.18', 'head.21.9.v', 0.0015612227143719792), ('head.17.30', 'mlp.17', -0.0015610615955665708), ('mlp.7', 'mlp.10', -0.0015545483911409974), ('head.7.14', 'mlp.15', 0.0015438116388395429), ('mlp.3', 'mlp.5', 0.0015396539820358157), ('head.9.15', 'mlp.12', -0.001538568758405745), ('head.9.15', 'mlp.14', -0.0015276921913027763), ('head.17.30', 'head.21.9.v', 0.0015151547268033028), ('head.16.17', 'mlp.16', -0.0015022397274151444), ('mlp.24', 'head.25.1.k', -0.0014950997428968549), ('mlp.8', 'mlp.13', 0.0014932940248399973), ('mlp.4', 'head.21.9.k', 0.0014929039170965552), ('mlp.6', 'mlp.13', 0.0014775244053453207), ('head.9.15', 'mlp.13', -0.0014682551845908165), ('mlp.7', 'head.16.20.v', 0.0014557429822161794), ('mlp.0', 'head.21.31.k', -0.0014490863541141152), ('head.12.17', 'head.15.4.v', 0.0014430660521611571), ('mlp.6', 'head.7.20.v', 0.0014389472780749202), ('mlp.0', 'head.4.13.q', 0.0014347839169204235), ('mlp.0', 'head.1.16.q', 0.0014134803786873817), ('mlp.8', 'mlp.10', 0.0014106555609032512), ('mlp.0', 'head.21.19.k', -0.001405258197337389), ('head.17.30', 'head.21.9.k', 0.0014030528254806995), ('mlp.9', 'mlp.10', 0.0013922336511313915), ('mlp.0', 'mlp.3', -0.0013902803184464574), ('mlp.6', 'head.16.20.v', 0.0013750517973676324), ('head.9.3', 'mlp.9', -0.0013734701788052917), ('head.13.8', 'head.17.30.q', 0.0013706028694286942), ('head.16.20', 'head.22.17.v', 0.0013674175133928657), ('head.13.8', 'head.15.20.q', -0.0013636015355587006), ('mlp.8', 'head.14.14.q', -0.001362730166874826), ('mlp.0', 'head.16.21.k', 0.0013574105687439442), ('head.7.8', 'head.17.30.k', 0.0013550223084166646), ('head.19.24', 'head.21.9.v', 0.00135287013836205), ('head.0.28', 'mlp.0', -0.001351020997390151), ('head.14.14', 'head.15.20.q', -0.0013473035069182515), ('mlp.0', 'head.1.10.k', 0.0013392082182690501), ('mlp.10', 'head.15.20.q', 0.0013274125522002578), ('mlp.7', 'mlp.14', -0.0013219445245340466), ('head.12.17', 'head.15.20.v', -0.0013092361623421311), ('mlp.11', 'head.17.30.k', -0.0013053971342742443), ('mlp.7', 'head.21.9.k', 0.001304464996792376), ('mlp.0', 'head.1.4.v', 0.0012995852157473564), ('head.13.8', 'head.14.31.q', -0.0012961990432813764), ('mlp.21', 'mlp.31', 0.0012819045223295689), ('mlp.15', 'head.16.20.v', 0.001273989793844521), ('head.13.8', 'head.16.20.q', 0.001270874636247754), ('mlp.0', 'head.1.25.k', -0.001269094762392342), ('mlp.20', 'mlp.31', 0.0012679877690970898), ('mlp.7', 'mlp.11', 0.0012615789892151952), ('mlp.9', 'head.11.21.q', 0.0012575825676321983), ('head.0.30', 'mlp.3', 0.001251908834092319), ('mlp.0', 'head.24.21.k', 0.0012514435220509768), ('mlp.8', 'head.16.20.k', 0.0012460232246667147), ('head.0.16', 'mlp.0', 0.0012409038608893752), ('mlp.0', 'head.15.11.k', -0.001235301955603063), ('head.0.17', 'mlp.0', 0.0012327723670750856), ('mlp.23', 'head.25.1.k', -0.0012299207737669349), ('head.12.17', 'head.16.20.v', 0.0012290324084460735), ('mlp.12', 'mlp.15', 0.0012218646006658673), ('head.15.4', 'head.16.20.v', 0.001221155864186585), ('head.0.4', 'mlp.0', 0.001221106736920774), ('head.12.17', 'head.21.9.k', 0.001220965525135398), ('mlp.12', 'head.16.20.v', 0.0012155117001384497), ('head.16.20', 'head.21.19.k', -0.001211330178193748), ('mlp.3', 'head.21.9.k', 0.0011980809504166245), ('head.16.20', 'head.17.30.q', -0.0011938184034079313), ('mlp.15', 'head.16.17.k', -0.001190812443383038), ('head.13.30', 'mlp.14', 0.0011839853832498193), ('head.8.11', 'mlp.15', -0.0011744748335331678), ('mlp.8', 'head.15.20.v', -0.0011725453659892082), ('head.14.14', 'head.21.9.k', 0.0011706198565661907), ('mlp.6', 'head.15.20.k', -0.0011685850331559777), ('mlp.25', 'mlp.26', -0.0011683834018185735), ('mlp.4', 'head.16.20.v', 0.0011622239835560322), ('mlp.8', 'mlp.11', 0.0011603647144511342), ('mlp.2', 'mlp.15', -0.001156176207587123), ('head.9.3', 'mlp.14', -0.001154008787125349), ('mlp.15', 'head.16.20.q', -0.001148901996202767), ('head.17.30', 'head.22.15.v', 0.0011446698335930705), ('head.13.30', 'mlp.15', 0.0011397490743547678), ('mlp.18', 'head.25.1.k', -0.0011324080405756831), ('head.13.20', 'head.15.4.v', 0.001122756046243012), ('mlp.21', 'head.25.1.k', -0.0011200009612366557), ('head.0.7', 'mlp.0', 0.0011196527630090714), ('mlp.13', 'head.15.20.k', 0.0011141891591250896), ('head.7.9', 'mlp.15', -0.001111720921471715), ('mlp.2', 'head.21.9.k', 0.001110269222408533), ('head.1.25', 'mlp.3', 0.0011059733806177974), ('head.9.15', 'head.21.9.k', 0.0011041940888389945), ('mlp.0', 'head.1.4.k', -0.001102518173865974), ('mlp.23', 'head.26.25.k', 0.001102395704947412), ('mlp.15', 'head.16.17.v', -0.0011007385328412056), ('head.13.30', 'head.16.20.q', -0.001094624400138855), ('mlp.18', 'head.21.9.k', 0.0010888677788898349), ('head.8.14', 'mlp.9', -0.0010858307359740138), ('head.15.4', 'head.17.30.q', 0.0010818063747137785), ('mlp.6', 'head.15.20.v', -0.001078712404705584), ('head.9.15', 'head.10.26.v', -0.0010778617579489946), ('mlp.0', 'mlp.8', -0.0010757920099422336), ('head.15.27', 'head.16.20.q', -0.0010755263501778245), ('mlp.7', 'head.14.14.v', -0.001074428204447031), ('head.15.4', 'head.21.9.q', 0.0010719193378463387), ('head.14.14', 'head.16.17.v', 0.0010705209570005536), ('mlp.4', 'mlp.12', -0.0010661009000614285), ('head.7.8', 'head.15.20.k', 0.0010634062346071005), ('mlp.23', 'mlp.28', -0.001054505119100213), ('head.7.8', 'head.14.8.v', 0.0010530278086662292), ('mlp.13', 'head.15.4.v', 0.0010519307106733322), ('mlp.11', 'head.16.17.k', -0.0010491471039131284), ('mlp.9', 'mlp.18', -0.001046185614541173), ('head.5.17', 'mlp.7', 0.001044679433107376), ('mlp.8', 'head.13.8.v', 0.0010418110759928823), ('head.7.15', 'mlp.9', -0.0010394830023869872), ('mlp.26', 'mlp.30', -0.0010386754292994738), ('mlp.6', 'head.16.21.k', 0.0010373503901064396), ('head.15.20', 'head.16.17.v', -0.0010349199874326587), ('mlp.0', 'head.1.12.v', 0.0010330087970942259), ('head.12.26', 'mlp.14', -0.0010282696457579732), ('mlp.0', 'head.1.6.v', 0.0010257066460326314), ('head.13.30', 'mlp.13', 0.001021881471388042), ('mlp.6', 'head.20.2.k', -0.0010205552680417895), ('head.13.30', 'head.16.20.k', -0.0010205348953604698), ('head.15.4', 'head.21.19.k', -0.0010198857635259628), ('mlp.8', 'head.13.30.v', -0.0010180402314290404), ('head.15.4', 'head.25.1.k', -0.0010171744506806135), ('mlp.0', 'head.1.17.v', 0.0010166249703615904), ('head.14.14', 'head.17.30.q', 0.0010091098956763744), ('head.14.14', 'head.15.20.k', -0.001008716062642634), ('mlp.0', 'head.22.17.k', 0.0010071411961689591), ('head.17.30', 'head.25.1.k', -0.0010067331604659557), ('head.9.3', 'head.15.4.v', 0.001002408331260085), ('mlp.13', 'head.16.20.k', 0.0010006306692957878)]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.001\n",
    "import pickle\n",
    "with open('localizations/eap/eap_sports/1000_graph.pkl', 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "\n",
    "eap_edges = graph.top_edges(n=1000, threshold=threshold)\n",
    "# eap_edges = set()\n",
    "# for i in range(eap_scores.shape[0]):\n",
    "#     for j in range(eap_scores.shape[1]):\n",
    "#         if eap_scores[i, j] > threshold:\n",
    "            # eap_edges.add((get_node_name(graph.node_names[i], show_full_index=False), get_node_name(graph.node_names[j, show_full_index=False))))\n",
    "print(eap_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3277824"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.eap_scores.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert format:\n",
    "want: {((3, 'm3'), (3, 'a3.0')),\n",
    " ((4, 'm4'), (0, 'm0')),\n",
    " ((4, 'm4'), (3, 'a3.0')),\n",
    " ((5, 'a5.9'), (0, 'm0')),}\n",
    "\n",
    "have:\n",
    "[('mlp.0', 'mlp.2', 0.005653967149555683),\n",
    "('head.0.14', 'mlp.0', 0.006188404746353626),]\n",
    "...\n",
    "\"\"\"\n",
    "from cb_utils.mask_utils import get_formatted_edges_from_eap, get_masks_from_eap_exp\n",
    "# formatted_eap_edges = get_formatted_edges_from_eap(eap_edges)\n",
    "# formatted_eap_edges\n",
    "with open('localizations/eap/eap_sports/1000_graph.pkl', 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "acdcpp_nodes, acdcpp_edges, acdcpp_mask_dict, acdcpp_weight_mask_attn_dict, acdcpp_weight_mask_mlp_dict = get_masks_from_eap_exp(graph, threshold=0.001, num_layers=32, num_heads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acdcpp_mask_dict['m31'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.292320251464844 1.4027974605560303\n"
     ]
    }
   ],
   "source": [
    "from tasks import InductionTask\n",
    "ind_task = InductionTask(batch_size=16, tokenizer=model.tokenizer, prep_acdcpp=True, seq_len=10, acdcpp_metric=\"ave_logit_diff\")\n",
    "ind_task.set_logit_diffs(model)\n",
    "print(ind_task.clean_logit_diff, ind_task.corrupted_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_metric = ind_task.get_acdcpp_metric()\n",
    "def negative_abs_ind_metric(logits: Float[Tensor, \"batch seq_len d_vocab\"]):\n",
    "    return -abs(ind_metric(logits))\n",
    "\n",
    "with t.no_grad():\n",
    "    clean_logits = model(ind_task.clean_data.cuda())\n",
    "    corrupt_logits = model(ind_task.corr_data.cuda())\n",
    "    clean_logit_diff = ind_task.ave_logit_diff(clean_logits, ind_task.clean_data).item()\n",
    "    corrupt_logit_diff = ind_task.ave_logit_diff(corrupt_logits, ind_task.corr_data).item()\n",
    "    \n",
    "print(ind_metric(clean_logits))\n",
    "print(ind_metric(corrupt_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 15171.34it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:04<00:00, 252.85it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 304067.19it/s]\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([-1, 11, 10, 9, 8, 7, 5, 0, 1, 2, 3, 4, 6, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "from cb_utils.mask_utils import get_masks_from_acdcpp_exp\n",
    "THRESHOLDS = [0.05]#np.arange(0.005, 0.155, 0.005)\n",
    "RUN_NAME = 'abs_edge'\n",
    "\n",
    "acdcpp_exp = ACDCPPExperiment(\n",
    "    model=model,\n",
    "    clean_data=ind_task.clean_data,\n",
    "    corr_data=ind_task.corr_data,\n",
    "    acdc_metric=negative_abs_ind_metric,\n",
    "    acdcpp_metric=ind_metric,\n",
    "    thresholds=THRESHOLDS,\n",
    "    run_name=RUN_NAME,\n",
    "    verbose=False,\n",
    "    attr_absolute_val=True,\n",
    "    save_graphs_after=-100,\n",
    "    pruning_mode='edge',\n",
    "    no_pruned_nodes_attr=1,\n",
    "    run_acdc=False,\n",
    "    run_acdcpp=True,\n",
    ")\n",
    "# e=acdcpp_exp.setup_exp(0.0)\n",
    "\n",
    "# pruned_heads, num_passes, acdcpp_pruned_attrs, acdc_pruned_attrs, edges_after_acdcpp, edges_after_acdc = acdcpp_exp.run()\n",
    "acdcpp_nodes, acdcpp_edges, acdcpp_mask_dict, acdcpp_weight_mask_attn_dict, acdcpp_weight_mask_mlp_dict = get_masks_from_acdcpp_exp(acdcpp_exp, threshold=THRESHOLDS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'acdcpp_mask_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m localize_acdcpp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# if edge_masks is True, then have mask_dict_superset be acdcpp_mask_dict\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m mask_dict_superset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m edge_masks \u001b[38;5;28;01melse\u001b[39;00m \u001b[43macdcpp_mask_dict\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# model = load_demo_gpt2(means=means, mask_dict_superset=acdcpp_mask_dict)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m localize_acdcpp:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acdcpp_mask_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from cb_utils.transformer import DemoTransformer\n",
    "from cb_utils.models import load_demo_gpt2, tokenizer\n",
    "means_ioi = True\n",
    "if means_ioi:\n",
    "    with open(\"data/gpt2_ioi_abc_means.pkl\", \"rb\") as f:\n",
    "        means = pickle.load(f)[0]\n",
    "else:\n",
    "    with open(\"data/gpt2_means.pkl\", \"rb\") as f:\n",
    "        means = pickle.load(f)[0]\n",
    "\n",
    "edge_masks = True\n",
    "weight_masks_attn = True\n",
    "weight_masks_mlp = True\n",
    "train_base_weights = True\n",
    "localize_acdcpp = True\n",
    "\n",
    "# if edge_masks is True, then have mask_dict_superset be acdcpp_mask_dict\n",
    "mask_dict_superset = None if not edge_masks else acdcpp_mask_dict\n",
    "# model = load_demo_gpt2(means=means, mask_dict_superset=acdcpp_mask_dict)\n",
    "if localize_acdcpp:\n",
    "    weight_mask_attn_dict = acdcpp_weight_mask_attn_dict if weight_masks_attn else None\n",
    "    weight_mask_mlp_dict = acdcpp_weight_mask_mlp_dict if weight_masks_mlp else None\n",
    "    base_weight_attn_dict = acdcpp_weight_mask_attn_dict if train_base_weights else None\n",
    "    base_weight_mlp_dict = acdcpp_weight_mask_mlp_dict if train_base_weights else None\n",
    "\n",
    "else:\n",
    "    weight_mask_attn_dict = None\n",
    "    weight_mask_mlp_dict = None\n",
    "    base_weight_attn_dict = None\n",
    "    base_weight_mlp_dict = None\n",
    "\n",
    "# model = load_demo_gpt2(means=False, edge_masks=edge_masks, mask_dict_superset=mask_dict_superset, weight_masks_attn=weight_masks_attn, weight_masks_mlp=weight_masks_mlp, weight_mask_attn_dict=weight_mask_attn_dict, weight_mask_mlp_dict=weight_mask_mlp_dict, train_base_weights=train_base_weights, base_weight_attn_dict=base_weight_attn_dict, base_weight_mlp_dict=base_weight_mlp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-2.8b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from cb_utils.models import load_demo_pythia\n",
    "threshold = 0.0005\n",
    "with open(f\"localizations/eap/eap_sports/pythia-2.8b_{threshold=}.pkl\", \"rb\") as f:\n",
    "    acdcpp_nodes, acdcpp_edges, acdcpp_mask_dict, acdcpp_weight_mask_attn_dict, acdcpp_weight_mask_mlp_dict = pickle.load(f)\n",
    "\n",
    "# model = load_demo_pythia(means=False, model_name=\"pythia-2.8b\", edge_masks=True, mask_dict_superset=acdcpp_mask_dict)\n",
    "model = load_demo_pythia(means=False, model_name=\"pythia-2.8b\", edge_mask=False, weight_mask=True, weight_masks_attn=True, weight_masks_mlp=True, weight_mask_attn_dict=acdcpp_weight_mask_attn_dict, weight_mask_mlp_dict=acdcpp_weight_mask_mlp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-2.8b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "reference_pythia = HookedTransformer.from_pretrained(\n",
    "        'pythia-2.8b',\n",
    "        fold_ln=False,\n",
    "        center_writing_weights=False,\n",
    "        center_unembed=False,\n",
    "        # default_padding_side=\"left\",\n",
    "        # device='cuda'\n",
    "        device='cpu'\n",
    "    )\n",
    "tokenizer = reference_pythia.tokenizer\n",
    "pythia_tokenizer = reference_pythia.tokenizer\n",
    "# reference_pythia.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the two models\n",
    "# compare model outputs\n",
    "with torch.no_grad():\n",
    "    test_input = t.tensor(pythia_tokenizer.encode(\"The quick brown fox jumps over the lazy\")).unsqueeze(0).cuda()\n",
    "    # print((model(test_input)[0][0, -1] - reference_pythia(test_input)[0, -1]).std())\n",
    "    # print((model(test_input)[0][0, -1] - edge_masked_model(test_input)[0][0, -1]).std())\n",
    "    # print((reference_pythia(test_input)[0, -1] - edge_masked_model(test_input)[0][0, -1]).std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.96875\n",
      "tensor(12.0880, device='cuda:0')\n",
      "tensor(2.8271, device='cuda:0')\n",
      "tensor(3.4641, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from tasks import SportsTask, InductionTask, IOITask, InductionTask_Uniform, OWTTask#, SportsTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask_Uniform\n",
    "sports_task = SportsTask(batch_size=32, tokenizer=tokenizer, prep_acdcpp=False)\n",
    "ioi_task = IOITask(batch_size=32, tokenizer=tokenizer, prep_acdcpp=False)\n",
    "ind_task = InductionTask(batch_size=32, tokenizer=tokenizer, prep_acdcpp=False)\n",
    "ind_uniform_task = InductionTask_Uniform(batch_size=16, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, uniform_over=\"rep_tokens\")\n",
    "owt_task = OWTTask(batch_size=32, tokenizer=tokenizer, device=device, ctx_length=30)\n",
    "sports_uniform_task = SportsTask_Uniform(batch_size=32, tokenizer=tokenizer, uniform_over=\"sports_tokens\")\n",
    "print(sports_task.get_test_accuracy(model))#, sports_task.get_test_accuracy(reference_pythia))\n",
    "print(ioi_task.get_test_accuracy(model))#, ioi_task.get_test_accuracy(reference_pythia))\n",
    "print(ind_task.get_test_accuracy(model))#, ind_task.get_test_accuracy(reference_pythia))\n",
    "print(ind_uniform_task.get_test_loss(model))#, ind_uniform_task.get_test_loss(reference_pythia))\n",
    "print(owt_task.get_test_loss(model))#, owt_task.get_test_accuracy(reference_pythia))\n",
    "print(sports_uniform_task.get_test_loss(model))#, sports_uniform_task.get_test_accuracy(reference_pythia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.2142, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sports_uniform_task = SportsTask_Uniform(batch_size=32, tokenizer=tokenizer, uniform_over=\"all_tokens\")\n",
    "print(sports_uniform_task.get_test_loss(model))#, sports_uniform_task.get_test_accuracy(reference_pythia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tasks import LimitedSportsTask\n",
    "forget_task = LimitedSportsTask(batch_size=32, tokenizer=tokenizer, start_index=0, stop_index=64, make_complementary_task=True)\n",
    "remember_task = forget_task.complementary_task\n",
    "forget_task.get_test_accuracy(model), remember_task.get_test_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.968525312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(device=device) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# test max batch size for sports, owt\n",
    "owt_task = OWTTask(batch_size=1, tokenizer=tokenizer, ctx_length=30)\n",
    "sports_task = SportsTask(batch_size=1, tokenizer=tokenizer, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.304587776\n",
      "41.535725568\n",
      "51.745850368\n",
      "61.98750208\n",
      "72.183995392\n",
      "31.304588288\n"
     ]
    }
   ],
   "source": [
    "sports_task = SportsTask(batch_size=1, tokenizer=tokenizer, shuffle=False)\n",
    "tot_loss = 0\n",
    "print(torch.cuda.memory_allocated(device=device) / 1e9)\n",
    "for i in range(4):\n",
    "    loss = sports_task.get_train_loss(model)\n",
    "    tot_loss += loss\n",
    "    print(torch.cuda.memory_allocated(device=device) / 1e9)\n",
    "tot_loss.backward()\n",
    "print(torch.cuda.memory_allocated(device=device) / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.808385536\n",
      "19.528289792\n",
      "None\n",
      "19.150077952\n",
      "tensor([-0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
      "         0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "        -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0000, -0.1926,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0430,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "        -0.0000,  0.0000, -0.0000, -0.0041,  0.0266,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0000,  0.0000,  0.0028], device='cuda:0')\n",
      "19.530473472\n",
      "tensor([-0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "         0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0000, -0.1994,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0397,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0000, -0.0101,  0.0224,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0029], device='cuda:0')\n",
      "19.916095488\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0000, -0.2187,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0516,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0000,  0.0415,  0.0118,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0107], device='cuda:0')\n",
      "19.150077952\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.3756,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0774,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0000, -0.0243, -0.0222,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0840], device='cuda:0')\n",
      "19.150077952\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.3745,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0777,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0000, -0.0035, -0.0313,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0760], device='cuda:0')\n",
      "20.301221888\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.2625,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0764,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.3730, -0.0606,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.2777], device='cuda:0')\n",
      "19.150077952\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.2575,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0730,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.4224, -0.0521,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.1660], device='cuda:0')\n",
      "19.530473472\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.3422,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0573,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.4138, -0.0537,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.1833], device='cuda:0')\n",
      "19.150077952\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.3454,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0576,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.4142, -0.0529,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.1860], device='cuda:0')\n",
      "19.530473472\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.6088,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0573,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.2618, -0.0234,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.1402], device='cuda:0')\n",
      "19.150077952\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.8482,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0312,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0413,  0.0014,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.2160], device='cuda:0')\n",
      "19.530473472\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.9013,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0280,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0584,  0.0114,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.2556], device='cuda:0')\n",
      "18.75236864\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.9123,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0311,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0663,  0.0107,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.2653], device='cuda:0')\n",
      "19.150077952\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.9955,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0243,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.1122,  0.0201,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.2994], device='cuda:0')\n",
      "19.530473472\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.9868,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0802,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0145, -0.0399,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.2010], device='cuda:0')\n",
      "19.916095488\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.9972,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0819,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0032, -0.0410,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.1897], device='cuda:0')\n",
      "19.150077952\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -1.3423,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0843,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0399, -0.0116,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.2129], device='cuda:0')\n",
      "19.530473472\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -1.4041,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0863,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0732, -0.0122,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.2291], device='cuda:0')\n",
      "20.684939264\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -1.4221,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0859,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0132, -0.0242,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.1758], device='cuda:0')\n",
      "11.808385536\n"
     ]
    }
   ],
   "source": [
    "tot_loss = 0\n",
    "print(torch.cuda.memory_allocated(device=device) / 1e9)\n",
    "model.zero_grad()\n",
    "for i in range(20):\n",
    "    loss = sports_task.get_train_loss(model)\n",
    "    print(torch.cuda.memory_allocated(device=device) / 1e9)\n",
    "    print(model.blocks[2].edge_mask_mlp.grad)\n",
    "    loss.backward()\n",
    "print(torch.cuda.memory_allocated(device=device) / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000, -0.4634,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.1553,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.2797,  0.0654,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.3760], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[2].edge_mask_mlp.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test that gradients flow correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.0.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.0.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.0.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.0.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.0.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.0.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.0.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.1.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.1.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.1.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.1.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.1.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.1.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.1.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.1.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.2.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.2.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.2.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.2.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.2.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.2.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.2.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.2.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.3.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.3.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.3.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.3.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.3.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.3.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.3.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.3.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.4.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.4.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.4.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.4.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.4.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.4.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.4.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.4.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.5.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.5.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.5.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.5.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.5.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.5.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.5.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.5.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.6.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.6.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.6.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.6.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.6.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.6.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.6.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.6.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.7.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.7.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.7.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.7.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.7.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.7.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.7.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.7.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.8.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.8.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.8.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.8.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.8.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.8.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.8.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.8.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.9.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.9.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.9.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.9.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.9.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.9.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.9.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.9.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.10.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.10.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.10.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.10.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.10.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.10.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.10.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.10.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.11.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.11.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.11.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.11.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.11.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.11.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.11.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.11.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.12.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.12.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.12.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.12.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.12.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.12.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.12.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.12.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.13.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.13.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.13.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.13.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.13.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.13.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.13.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.13.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.14.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.14.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.14.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.14.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.14.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.14.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.14.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.14.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.15.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.15.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.15.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.15.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.15.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.15.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.15.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.15.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.16.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.16.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.16.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.16.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.16.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.16.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.16.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.16.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.17.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.17.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.17.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.17.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.17.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.17.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.17.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.17.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.18.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.18.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.18.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.18.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.18.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.18.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.18.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.18.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.19.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.19.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.19.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.19.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.19.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.19.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.19.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.19.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.20.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.20.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.20.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.20.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.20.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.20.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.20.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.20.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.21.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.21.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.21.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.21.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.21.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.21.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.21.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.21.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.22.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.22.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.22.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.22.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.22.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.22.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.22.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.22.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.23.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.23.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.23.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.23.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.23.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.23.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.23.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.23.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.24.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.24.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.24.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.24.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.24.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.24.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.24.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.24.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.25.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.25.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.25.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.25.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.25.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.25.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.25.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.25.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.26.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.26.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.26.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.26.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.26.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.26.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.26.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.26.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.27.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.27.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.27.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.27.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.27.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.27.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.27.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.27.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.28.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.28.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.28.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.28.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.28.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.28.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.28.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.28.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.29.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.29.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.29.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.29.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.29.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.29.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.29.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.29.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.30.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.30.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.30.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.30.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.30.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.30.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.30.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.30.mlp.weight_mask_b_out torch.Size([2560]) True\n",
      "blocks.31.attn.weight_mask_W_Q torch.Size([32, 2560, 80]) True\n",
      "blocks.31.attn.weight_mask_W_K torch.Size([32, 2560, 80]) True\n",
      "blocks.31.attn.weight_mask_W_V torch.Size([32, 2560, 80]) True\n",
      "blocks.31.attn.weight_mask_W_O torch.Size([32, 80, 2560]) True\n",
      "blocks.31.mlp.weight_mask_W_in torch.Size([2560, 10240]) True\n",
      "blocks.31.mlp.weight_mask_W_out torch.Size([10240, 2560]) True\n",
      "blocks.31.mlp.weight_mask_b_in torch.Size([10240]) True\n",
      "blocks.31.mlp.weight_mask_b_out torch.Size([2560]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape, param.requires_grad)\n",
    "    # print(name, param.shape, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "batch_size = 2\n",
    "ioi = IOITask(batch_size=batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False)\n",
    "loss = ioi.get_train_loss(model)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.17700352"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(device=device) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0216, device='cuda:0')\n",
      "blocks.0.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(1.5815, device='cuda:0')\n",
      "blocks.0.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(1.3946, device='cuda:0')\n",
      "blocks.0.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(1.7858, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(3.0081, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(5.3979, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.5360, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.6562, device='cuda:0')\n",
      "blocks.1.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0523, device='cuda:0')\n",
      "blocks.1.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(2.6793, device='cuda:0')\n",
      "blocks.1.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(3.4024, device='cuda:0')\n",
      "blocks.1.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(4.1716, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(3.0001, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(2.7603, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1013, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.4754, device='cuda:0')\n",
      "blocks.2.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0153, device='cuda:0')\n",
      "blocks.2.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.4646, device='cuda:0')\n",
      "blocks.2.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.6357, device='cuda:0')\n",
      "blocks.2.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.5915, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(6.0486, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(5.4989, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1658, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.4407, device='cuda:0')\n",
      "blocks.3.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0287, device='cuda:0')\n",
      "blocks.3.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(1.1237, device='cuda:0')\n",
      "blocks.3.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(1.1898, device='cuda:0')\n",
      "blocks.3.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(1.3442, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(6.7269, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(4.4302, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1361, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.3720, device='cuda:0')\n",
      "blocks.4.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0340, device='cuda:0')\n",
      "blocks.4.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(1.2193, device='cuda:0')\n",
      "blocks.4.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(1.1874, device='cuda:0')\n",
      "blocks.4.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(1.5638, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(5.7872, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(3.8785, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1223, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.2525, device='cuda:0')\n",
      "blocks.5.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0247, device='cuda:0')\n",
      "blocks.5.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(1.5181, device='cuda:0')\n",
      "blocks.5.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(1.1584, device='cuda:0')\n",
      "blocks.5.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.9633, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(5.6964, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(3.4137, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1316, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.2880, device='cuda:0')\n",
      "blocks.6.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0326, device='cuda:0')\n",
      "blocks.6.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(1.3960, device='cuda:0')\n",
      "blocks.6.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.2927, device='cuda:0')\n",
      "blocks.6.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.3720, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(4.1122, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(2.8020, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1218, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.2403, device='cuda:0')\n",
      "blocks.7.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0707, device='cuda:0')\n",
      "blocks.7.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(1.0487, device='cuda:0')\n",
      "blocks.7.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(1.0041, device='cuda:0')\n",
      "blocks.7.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(1.3239, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(3.1489, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(2.4518, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0938, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1907, device='cuda:0')\n",
      "blocks.8.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0243, device='cuda:0')\n",
      "blocks.8.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.6422, device='cuda:0')\n",
      "blocks.8.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.4250, device='cuda:0')\n",
      "blocks.8.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.6018, device='cuda:0')\n",
      "blocks.8.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(3.1996, device='cuda:0')\n",
      "blocks.8.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(2.1894, device='cuda:0')\n",
      "blocks.8.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1043, device='cuda:0')\n",
      "blocks.8.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1480, device='cuda:0')\n",
      "blocks.9.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1076, device='cuda:0')\n",
      "blocks.9.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.6959, device='cuda:0')\n",
      "blocks.9.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.6134, device='cuda:0')\n",
      "blocks.9.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(1.0054, device='cuda:0')\n",
      "blocks.9.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(2.0523, device='cuda:0')\n",
      "blocks.9.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(1.9276, device='cuda:0')\n",
      "blocks.9.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0588, device='cuda:0')\n",
      "blocks.9.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1275, device='cuda:0')\n",
      "blocks.10.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1095, device='cuda:0')\n",
      "blocks.10.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.4939, device='cuda:0')\n",
      "blocks.10.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.6077, device='cuda:0')\n",
      "blocks.10.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.8943, device='cuda:0')\n",
      "blocks.10.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(1.7116, device='cuda:0')\n",
      "blocks.10.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(1.7489, device='cuda:0')\n",
      "blocks.10.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0526, device='cuda:0')\n",
      "blocks.10.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1074, device='cuda:0')\n",
      "blocks.11.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1050, device='cuda:0')\n",
      "blocks.11.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.7140, device='cuda:0')\n",
      "blocks.11.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.4779, device='cuda:0')\n",
      "blocks.11.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.7883, device='cuda:0')\n",
      "blocks.11.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(2.0600, device='cuda:0')\n",
      "blocks.11.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(1.6167, device='cuda:0')\n",
      "blocks.11.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0715, device='cuda:0')\n",
      "blocks.11.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1083, device='cuda:0')\n",
      "blocks.12.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0721, device='cuda:0')\n",
      "blocks.12.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.4778, device='cuda:0')\n",
      "blocks.12.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.7437, device='cuda:0')\n",
      "blocks.12.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.6520, device='cuda:0')\n",
      "blocks.12.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(1.4094, device='cuda:0')\n",
      "blocks.12.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(1.4171, device='cuda:0')\n",
      "blocks.12.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0439, device='cuda:0')\n",
      "blocks.12.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1021, device='cuda:0')\n",
      "blocks.13.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1011, device='cuda:0')\n",
      "blocks.13.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.5514, device='cuda:0')\n",
      "blocks.13.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.4197, device='cuda:0')\n",
      "blocks.13.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.6264, device='cuda:0')\n",
      "blocks.13.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(1.4831, device='cuda:0')\n",
      "blocks.13.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(1.3279, device='cuda:0')\n",
      "blocks.13.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0461, device='cuda:0')\n",
      "blocks.13.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1136, device='cuda:0')\n",
      "blocks.14.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1698, device='cuda:0')\n",
      "blocks.14.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.4920, device='cuda:0')\n",
      "blocks.14.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.4761, device='cuda:0')\n",
      "blocks.14.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.5347, device='cuda:0')\n",
      "blocks.14.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(1.3809, device='cuda:0')\n",
      "blocks.14.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(1.2714, device='cuda:0')\n",
      "blocks.14.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0472, device='cuda:0')\n",
      "blocks.14.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1006, device='cuda:0')\n",
      "blocks.15.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1117, device='cuda:0')\n",
      "blocks.15.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.8832, device='cuda:0')\n",
      "blocks.15.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.7689, device='cuda:0')\n",
      "blocks.15.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.6868, device='cuda:0')\n",
      "blocks.15.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(1.2130, device='cuda:0')\n",
      "blocks.15.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(1.1867, device='cuda:0')\n",
      "blocks.15.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0375, device='cuda:0')\n",
      "blocks.15.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1102, device='cuda:0')\n",
      "blocks.16.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0881, device='cuda:0')\n",
      "blocks.16.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.6491, device='cuda:0')\n",
      "blocks.16.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(1.4239, device='cuda:0')\n",
      "blocks.16.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.5172, device='cuda:0')\n",
      "blocks.16.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.9002, device='cuda:0')\n",
      "blocks.16.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.8568, device='cuda:0')\n",
      "blocks.16.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0284, device='cuda:0')\n",
      "blocks.16.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0876, device='cuda:0')\n",
      "blocks.17.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0202, device='cuda:0')\n",
      "blocks.17.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.5240, device='cuda:0')\n",
      "blocks.17.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.6827, device='cuda:0')\n",
      "blocks.17.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.4406, device='cuda:0')\n",
      "blocks.17.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8107, device='cuda:0')\n",
      "blocks.17.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7710, device='cuda:0')\n",
      "blocks.17.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0251, device='cuda:0')\n",
      "blocks.17.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0848, device='cuda:0')\n",
      "blocks.18.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0177, device='cuda:0')\n",
      "blocks.18.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.1040, device='cuda:0')\n",
      "blocks.18.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1383, device='cuda:0')\n",
      "blocks.18.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.1011, device='cuda:0')\n",
      "blocks.18.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8756, device='cuda:0')\n",
      "blocks.18.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7267, device='cuda:0')\n",
      "blocks.18.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0321, device='cuda:0')\n",
      "blocks.18.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0764, device='cuda:0')\n",
      "blocks.19.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0253, device='cuda:0')\n",
      "blocks.19.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.8453, device='cuda:0')\n",
      "blocks.19.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.0762, device='cuda:0')\n",
      "blocks.19.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0645, device='cuda:0')\n",
      "blocks.19.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.7466, device='cuda:0')\n",
      "blocks.19.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.6848, device='cuda:0')\n",
      "blocks.19.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0295, device='cuda:0')\n",
      "blocks.19.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0766, device='cuda:0')\n",
      "blocks.20.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1612, device='cuda:0')\n",
      "blocks.20.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.5107, device='cuda:0')\n",
      "blocks.20.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1835, device='cuda:0')\n",
      "blocks.20.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.1371, device='cuda:0')\n",
      "blocks.20.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8223, device='cuda:0')\n",
      "blocks.20.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7292, device='cuda:0')\n",
      "blocks.20.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0507, device='cuda:0')\n",
      "blocks.20.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0725, device='cuda:0')\n",
      "blocks.21.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0411, device='cuda:0')\n",
      "blocks.21.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(1.6082, device='cuda:0')\n",
      "blocks.21.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.4147, device='cuda:0')\n",
      "blocks.21.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.2566, device='cuda:0')\n",
      "blocks.21.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8589, device='cuda:0')\n",
      "blocks.21.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7254, device='cuda:0')\n",
      "blocks.21.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0369, device='cuda:0')\n",
      "blocks.21.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0550, device='cuda:0')\n",
      "blocks.22.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0118, device='cuda:0')\n",
      "blocks.22.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(2.9092, device='cuda:0')\n",
      "blocks.22.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.4474, device='cuda:0')\n",
      "blocks.22.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.3173, device='cuda:0')\n",
      "blocks.22.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.7197, device='cuda:0')\n",
      "blocks.22.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.6838, device='cuda:0')\n",
      "blocks.22.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0204, device='cuda:0')\n",
      "blocks.22.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0511, device='cuda:0')\n",
      "blocks.23.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0093, device='cuda:0')\n",
      "blocks.23.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(2.3585, device='cuda:0')\n",
      "blocks.23.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1862, device='cuda:0')\n",
      "blocks.23.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0740, device='cuda:0')\n",
      "blocks.23.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8991, device='cuda:0')\n",
      "blocks.23.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.8119, device='cuda:0')\n",
      "blocks.23.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0500, device='cuda:0')\n",
      "blocks.23.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.1179, device='cuda:0')\n",
      "blocks.24.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0508, device='cuda:0')\n",
      "blocks.24.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(1.1172, device='cuda:0')\n",
      "blocks.24.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1264, device='cuda:0')\n",
      "blocks.24.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0462, device='cuda:0')\n",
      "blocks.24.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.7543, device='cuda:0')\n",
      "blocks.24.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7233, device='cuda:0')\n",
      "blocks.24.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0206, device='cuda:0')\n",
      "blocks.24.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0740, device='cuda:0')\n",
      "blocks.25.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0253, device='cuda:0')\n",
      "blocks.25.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.7412, device='cuda:0')\n",
      "blocks.25.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1592, device='cuda:0')\n",
      "blocks.25.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0607, device='cuda:0')\n",
      "blocks.25.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8118, device='cuda:0')\n",
      "blocks.25.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7977, device='cuda:0')\n",
      "blocks.25.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0196, device='cuda:0')\n",
      "blocks.25.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0570, device='cuda:0')\n",
      "blocks.26.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0965, device='cuda:0')\n",
      "blocks.26.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(1.4008, device='cuda:0')\n",
      "blocks.26.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.3048, device='cuda:0')\n",
      "blocks.26.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.1360, device='cuda:0')\n",
      "blocks.26.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.7854, device='cuda:0')\n",
      "blocks.26.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7327, device='cuda:0')\n",
      "blocks.26.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0208, device='cuda:0')\n",
      "blocks.26.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0462, device='cuda:0')\n",
      "blocks.27.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0133, device='cuda:0')\n",
      "blocks.27.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.1217, device='cuda:0')\n",
      "blocks.27.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1298, device='cuda:0')\n",
      "blocks.27.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0378, device='cuda:0')\n",
      "blocks.27.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8495, device='cuda:0')\n",
      "blocks.27.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7477, device='cuda:0')\n",
      "blocks.27.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0203, device='cuda:0')\n",
      "blocks.27.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0382, device='cuda:0')\n",
      "blocks.28.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0673, device='cuda:0')\n",
      "blocks.28.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.2781, device='cuda:0')\n",
      "blocks.28.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.0908, device='cuda:0')\n",
      "blocks.28.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0264, device='cuda:0')\n",
      "blocks.28.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8755, device='cuda:0')\n",
      "blocks.28.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7465, device='cuda:0')\n",
      "blocks.28.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0207, device='cuda:0')\n",
      "blocks.28.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0370, device='cuda:0')\n",
      "blocks.29.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0097, device='cuda:0')\n",
      "blocks.29.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.0849, device='cuda:0')\n",
      "blocks.29.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1065, device='cuda:0')\n",
      "blocks.29.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0473, device='cuda:0')\n",
      "blocks.29.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8123, device='cuda:0')\n",
      "blocks.29.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.7129, device='cuda:0')\n",
      "blocks.29.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0166, device='cuda:0')\n",
      "blocks.29.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0395, device='cuda:0')\n",
      "blocks.30.attn.weight_mask_W_Q grad is all zeros\n",
      "blocks.30.attn.weight_mask_W_K grad is all zeros\n",
      "blocks.30.attn.weight_mask_W_V grad is all zeros\n",
      "blocks.30.attn.weight_mask_W_O grad is all zeros\n",
      "blocks.30.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(1.2086, device='cuda:0')\n",
      "blocks.30.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.9111, device='cuda:0')\n",
      "blocks.30.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0195, device='cuda:0')\n",
      "blocks.30.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0239, device='cuda:0')\n",
      "blocks.31.attn.weight_mask_W_Q grad is all zeros\n",
      "blocks.31.attn.weight_mask_W_K grad is all zeros\n",
      "blocks.31.attn.weight_mask_W_V grad is all zeros\n",
      "blocks.31.attn.weight_mask_W_O grad is all zeros\n",
      "blocks.31.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.8112, device='cuda:0')\n",
      "blocks.31.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.8142, device='cuda:0')\n",
      "blocks.31.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0111, device='cuda:0')\n",
      "blocks.31.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0247, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "param_names = []\n",
    "model_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad: # and \"edge\" in name:\n",
    "        # check if param.grad is all zeros\n",
    "        if param.grad is not None and param.grad.sum() != 0:\n",
    "            print(f\"{name} grad is not all zeros, {param.grad.norm()=}\")\n",
    "        else:\n",
    "            print(f\"{name} grad is all zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 'a0.21'),\n",
       " (0, 'a0.30'),\n",
       " (0, 'm0'),\n",
       " (1, 'a1.0'),\n",
       " (1, 'a1.10'),\n",
       " (1, 'a1.11'),\n",
       " (1, 'a1.12'),\n",
       " (1, 'a1.14'),\n",
       " (1, 'a1.15'),\n",
       " (1, 'a1.16'),\n",
       " (1, 'a1.17'),\n",
       " (1, 'a1.18'),\n",
       " (1, 'a1.25'),\n",
       " (1, 'a1.26'),\n",
       " (1, 'a1.29'),\n",
       " (1, 'a1.30'),\n",
       " (1, 'a1.4'),\n",
       " (1, 'a1.6'),\n",
       " (1, 'm1'),\n",
       " (2, 'a2.11'),\n",
       " (2, 'a2.12'),\n",
       " (2, 'm2'),\n",
       " (3, 'a3.23'),\n",
       " (3, 'a3.29'),\n",
       " (3, 'm3'),\n",
       " (4, 'a4.10'),\n",
       " (4, 'a4.13'),\n",
       " (4, 'a4.16'),\n",
       " (4, 'a4.20'),\n",
       " (4, 'a4.25'),\n",
       " (4, 'a4.4'),\n",
       " (4, 'm4'),\n",
       " (5, 'a5.0'),\n",
       " (5, 'a5.17'),\n",
       " (5, 'a5.20'),\n",
       " (5, 'm5'),\n",
       " (6, 'a6.19'),\n",
       " (6, 'a6.6'),\n",
       " (6, 'm6'),\n",
       " (7, 'a7.14'),\n",
       " (7, 'a7.15'),\n",
       " (7, 'a7.20'),\n",
       " (7, 'a7.8'),\n",
       " (7, 'a7.9'),\n",
       " (7, 'm7'),\n",
       " (8, 'a8.11'),\n",
       " (8, 'a8.14'),\n",
       " (8, 'a8.26'),\n",
       " (8, 'a8.6'),\n",
       " (8, 'm8'),\n",
       " (9, 'a9.0'),\n",
       " (9, 'a9.15'),\n",
       " (9, 'a9.19'),\n",
       " (9, 'a9.3'),\n",
       " (9, 'a9.8'),\n",
       " (9, 'a9.9'),\n",
       " (9, 'm9'),\n",
       " (10, 'a10.1'),\n",
       " (10, 'a10.10'),\n",
       " (10, 'a10.11'),\n",
       " (10, 'a10.14'),\n",
       " (10, 'a10.21'),\n",
       " (10, 'a10.26'),\n",
       " (10, 'a10.29'),\n",
       " (10, 'm10'),\n",
       " (11, 'a11.10'),\n",
       " (11, 'a11.12'),\n",
       " (11, 'a11.14'),\n",
       " (11, 'a11.21'),\n",
       " (11, 'a11.24'),\n",
       " (11, 'a11.25'),\n",
       " (11, 'a11.31'),\n",
       " (11, 'a11.8'),\n",
       " (11, 'm11'),\n",
       " (12, 'a12.1'),\n",
       " (12, 'a12.12'),\n",
       " (12, 'a12.15'),\n",
       " (12, 'a12.17'),\n",
       " (12, 'a12.2'),\n",
       " (12, 'a12.23'),\n",
       " (12, 'a12.26'),\n",
       " (12, 'm12'),\n",
       " (13, 'a13.0'),\n",
       " (13, 'a13.12'),\n",
       " (13, 'a13.16'),\n",
       " (13, 'a13.20'),\n",
       " (13, 'a13.25'),\n",
       " (13, 'a13.30'),\n",
       " (13, 'a13.8'),\n",
       " (13, 'm13'),\n",
       " (14, 'a14.12'),\n",
       " (14, 'a14.14'),\n",
       " (14, 'a14.22'),\n",
       " (14, 'a14.23'),\n",
       " (14, 'a14.31'),\n",
       " (14, 'a14.4'),\n",
       " (14, 'a14.8'),\n",
       " (14, 'm14'),\n",
       " (15, 'a15.11'),\n",
       " (15, 'a15.18'),\n",
       " (15, 'a15.20'),\n",
       " (15, 'a15.27'),\n",
       " (15, 'a15.28'),\n",
       " (15, 'a15.4'),\n",
       " (15, 'a15.5'),\n",
       " (15, 'a15.6'),\n",
       " (15, 'm15'),\n",
       " (16, 'a16.10'),\n",
       " (16, 'a16.17'),\n",
       " (16, 'a16.20'),\n",
       " (16, 'a16.21'),\n",
       " (16, 'a16.29'),\n",
       " (16, 'm16'),\n",
       " (17, 'a17.11'),\n",
       " (17, 'a17.21'),\n",
       " (17, 'a17.28'),\n",
       " (17, 'a17.30'),\n",
       " (17, 'a17.6'),\n",
       " (17, 'm17'),\n",
       " (18, 'a18.31'),\n",
       " (18, 'm18'),\n",
       " (19, 'a19.24'),\n",
       " (19, 'a19.30'),\n",
       " (19, 'm19'),\n",
       " (20, 'a20.17'),\n",
       " (20, 'a20.2'),\n",
       " (20, 'a20.8'),\n",
       " (20, 'm20'),\n",
       " (21, 'a21.19'),\n",
       " (21, 'a21.23'),\n",
       " (21, 'a21.31'),\n",
       " (21, 'a21.9'),\n",
       " (21, 'm21'),\n",
       " (22, 'a22.15'),\n",
       " (22, 'a22.17'),\n",
       " (22, 'a22.24'),\n",
       " (22, 'm22'),\n",
       " (23, 'a23.26'),\n",
       " (23, 'm23'),\n",
       " (24, 'a24.21'),\n",
       " (24, 'm24'),\n",
       " (25, 'a25.1'),\n",
       " (25, 'a25.17'),\n",
       " (25, 'm25'),\n",
       " (26, 'a26.0'),\n",
       " (26, 'a26.25'),\n",
       " (26, 'a26.4'),\n",
       " (26, 'm26'),\n",
       " (27, 'a27.13'),\n",
       " (27, 'm27'),\n",
       " (28, 'a28.19'),\n",
       " (28, 'm28'),\n",
       " (29, 'a29.13'),\n",
       " (29, 'm29'),\n",
       " (30, 'm30'),\n",
       " (31, 'm31')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acdcpp_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='blocks.29.attn.weight_mask_W_O', nonzero indices: (tensor([13, 13, 13,  ..., 13, 13, 13], device='cuda:0'), tensor([ 0,  0,  0,  ..., 79, 79, 79], device='cuda:0'), tensor([   0,    1,    2,  ..., 2557, 2558, 2559], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad and \"blocks.29.attn.weight_mask_W_O\" in name:\n",
    "        zero_indices = torch.nonzero(param.grad != 0, as_tuple=True)\n",
    "        print(f\"{name=}, nonzero indices: {zero_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if correct MLPs flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'm2')\n",
      "(10, 'm10')\n",
      "(5, 'm5')\n",
      "(3, 'm3')\n",
      "(7, 'm7')\n",
      "(1, 'm1')\n",
      "(9, 'm9')\n",
      "(8, 'm8')\n",
      "(4, 'm4')\n",
      "(0, 'm0')\n",
      "(-1, 'embed')\n",
      "(6, 'm6')\n"
     ]
    }
   ],
   "source": [
    "for node in acdcpp_nodes:\n",
    "    if \"m\" in node[1]:\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.edge_mask_mlp grad is all zeros\n",
      "blocks.0.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.0.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.0.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(1.5009, device='cuda:0')\n",
      "blocks.0.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.3840, device='cuda:0')\n",
      "blocks.0.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(1.9580, device='cuda:0')\n",
      "blocks.0.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.2079, device='cuda:0')\n",
      "blocks.1.edge_mask_mlp grad is all zeros\n",
      "blocks.1.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.1.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.1.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(2.1881, device='cuda:0')\n",
      "blocks.1.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.4780, device='cuda:0')\n",
      "blocks.1.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(2.0281, device='cuda:0')\n",
      "blocks.1.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.2563, device='cuda:0')\n",
      "blocks.2.edge_mask_mlp grad is all zeros\n",
      "blocks.2.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.2.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.2.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(2.7383, device='cuda:0')\n",
      "blocks.2.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.4888, device='cuda:0')\n",
      "blocks.2.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(2.4441, device='cuda:0')\n",
      "blocks.2.mlp.b_out grad is all zeros\n",
      "blocks.3.edge_mask_mlp grad is all zeros\n",
      "blocks.3.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.3.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.3.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(2.1551, device='cuda:0')\n",
      "blocks.3.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.3966, device='cuda:0')\n",
      "blocks.3.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(2.1005, device='cuda:0')\n",
      "blocks.3.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.2987, device='cuda:0')\n",
      "blocks.4.edge_mask_mlp grad is all zeros\n",
      "blocks.4.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.4.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.4.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(2.7344, device='cuda:0')\n",
      "blocks.4.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.5089, device='cuda:0')\n",
      "blocks.4.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(2.5127, device='cuda:0')\n",
      "blocks.4.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.3237, device='cuda:0')\n",
      "blocks.5.edge_mask_mlp grad is all zeros\n",
      "blocks.5.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.5.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.5.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(2.8992, device='cuda:0')\n",
      "blocks.5.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.5541, device='cuda:0')\n",
      "blocks.5.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(2.4629, device='cuda:0')\n",
      "blocks.5.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.3042, device='cuda:0')\n",
      "blocks.6.edge_mask_mlp grad is all zeros\n",
      "blocks.6.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.6.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.6.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(3.0009, device='cuda:0')\n",
      "blocks.6.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.5724, device='cuda:0')\n",
      "blocks.6.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(2.4607, device='cuda:0')\n",
      "blocks.6.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.2637, device='cuda:0')\n",
      "blocks.7.edge_mask_mlp grad is all zeros\n",
      "blocks.7.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.7.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.7.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(2.3364, device='cuda:0')\n",
      "blocks.7.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.4871, device='cuda:0')\n",
      "blocks.7.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(1.9889, device='cuda:0')\n",
      "blocks.7.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.2189, device='cuda:0')\n",
      "blocks.8.edge_mask_mlp grad is all zeros\n",
      "blocks.8.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.8.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.8.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(2.8043, device='cuda:0')\n",
      "blocks.8.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.6429, device='cuda:0')\n",
      "blocks.8.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(1.5990, device='cuda:0')\n",
      "blocks.8.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.1610, device='cuda:0')\n",
      "blocks.9.edge_mask_mlp grad is all zeros\n",
      "blocks.9.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.9.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.9.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(2.1774, device='cuda:0')\n",
      "blocks.9.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.4569, device='cuda:0')\n",
      "blocks.9.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(1.3034, device='cuda:0')\n",
      "blocks.9.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.1200, device='cuda:0')\n",
      "blocks.10.edge_mask_mlp grad is all zeros\n",
      "blocks.10.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.10.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.10.mlp.W_in grad is not all zeros, param.grad.norm()=tensor(1.3321, device='cuda:0')\n",
      "blocks.10.mlp.b_in grad is not all zeros, param.grad.norm()=tensor(0.2768, device='cuda:0')\n",
      "blocks.10.mlp.W_out grad is not all zeros, param.grad.norm()=tensor(0.9347, device='cuda:0')\n",
      "blocks.10.mlp.b_out grad is not all zeros, param.grad.norm()=tensor(0.0822, device='cuda:0')\n",
      "blocks.11.edge_mask_mlp grad is all zeros\n",
      "blocks.11.edge_mask_mlp_baseline grad is all zeros\n",
      "blocks.11.edge_mask_mlp_frozen grad is all zeros\n",
      "blocks.11.mlp.W_in grad is all zeros\n",
      "blocks.11.mlp.b_in grad is all zeros\n",
      "blocks.11.mlp.W_out grad is all zeros\n",
      "blocks.11.mlp.b_out grad is all zeros\n"
     ]
    }
   ],
   "source": [
    "param_names = []\n",
    "model_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if \"mlp\" in name:\n",
    "        # check if param.grad is all zeros\n",
    "        if param.grad is not None and param.grad.sum() != 0:\n",
    "            print(f\"{name} grad is not all zeros, {param.grad.norm()=}\")\n",
    "        else:\n",
    "            print(f\"{name} grad is all zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if individual attention heads have gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 'a9.7')\n",
      "(9, 'a9.9')\n",
      "(9, 'a9.6')\n",
      "(9, 'a9.8')\n"
     ]
    }
   ],
   "source": [
    "for node in acdcpp_nodes:\n",
    "    if \"a9\" in node[1]:\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 768, 64])\n",
      "param.grad[3].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[4].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[7].norm()=tensor(0.1051, device='cuda:0')\n",
      "param.grad[8].norm()=tensor(0.0287, device='cuda:0')\n",
      "param.grad[11].norm()=tensor(0., device='cuda:0')\n",
      "\n",
      "torch.Size([12, 768, 64])\n",
      "param.grad[3].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[4].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[7].norm()=tensor(0.1273, device='cuda:0')\n",
      "param.grad[8].norm()=tensor(0.0335, device='cuda:0')\n",
      "param.grad[11].norm()=tensor(0., device='cuda:0')\n",
      "\n",
      "torch.Size([12, 768, 64])\n",
      "param.grad[3].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[4].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[7].norm()=tensor(0.0570, device='cuda:0')\n",
      "param.grad[8].norm()=tensor(0.0485, device='cuda:0')\n",
      "param.grad[11].norm()=tensor(0., device='cuda:0')\n",
      "\n",
      "torch.Size([12, 64, 768])\n",
      "param.grad[3].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[4].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[7].norm()=tensor(0.0306, device='cuda:0')\n",
      "param.grad[8].norm()=tensor(0.0389, device='cuda:0')\n",
      "param.grad[11].norm()=tensor(0., device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_names = []\n",
    "model_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad and \"9.attn.weight\" in name:\n",
    "    # if param.requires_grad and \"9.attn.b\" in name:\n",
    "        print(param.shape)\n",
    "        # if param.grad is not None and param.grad.sum() != 0:\n",
    "        #     print(f\"{name} grad is not all zeros, {param.grad.norm()=}\")\n",
    "        # else:\n",
    "        #     print(f\"{name} grad is all zeros\")\n",
    "        print(f\"{param.grad[3].norm()=}\")\n",
    "        print(f\"{param.grad[4].norm()=}\")\n",
    "        print(f\"{param.grad[7].norm()=}\")\n",
    "        print(f\"{param.grad[8].norm()=}\")\n",
    "        print(f\"{param.grad[11].norm()=}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Mask Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from tasks import IOITask, SportsTask, OWTTask\n",
    "batch_size = 64\n",
    "ioi = IOITask(batch_size=batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, prompt_type=\"ABBA\", nb_templates=1, template_start_idx=0)\n",
    "sports = SportsTask(batch_size=batch_size, tokenizer=tokenizer, device=device)\n",
    "owt = OWTTask(batch_size=batch_size, tokenizer=tokenizer, device=device)\n",
    "\n",
    "ioi_ood = IOITask(batch_size=batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, prompt_type=\"ABBA\", nb_templates=1, template_start_idx=1) # different template\n",
    "\n",
    "train_tasks = {\"ioi\": ioi, \"owt\": owt}\n",
    "task_weights = {\"ioi\": -.2, \"owt\": 1} # I think means preserve OWT, corrupt IOI\n",
    "eval_tasks = {\"ioi\": ioi, \"sports\": sports, \"owt\": owt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_params = []\n",
    "param_names = []\n",
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        param_names.append(name)\n",
    "        mask_params.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphilliphguo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/phillip_guo/mechanistic-unlearning/wandb/run-20240110_085753-mznr9fva</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/philliphguo/mech_unlearning/runs/mznr9fva' target=\"_blank\">vocal-deluge-22</a></strong> to <a href='https://wandb.ai/philliphguo/mech_unlearning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/philliphguo/mech_unlearning' target=\"_blank\">https://wandb.ai/philliphguo/mech_unlearning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/philliphguo/mech_unlearning/runs/mznr9fva' target=\"_blank\">https://wandb.ai/philliphguo/mech_unlearning/runs/mznr9fva</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 32/501 [10:48<2:38:21, 20.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_93609/3197613862.py\", line 15, in <module>\n",
      "    train_masks(model, tasks=train_tasks, optimizer=optimizer, num_epochs=epochs_left, steps_per_epoch=steps_per_epoch,\n",
      "  File \"/data/phillip_guo/mechanistic-unlearning/cb_utils/learn_mask.py\", line 178, in train_masks\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from cb_utils.learn_mask import train_masks\n",
    "\n",
    "epochs_left = 500\n",
    "steps_per_epoch = 10\n",
    "lr = .05 # free\n",
    "weight_decay = 0\n",
    "evaluate_every = 1\n",
    "discretize_every = 50 # 5 # free\n",
    "threshold = 0.5\n",
    "use_wandb = False\n",
    "edge_mask_reg_strength = None\n",
    "weight_mask_reg_strength = 10\n",
    "\n",
    "wandb_config = {\"edge_masks\": edge_masks, \"weight_masks_attn\": weight_masks_attn, \"weight_masks_mlp\": weight_masks_mlp, \"epochs\": epochs_left, \"steps_per_epoch\": steps_per_epoch, \"lr\": lr, \"weight_decay\": weight_decay, \"evaluate_every\": evaluate_every, \"discretize_every\": discretize_every, \"threshold\": threshold, \"edge_mask_reg_strength\": edge_mask_reg_strength, \"weight_mask_reg_strength\": weight_mask_reg_strength}\n",
    "\n",
    "optimizer = torch.optim.AdamW(mask_params, lr=lr, weight_decay=weight_decay)\n",
    "train_masks(model, tasks=train_tasks, optimizer=optimizer, num_epochs=epochs_left, steps_per_epoch=steps_per_epoch,\n",
    "            # param_names=param_names, mask_params=mask_params, \n",
    "            task_weights=task_weights, eval_tasks=eval_tasks, evaluate_every=evaluate_every, discretize_every=discretize_every, threshold=threshold, edge_mask_reg_strength=edge_mask_reg_strength, weight_mask_reg_strength=None, verbose=False, use_wandb=use_wandb, wandb_config=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"masks/trained_mask_params_{epochs_left=}_{edge_mask_reg_strength=}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mask_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, p in zip(param_names, mask_params):\n",
    "    if p.requires_grad:\n",
    "        # print(name, p)\n",
    "        # count how many zeros in p\n",
    "        print(torch.sum(p == 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlrn",
   "language": "python",
   "name": "unlrn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
