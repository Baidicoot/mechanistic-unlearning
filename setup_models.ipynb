{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up models for edge or weight masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow:\n",
    "- Load model\n",
    "- Use Task with clean and corrupt data, use ACDCPP and get the ACDCPP-style edges\n",
    "- Convert ACDCPP-style edges to edge mask, get either edge superset of node superset\n",
    "- Apply these masks to the mask training, either by limiting edge mask to only edge superset, node superset, or by limiting weight mask to node superset\n",
    "\n",
    "- Also need to test other baselines, like regular finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('acdcpp/Automatic-Circuit-Discovery/')\n",
    "sys.path.append('acdcpp/')\n",
    "from acdc import TLACDCExperiment\n",
    "from acdcpp.ACDCPPExperiment import ACDCPPExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# import acdc\n",
    "from acdc.TLACDCExperiment import TLACDCExperiment\n",
    "from acdc.acdc_utils import TorchIndex, EdgeType\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import einops\n",
    "import itertools\n",
    "\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "import plotly\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "\n",
    "from jaxtyping import Float, Bool\n",
    "from typing import Callable, Tuple, Union, Dict, Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "device = t.device('cuda') if t.cuda.is_available() else t.device('cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# set up pipeline from acdcpp to edge mask\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    'gpt2-small',\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.666549248"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated(device=device) / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ACDCPP edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.ioi.IOITask import IOITask_old, IOITask\n",
    "# ioi_task = IOITask(batch_size=5, tokenizer=model.tokenizer, device=device, prep_acdcpp=True, acdcpp_N=25)\n",
    "ioi_task = IOITask(batch_size=5, tokenizer=model.tokenizer, device=device, prep_acdcpp=True, acdcpp_N=25, nb_templates=1, prompt_type=\"ABBA\")\n",
    "ioi_task.set_logit_diffs(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ioi_metric = ioi_task.get_acdcpp_metric()\n",
    "def negative_abs_ioi_metric(logits: Float[Tensor, \"batch seq_len d_vocab\"]):\n",
    "    return -abs(ioi_metric(logits))\n",
    "\n",
    "with t.no_grad():\n",
    "    clean_logits = model(ioi_task.clean_data.toks)\n",
    "    corrupt_logits = model(ioi_task.corr_data.toks)\n",
    "    clean_logit_diff = ioi_task.ave_logit_diff(clean_logits, ioi_task.clean_data).item()\n",
    "    corrupt_logit_diff = ioi_task.ave_logit_diff(corrupt_logits, ioi_task.corr_data).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean direction: 2.9320199489593506, Corrupt direction: 1.086446762084961\n",
      "Clean metric: 1.0, Corrupt metric: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get clean and corrupt logit differences\n",
    "with t.no_grad():\n",
    "    clean_metric = ioi_metric(clean_logits, corrupt_logit_diff, clean_logit_diff, ioi_task.clean_data)\n",
    "    corrupt_metric = ioi_metric(corrupt_logits, corrupt_logit_diff, clean_logit_diff, ioi_task.corr_data)\n",
    "\n",
    "print(f'Clean direction: {clean_logit_diff}, Corrupt direction: {corrupt_logit_diff}')\n",
    "print(f'Clean metric: {clean_metric}, Corrupt metric: {corrupt_metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 15052.08it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:04<00:00, 243.69it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 304686.69it/s]\n",
      " 50%|█████     | 1/2 [00:08<00:08,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([-1, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 14879.49it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:04<00:00, 245.62it/s]\n",
      "Edge pruning: 100%|██████████| 1034/1034 [00:00<00:00, 309934.28it/s]\n",
      "100%|██████████| 2/2 [00:15<00:00,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([-1, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "THRESHOLDS = [0.08, .15]#np.arange(0.005, 0.155, 0.005)\n",
    "RUN_NAME = 'abs_edge'\n",
    "\n",
    "acdcpp_exp = ACDCPPExperiment(\n",
    "    model=model,\n",
    "    clean_data=ioi_task.clean_data.toks,\n",
    "    corr_data=ioi_task.corr_data.toks,\n",
    "    acdc_metric=negative_abs_ioi_metric,\n",
    "    acdcpp_metric=ioi_metric,\n",
    "    thresholds=THRESHOLDS,\n",
    "    run_name=RUN_NAME,\n",
    "    verbose=False,\n",
    "    attr_absolute_val=True,\n",
    "    save_graphs_after=-100,\n",
    "    pruning_mode='edge',\n",
    "    no_pruned_nodes_attr=1,\n",
    "    run_acdc=False,\n",
    "    run_acdcpp=True,\n",
    ")\n",
    "# e=acdcpp_exp.setup_exp(0.0)\n",
    "\n",
    "pruned_heads, num_passes, acdcpp_pruned_attrs, acdc_pruned_attrs, edges_after_acdcpp, edges_after_acdc = acdcpp_exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"masks/ioi_acdcpp_edges.pkl\", \"wb\") as f:\n",
    "    pickle.dump(edges_after_acdcpp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cb_utils.mask_utils import get_node_name\n",
    "\n",
    "acdcpp_edges = set()\n",
    "for edge in edges_after_acdcpp[0.08]:\n",
    "    # split the edge into two nodes, e.g. blocks.1.attn.hook_result[:, :, 10]blocks.0.hook_mlp_in[:] into blocks.1.attn.hook_result[:, :, 10] and blocks.0.hook_mlp_in[:]\n",
    "    node_1 = get_node_name(edge.split(\"]\")[0]+\"]\", show_full_index=False)\n",
    "    node_2 = get_node_name(edge.split(\"]\")[1]+\"]\", show_full_index=False)\n",
    "    if node_1 != node_2:\n",
    "        acdcpp_edges.add((node_1, node_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cb_utils.mask_utils import get_edge_mask_template, get_mask_from_edges, convert_mask_dict_to_params, get_nodes_from_edges, get_mask_components\n",
    "edge_mask_template = get_edge_mask_template()\n",
    "acdcpp_mask_dict = get_mask_from_edges(acdcpp_edges, edge_mask_template=edge_mask_template, num_layers=12, num_heads=12)\n",
    "acdcpp_nodes = get_nodes_from_edges(acdcpp_edges)\n",
    "acdcpp_weight_mask_attn_dict, acdcpp_weight_mask_mlp_dict = get_mask_components(acdcpp_nodes, num_layers=12, num_heads=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: True,\n",
       " 1: True,\n",
       " 2: True,\n",
       " 3: True,\n",
       " 4: True,\n",
       " 5: True,\n",
       " 6: True,\n",
       " 7: True,\n",
       " 8: False,\n",
       " 9: False,\n",
       " 10: False,\n",
       " 11: False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acdcpp_weight_mask_mlp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from cb_utils.transformer import DemoTransformer\n",
    "from cb_utils.models import load_demo_gpt2, tokenizer\n",
    "means_ioi = True\n",
    "if means_ioi:\n",
    "    with open(\"data/gpt2_ioi_abc_means.pkl\", \"rb\") as f:\n",
    "        means = pickle.load(f)[0]\n",
    "else:\n",
    "    with open(\"data/gpt2_means.pkl\", \"rb\") as f:\n",
    "        means = pickle.load(f)[0]\n",
    "\n",
    "edge_masks = False\n",
    "weight_masks_attn = True\n",
    "weight_masks_mlp = True\n",
    "# model = load_demo_gpt2(means=means, mask_dict_superset=acdcpp_mask_dict)\n",
    "model = load_demo_gpt2(means=False, edge_masks=edge_masks, weight_masks_attn=weight_masks_attn, weight_masks_mlp=weight_masks_mlp, weight_mask_attn_dict=acdcpp_weight_mask_attn_dict, weight_mask_mlp_dict=acdcpp_weight_mask_mlp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test that gradients flow correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "batch_size = 8\n",
    "ioi = IOITask(batch_size=batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False)\n",
    "loss = ioi.get_train_loss(model)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_mask grad is all zeros\n",
      "blocks.0.edge_mask_attentions grad is all zeros\n",
      "blocks.0.edge_mask_mlp grad is all zeros\n",
      "blocks.0.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0015, device='cuda:0')\n",
      "blocks.0.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.0019, device='cuda:0')\n",
      "blocks.0.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.0386, device='cuda:0')\n",
      "blocks.0.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0713, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.2116, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2009, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0584, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0196, device='cuda:0')\n",
      "blocks.1.edge_mask_attentions grad is all zeros\n",
      "blocks.1.edge_mask_mlp grad is all zeros\n",
      "blocks.1.attn.weight_mask_W_Q grad is all zeros\n",
      "blocks.1.attn.weight_mask_W_K grad is all zeros\n",
      "blocks.1.attn.weight_mask_W_V grad is all zeros\n",
      "blocks.1.attn.weight_mask_W_O grad is all zeros\n",
      "blocks.1.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.2823, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.1886, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0631, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0270, device='cuda:0')\n",
      "blocks.2.edge_mask_attentions grad is all zeros\n",
      "blocks.2.edge_mask_mlp grad is all zeros\n",
      "blocks.2.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0127, device='cuda:0')\n",
      "blocks.2.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.0170, device='cuda:0')\n",
      "blocks.2.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.0239, device='cuda:0')\n",
      "blocks.2.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0319, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3676, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2076, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0597, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0347, device='cuda:0')\n",
      "blocks.3.edge_mask_attentions grad is all zeros\n",
      "blocks.3.edge_mask_mlp grad is all zeros\n",
      "blocks.3.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0191, device='cuda:0')\n",
      "blocks.3.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.0210, device='cuda:0')\n",
      "blocks.3.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.0321, device='cuda:0')\n",
      "blocks.3.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0502, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.2614, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.1930, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0559, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0345, device='cuda:0')\n",
      "blocks.4.edge_mask_attentions grad is all zeros\n",
      "blocks.4.edge_mask_mlp grad is all zeros\n",
      "blocks.4.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1006, device='cuda:0')\n",
      "blocks.4.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.0686, device='cuda:0')\n",
      "blocks.4.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.0851, device='cuda:0')\n",
      "blocks.4.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0867, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3642, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2323, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0817, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0508, device='cuda:0')\n",
      "blocks.5.edge_mask_attentions grad is all zeros\n",
      "blocks.5.edge_mask_mlp grad is all zeros\n",
      "blocks.5.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0590, device='cuda:0')\n",
      "blocks.5.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.0522, device='cuda:0')\n",
      "blocks.5.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.0940, device='cuda:0')\n",
      "blocks.5.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0776, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3597, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2412, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1062, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0356, device='cuda:0')\n",
      "blocks.6.edge_mask_attentions grad is all zeros\n",
      "blocks.6.edge_mask_mlp grad is all zeros\n",
      "blocks.6.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1236, device='cuda:0')\n",
      "blocks.6.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.0886, device='cuda:0')\n",
      "blocks.6.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.0739, device='cuda:0')\n",
      "blocks.6.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0691, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3642, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2584, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0725, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0336, device='cuda:0')\n",
      "blocks.7.edge_mask_attentions grad is all zeros\n",
      "blocks.7.edge_mask_mlp grad is all zeros\n",
      "blocks.7.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.3010, device='cuda:0')\n",
      "blocks.7.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.2242, device='cuda:0')\n",
      "blocks.7.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1309, device='cuda:0')\n",
      "blocks.7.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0756, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3085, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2502, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1188, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0308, device='cuda:0')\n",
      "blocks.8.edge_mask_attentions grad is all zeros\n",
      "blocks.8.edge_mask_mlp grad is all zeros\n",
      "blocks.8.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.3146, device='cuda:0')\n",
      "blocks.8.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.1734, device='cuda:0')\n",
      "blocks.8.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1324, device='cuda:0')\n",
      "blocks.8.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.1099, device='cuda:0')\n",
      "blocks.9.edge_mask_attentions grad is all zeros\n",
      "blocks.9.edge_mask_mlp grad is all zeros\n",
      "blocks.9.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.0756, device='cuda:0')\n",
      "blocks.9.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.0954, device='cuda:0')\n",
      "blocks.9.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1278, device='cuda:0')\n",
      "blocks.9.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0873, device='cuda:0')\n",
      "blocks.10.edge_mask_attentions grad is all zeros\n",
      "blocks.10.edge_mask_mlp grad is all zeros\n",
      "blocks.10.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1390, device='cuda:0')\n",
      "blocks.10.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.1565, device='cuda:0')\n",
      "blocks.10.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.1409, device='cuda:0')\n",
      "blocks.10.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0765, device='cuda:0')\n",
      "blocks.11.edge_mask_attentions grad is all zeros\n",
      "blocks.11.edge_mask_mlp grad is all zeros\n",
      "blocks.11.attn.weight_mask_W_Q grad is not all zeros, param.grad.norm()=tensor(0.1658, device='cuda:0')\n",
      "blocks.11.attn.weight_mask_W_K grad is not all zeros, param.grad.norm()=tensor(0.2444, device='cuda:0')\n",
      "blocks.11.attn.weight_mask_W_V grad is not all zeros, param.grad.norm()=tensor(0.0702, device='cuda:0')\n",
      "blocks.11.attn.weight_mask_W_O grad is not all zeros, param.grad.norm()=tensor(0.0414, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "param_names = []\n",
    "model_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        # check if param.grad is all zeros\n",
    "        if param.grad is not None and param.grad.sum() != 0:\n",
    "            print(f\"{name} grad is not all zeros, {param.grad.norm()=}\")\n",
    "        else:\n",
    "            print(f\"{name} grad is all zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if correct MLPs flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 'embed')\n",
      "(6, 'm6')\n",
      "(4, 'm4')\n",
      "(5, 'm5')\n",
      "(7, 'm7')\n",
      "(3, 'm3')\n",
      "(2, 'm2')\n",
      "(0, 'm0')\n",
      "(1, 'm1')\n"
     ]
    }
   ],
   "source": [
    "for node in acdcpp_nodes:\n",
    "    if \"m\" in node[1]:\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.0.edge_mask_mlp grad is all zeros\n",
      "blocks.0.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.2116, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2009, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0584, device='cuda:0')\n",
      "blocks.0.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0196, device='cuda:0')\n",
      "blocks.1.edge_mask_mlp grad is all zeros\n",
      "blocks.1.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.2823, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.1886, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0631, device='cuda:0')\n",
      "blocks.1.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0270, device='cuda:0')\n",
      "blocks.2.edge_mask_mlp grad is all zeros\n",
      "blocks.2.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3676, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2076, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0597, device='cuda:0')\n",
      "blocks.2.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0347, device='cuda:0')\n",
      "blocks.3.edge_mask_mlp grad is all zeros\n",
      "blocks.3.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.2614, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.1930, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0559, device='cuda:0')\n",
      "blocks.3.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0345, device='cuda:0')\n",
      "blocks.4.edge_mask_mlp grad is all zeros\n",
      "blocks.4.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3642, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2323, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0817, device='cuda:0')\n",
      "blocks.4.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0508, device='cuda:0')\n",
      "blocks.5.edge_mask_mlp grad is all zeros\n",
      "blocks.5.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3597, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2412, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1062, device='cuda:0')\n",
      "blocks.5.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0356, device='cuda:0')\n",
      "blocks.6.edge_mask_mlp grad is all zeros\n",
      "blocks.6.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3642, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2584, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.0725, device='cuda:0')\n",
      "blocks.6.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0336, device='cuda:0')\n",
      "blocks.7.edge_mask_mlp grad is all zeros\n",
      "blocks.7.mlp.weight_mask_W_in grad is not all zeros, param.grad.norm()=tensor(0.3085, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_W_out grad is not all zeros, param.grad.norm()=tensor(0.2502, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_b_in grad is not all zeros, param.grad.norm()=tensor(0.1188, device='cuda:0')\n",
      "blocks.7.mlp.weight_mask_b_out grad is not all zeros, param.grad.norm()=tensor(0.0308, device='cuda:0')\n",
      "blocks.8.edge_mask_mlp grad is all zeros\n",
      "blocks.9.edge_mask_mlp grad is all zeros\n",
      "blocks.10.edge_mask_mlp grad is all zeros\n",
      "blocks.11.edge_mask_mlp grad is all zeros\n"
     ]
    }
   ],
   "source": [
    "param_names = []\n",
    "model_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad and \"mlp\" in name:\n",
    "        # check if param.grad is all zeros\n",
    "        if param.grad is not None and param.grad.sum() != 0:\n",
    "            print(f\"{name} grad is not all zeros, {param.grad.norm()=}\")\n",
    "        else:\n",
    "            print(f\"{name} grad is all zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if individual attention heads have gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 'a4.11')\n",
      "(4, 'a4.3')\n",
      "(4, 'a4.7')\n"
     ]
    }
   ],
   "source": [
    "for node in acdcpp_nodes:\n",
    "    if \"a4\" in node[1]:\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param.grad[3].norm()=tensor(0.0645, device='cuda:0')\n",
      "param.grad[4].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[7].norm()=tensor(0.0773, device='cuda:0')\n",
      "param.grad[8].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[11].norm()=tensor(6.8363e-05, device='cuda:0')\n",
      "\n",
      "param.grad[3].norm()=tensor(0.0472, device='cuda:0')\n",
      "param.grad[4].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[7].norm()=tensor(0.0497, device='cuda:0')\n",
      "param.grad[8].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[11].norm()=tensor(6.9457e-05, device='cuda:0')\n",
      "\n",
      "param.grad[3].norm()=tensor(0.0416, device='cuda:0')\n",
      "param.grad[4].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[7].norm()=tensor(0.0587, device='cuda:0')\n",
      "param.grad[8].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[11].norm()=tensor(0.0455, device='cuda:0')\n",
      "\n",
      "param.grad[3].norm()=tensor(0.0442, device='cuda:0')\n",
      "param.grad[4].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[7].norm()=tensor(0.0540, device='cuda:0')\n",
      "param.grad[8].norm()=tensor(0., device='cuda:0')\n",
      "param.grad[11].norm()=tensor(0.0515, device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_names = []\n",
    "model_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad and \"4.attn.weight\" in name:\n",
    "        # if param.grad is not None and param.grad.sum() != 0:\n",
    "        #     print(f\"{name} grad is not all zeros, {param.grad.norm()=}\")\n",
    "        # else:\n",
    "        #     print(f\"{name} grad is all zeros\")\n",
    "        print(f\"{param.grad[3].norm()=}\")\n",
    "        print(f\"{param.grad[4].norm()=}\")\n",
    "        print(f\"{param.grad[7].norm()=}\")\n",
    "        print(f\"{param.grad[8].norm()=}\")\n",
    "        print(f\"{param.grad[11].norm()=}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Mask Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from tasks import IOITask, SportsTask, OWTTask\n",
    "batch_size = 64\n",
    "ioi = IOITask(batch_size=batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, prompt_type=\"ABBA\", nb_templates=1, template_start_idx=0)\n",
    "sports = SportsTask(batch_size=batch_size, tokenizer=tokenizer, device=device)\n",
    "owt = OWTTask(batch_size=batch_size, tokenizer=tokenizer, device=device)\n",
    "\n",
    "ioi_ood = IOITask(batch_size=batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, prompt_type=\"ABBA\", nb_templates=1, template_start_idx=1) # different template\n",
    "\n",
    "train_tasks = {\"ioi\": ioi, \"owt\": owt}\n",
    "task_weights = {\"ioi\": -.2, \"owt\": 1} # I think means preserve OWT, corrupt IOI\n",
    "eval_tasks = {\"ioi\": ioi, \"sports\": sports, \"owt\": owt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_params = []\n",
    "param_names = []\n",
    "for name, p in model.named_parameters():\n",
    "    if p.requires_grad:\n",
    "        param_names.append(name)\n",
    "        mask_params.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphilliphguo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/phillip_guo/mechanistic-unlearning/wandb/run-20240110_085753-mznr9fva</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/philliphguo/mech_unlearning/runs/mznr9fva' target=\"_blank\">vocal-deluge-22</a></strong> to <a href='https://wandb.ai/philliphguo/mech_unlearning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/philliphguo/mech_unlearning' target=\"_blank\">https://wandb.ai/philliphguo/mech_unlearning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/philliphguo/mech_unlearning/runs/mznr9fva' target=\"_blank\">https://wandb.ai/philliphguo/mech_unlearning/runs/mznr9fva</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 32/501 [10:48<2:38:21, 20.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_93609/3197613862.py\", line 15, in <module>\n",
      "    train_masks(model, tasks=train_tasks, optimizer=optimizer, num_epochs=epochs_left, steps_per_epoch=steps_per_epoch,\n",
      "  File \"/data/phillip_guo/mechanistic-unlearning/cb_utils/learn_mask.py\", line 178, in train_masks\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/data/phillip_guo/miniconda3/envs/unlrn/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from cb_utils.learn_mask import train_masks\n",
    "\n",
    "epochs_left = 500\n",
    "steps_per_epoch = 10\n",
    "lr = .05 # free\n",
    "weight_decay = 0\n",
    "evaluate_every = 1\n",
    "discretize_every = 50 # 5 # free\n",
    "threshold = 0.5\n",
    "use_wandb = False\n",
    "edge_mask_reg_strength = None\n",
    "weight_mask_reg_strength = 10\n",
    "\n",
    "wandb_config = {\"edge_masks\": edge_masks, \"weight_masks_attn\": weight_masks_attn, \"weight_masks_mlp\": weight_masks_mlp, \"epochs\": epochs_left, \"steps_per_epoch\": steps_per_epoch, \"lr\": lr, \"weight_decay\": weight_decay, \"evaluate_every\": evaluate_every, \"discretize_every\": discretize_every, \"threshold\": threshold, \"edge_mask_reg_strength\": edge_mask_reg_strength, \"weight_mask_reg_strength\": weight_mask_reg_strength}\n",
    "\n",
    "optimizer = torch.optim.AdamW(mask_params, lr=lr, weight_decay=weight_decay)\n",
    "train_masks(model, tasks=train_tasks, optimizer=optimizer, num_epochs=epochs_left, steps_per_epoch=steps_per_epoch,\n",
    "            # param_names=param_names, mask_params=mask_params, \n",
    "            task_weights=task_weights, eval_tasks=eval_tasks, evaluate_every=evaluate_every, discretize_every=discretize_every, threshold=threshold, edge_mask_reg_strength=edge_mask_reg_strength, weight_mask_reg_strength=None, verbose=False, use_wandb=use_wandb, wandb_config=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f\"masks/trained_mask_params_{epochs_left=}_{edge_mask_reg_strength=}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mask_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(3, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(2, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(12, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, p in zip(param_names, mask_params):\n",
    "    if p.requires_grad:\n",
    "        # print(name, p)\n",
    "        # count how many zeros in p\n",
    "        print(torch.sum(p == 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlrn",
   "language": "python",
   "name": "unlrn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
