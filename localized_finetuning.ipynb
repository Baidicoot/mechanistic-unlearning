{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from circuit_breaking.src import *\n",
    "import torch\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from circuit_breaking.src.utils import load_model_from_transformers, from_hf_to_tlens\n",
    "from circuit_breaking.src.masks import MLPHiddenMask\n",
    "from tqdm.auto import tqdm\n",
    "#torch.autograd.set_detect_anomaly(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model_type = \"gemma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key not found, will not be able to run evaluations on Sports Trivia Task\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21d8c68a4d04ff5b15773dd37d3e422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24fea0cd77c47b582eefddb7643b7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fba9561f63346ca816d99d85513e024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70e83df8ead4d829f4b702a290f86f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tasks import PileTask, OWTTask, InductionTask, GreaterThanTask\n",
    "from tasks.ioi.IOITask import IOITask, IOITask_NPO, IOITask_Uniform\n",
    "from tasks.induction.InductionTask import InductionTask, InductionTask_NPO, InductionTask_Uniform\n",
    "from tasks.facts.SportsTask import SportsTask, SportsTask_NPO, SportsTask_Uniform\n",
    "from tasks.facts.SportsTaskAdversarial import adversarial_sports_eval\n",
    "from tasks.facts.SportsTaskSideEffects import run_side_effects_evals\n",
    "\n",
    "\n",
    "train_batch_size = 4\n",
    "eval_batch_size=32\n",
    "\n",
    "device = \"cuda\"\n",
    "train_loss_type = \"sports\"\n",
    "\n",
    "maintain_sport = None\n",
    "\n",
    "\n",
    "forget_sport=None\n",
    "forget_athletes = 16\n",
    "save_dir = f\"results/localized_finetuning_{forget_athletes}_athletes\"\n",
    "forget_kwargs = {\"forget_player_subset\": forget_athletes, \"is_forget_dataset\": True, \"train_test_split\": False}\n",
    "maintain_kwargs = {\"forget_player_subset\": forget_athletes, \"is_forget_dataset\": False, \"train_test_split\": True}\n",
    "forget_loss_coef = 1\n",
    "\n",
    "# forget_sport=\"basketball\"\n",
    "# forget_athletes = None\n",
    "# save_dir = f\"results/localized_finetuning_{forget_sport}\"\n",
    "# # save_dir = f\"results/localized_finetuning_{forget_sport}_old\"\n",
    "# forget_kwargs = {\"forget_sport_subset\": {forget_sport}, \"is_forget_dataset\": True, \"train_test_split\": True}\n",
    "# maintain_kwargs = {\"forget_sport_subset\": {forget_sport}, \"is_forget_dataset\": False, \"train_test_split\": True}\n",
    "# forget_loss_coef=.2\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "sports_1mp = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"log_1_minus_p\", **forget_kwargs)\n",
    "\n",
    "if maintain_sport is None:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", **maintain_kwargs)\n",
    "else:\n",
    "    maintain_sports = SportsTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", **maintain_kwargs)\n",
    "\n",
    "train_pile = PileTask(batch_size=train_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "train_tasks = {\"sports_1mp\": (sports_1mp, forget_loss_coef), \"maintain_sports\": (maintain_sports, 1), \"pile\": (train_pile, 1)}\n",
    "# train_tasks = {\"maintain_sports\": (maintain_sports, 1)}\n",
    "\n",
    "# want to eval on other sports\n",
    "forget_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", **forget_kwargs)\n",
    "test_pile = PileTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, ctx_length=100, shuffle=True, buffer_size=50000)\n",
    "\n",
    "induction_eval = InductionTask(batch_size=eval_batch_size, tokenizer=tokenizer, prep_acdcpp=False, seq_len=15, device=device)\n",
    "if maintain_sport is None:\n",
    "    maintain_sports_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", **maintain_kwargs)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sports_eval}\n",
    "else:\n",
    "    maintain_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={maintain_sport}, is_forget_dataset=True)\n",
    "    val_sport_eval = SportsTask(batch_size=eval_batch_size, tokenizer=tokenizer, device=device, prep_acdcpp=False, criterion=\"cross_entropy\", forget_sport_subset={val_sport}, is_forget_dataset=True)\n",
    "    eval_tasks = {\"induction\": induction_eval, \"pile\": test_pile, \"forget_sport\": forget_sport_eval, \"maintain_sport\": maintain_sport_eval, \"val_sport\": val_sport_eval}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>athlete</th>\n",
       "      <th>sport</th>\n",
       "      <th>log_prob_one_shot</th>\n",
       "      <th>num_athlete_tokens</th>\n",
       "      <th>sport_index</th>\n",
       "      <th>sport_token</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642</td>\n",
       "      <td>DeForest Buckner</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.492917</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>738</td>\n",
       "      <td>Walter Payton</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.105714</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16778</td>\n",
       "      <td>Anthony DeSclafani</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.292668</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14501</td>\n",
       "      <td>Kevin Millwood</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.372979</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188</td>\n",
       "      <td>Vonta Leach</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.648644</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16887</td>\n",
       "      <td>Mitch Haniger</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.116977</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1371</td>\n",
       "      <td>Landon Collins</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.201034</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>930</td>\n",
       "      <td>Charlie Whitehurst</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.370951</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14084</td>\n",
       "      <td>Mariano Rivera</td>\n",
       "      <td>baseball</td>\n",
       "      <td>-0.060939</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14623</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5840</td>\n",
       "      <td>Boris Diaw</td>\n",
       "      <td>basketball</td>\n",
       "      <td>-0.155351</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14648</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1046</td>\n",
       "      <td>Michael Floyd</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.176301</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7253</td>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>basketball</td>\n",
       "      <td>-0.218019</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14648</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5611</td>\n",
       "      <td>Damon Stoudamire</td>\n",
       "      <td>basketball</td>\n",
       "      <td>-0.113105</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14648</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6347</td>\n",
       "      <td>Mario Chalmers</td>\n",
       "      <td>basketball</td>\n",
       "      <td>-0.182869</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14648</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>693</td>\n",
       "      <td>LaMarr Woodley</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.376294</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7323</td>\n",
       "      <td>Stan Van Gundy</td>\n",
       "      <td>basketball</td>\n",
       "      <td>-0.117287</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14648</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0             athlete       sport  log_prob_one_shot  \\\n",
       "0         1642    DeForest Buckner    football          -0.492917   \n",
       "1          738       Walter Payton    football          -0.105714   \n",
       "2        16778  Anthony DeSclafani    baseball          -0.292668   \n",
       "3        14501      Kevin Millwood    baseball          -0.372979   \n",
       "4          188         Vonta Leach    football          -0.648644   \n",
       "5        16887       Mitch Haniger    baseball          -0.116977   \n",
       "6         1371      Landon Collins    football          -0.201034   \n",
       "7          930  Charlie Whitehurst    football          -0.370951   \n",
       "8        14084      Mariano Rivera    baseball          -0.060939   \n",
       "9         5840          Boris Diaw  basketball          -0.155351   \n",
       "10        1046       Michael Floyd    football          -0.176301   \n",
       "11        7253         Jae Crowder  basketball          -0.218019   \n",
       "12        5611    Damon Stoudamire  basketball          -0.113105   \n",
       "13        6347      Mario Chalmers  basketball          -0.182869   \n",
       "14         693      LaMarr Woodley    football          -0.376294   \n",
       "15        7323      Stan Van Gundy  basketball          -0.117287   \n",
       "\n",
       "    num_athlete_tokens  sport_index  sport_token  \\\n",
       "0                    5            2         5842   \n",
       "1                    3            2         5842   \n",
       "2                    6            0        14623   \n",
       "3                    3            0        14623   \n",
       "4                    5            2         5842   \n",
       "5                    3            0        14623   \n",
       "6                    3            2         5842   \n",
       "7                    3            2         5842   \n",
       "8                    3            0        14623   \n",
       "9                    4            1        14648   \n",
       "10                   2            2         5842   \n",
       "11                   4            1        14648   \n",
       "12                   6            1        14648   \n",
       "13                   3            1        14648   \n",
       "14                   5            2         5842   \n",
       "15                   4            1        14648   \n",
       "\n",
       "                                               prompt  \n",
       "0   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "1   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "2   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "3   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "4   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "5   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "6   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "7   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "8   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "9   Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "10  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "11  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "12  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "13  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "14  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "15  Fact: Tiger Woods plays the sport of golf\\nFac...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_1mp.train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relearning Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "def do_relearning(model, train_tasks, n_iters, finetune_lora=False, lora_kwargs={'rank': 64, 'alpha': 32, 'dropout': 0.05, 'target_modules': 'all-linear'}, learning_kwargs={'lr': 1e-2, 'weight_decay': 0, 'use_cosine': False}, eval_callback_fn=None):\n",
    "    # can either finetune full or lora\n",
    "\n",
    "    if not finetune_lora:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_kwargs['lr'], weight_decay=learning_kwargs['weight_decay'])\n",
    "\n",
    "    elif finetune_lora:\n",
    "        peft_config = LoraConfig(\n",
    "            task_type=TaskType.CAUSAL_LM,\n",
    "            inference_mode=False,\n",
    "            r=lora_kwargs['rank'],\n",
    "            lora_alpha=lora_kwargs['alpha'],\n",
    "            lora_dropout=lora_kwargs['dropout'],\n",
    "            target_modules = lora_kwargs['target_modules'], #[\"q_proj\", \"v_proj\", \n",
    "        )\n",
    "\n",
    "        model = get_peft_model(model, peft_config).cuda()\n",
    "        # model.print_trainable_parameters()\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_kwargs['lr'], weight_decay=learning_kwargs['weight_decay'])\n",
    "    \n",
    "    if learning_kwargs['use_cosine']:\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=n_iters)\n",
    "\n",
    "    train_losses = defaultdict(list)\n",
    "    test_losses = []\n",
    "\n",
    "    for i in tqdm(range(n_iters)):\n",
    "        optimizer.zero_grad()\n",
    "        for task_name, (task, task_weight) in train_tasks.items():\n",
    "            loss = task.get_train_loss(model)\n",
    "            train_losses[task_name].append(loss.item())\n",
    "            # print(loss.item())\n",
    "            (loss * task_weight).backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if learning_kwargs['use_cosine']:\n",
    "            scheduler.step()\n",
    "\n",
    "        if eval_callback_fn is not None:\n",
    "            test_losses.append(eval_callback_fn(model))\n",
    "\n",
    "    if len(test_losses) > 0:\n",
    "        return train_losses, test_losses\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>athlete</th>\n",
       "      <th>sport</th>\n",
       "      <th>log_prob_one_shot</th>\n",
       "      <th>num_athlete_tokens</th>\n",
       "      <th>sport_index</th>\n",
       "      <th>sport_token</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642</td>\n",
       "      <td>DeForest Buckner</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.492917</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>738</td>\n",
       "      <td>Walter Payton</td>\n",
       "      <td>football</td>\n",
       "      <td>-0.105714</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5842</td>\n",
       "      <td>Fact: Tiger Woods plays the sport of golf\\nFac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           athlete     sport  log_prob_one_shot  \\\n",
       "0        1642  DeForest Buckner  football          -0.492917   \n",
       "1         738     Walter Payton  football          -0.105714   \n",
       "\n",
       "   num_athlete_tokens  sport_index  sport_token  \\\n",
       "0                   5            2         5842   \n",
       "1                   3            2         5842   \n",
       "\n",
       "                                              prompt  \n",
       "0  Fact: Tiger Woods plays the sport of golf\\nFac...  \n",
       "1  Fact: Tiger Woods plays the sport of golf\\nFac...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_eval_iters = 10\n",
    "n_relearn_iters = 10\n",
    "n_relearn_athletes = 2\n",
    "\n",
    "\n",
    "if forget_sport is None:\n",
    "    relearn_sport = SportsTask(batch_size=n_relearn_athletes, tokenizer=tokenizer, forget_player_subset=n_relearn_athletes, train_test_split=False, is_forget_dataset=True)\n",
    "else:\n",
    "    relearn_sport = SportsTask(batch_size=n_relearn_athletes, tokenizer=tokenizer, forget_sport_subset={forget_sport}, forget_player_subset=n_relearn_athletes, train_test_split=False, is_forget_dataset=True)\n",
    "\n",
    "relearn_sport.train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa7f8d95f744a339529faa4e1d425d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9cb7615a6a414ebe8a0aa79a08fbf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running relearning for orthogonalized_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b79c17f27fb4046a5a77f23da0415d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7970aaaccca24732ae073f9df08698a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d898c3a548a49258189d3a9ff1d06bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 175k/175k [00:00<00:00, 516kB/s]\n",
      "Downloading data: 100%|██████████| 1.28M/1.28M [00:00<00:00, 6.95MB/s]\n",
      "Downloading data: 100%|██████████| 208k/208k [00:00<00:00, 1.63MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad168b90b97848c8a0c194d1c9255c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2fe8ffa2a94c628fc84ea27475e029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1531 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3859f98fdf4964a68e923ab5dd5db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 79.15 GiB of which 974.12 MiB is free. Process 2057057 has 33.06 GiB memory in use. Process 2068297 has 45.13 GiB memory in use. Of the allocated memory 42.42 GiB is allocated by PyTorch, and 2.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(name)\n\u001b[1;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 47\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mdo_relearning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_tasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_relearn_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinetune_lora\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_cosine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_callback_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m relearning_train_results[name] \u001b[38;5;241m=\u001b[39m train_losses\n\u001b[1;32m     50\u001b[0m relearning_test_results[name] \u001b[38;5;241m=\u001b[39m test_losses\n",
      "Cell \u001b[0;32mIn[5], line 42\u001b[0m, in \u001b[0;36mdo_relearning\u001b[0;34m(model, train_tasks, n_iters, finetune_lora, lora_kwargs, learning_kwargs, eval_callback_fn)\u001b[0m\n\u001b[1;32m     39\u001b[0m         scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callback_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m         test_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43meval_callback_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(test_losses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_losses, test_losses\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36meval_callback\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_callback\u001b[39m(model):\n\u001b[0;32m---> 18\u001b[0m     mmlu_score \u001b[38;5;241m=\u001b[39m \u001b[43mrun_general_evals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgemma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMMLU\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m     adversarial_results \u001b[38;5;241m=\u001b[39m adversarial_sports_eval_redo(model, model_type\u001b[38;5;241m=\u001b[39mmodel_type, batch_size\u001b[38;5;241m=\u001b[39meval_batch_size, \n\u001b[1;32m     20\u001b[0m                     forget_task_init_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_system_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_icl\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\u001b[38;5;241m|\u001b[39mforget_kwargs, \n\u001b[1;32m     21\u001b[0m                     maintain_task_init_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_system_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_icl\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\u001b[38;5;241m|\u001b[39mmaintain_kwargs, \n\u001b[1;32m     22\u001b[0m                     continuous\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, include_evals\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMC\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# get dictionary of both\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/general_capabilities/MCTask_redo.py:235\u001b[0m, in \u001b[0;36mrun_general_evals\u001b[0;34m(model, model_type, evals_to_include, verbose, batch_size)\u001b[0m\n\u001b[1;32m    233\u001b[0m     n_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iters):\n\u001b[0;32m--> 235\u001b[0m         accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmmlu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_test_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_test_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_all_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     accuracy_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMMLU\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m accuracy \u001b[38;5;241m/\u001b[39m n_iters\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/general_capabilities/MCTask_redo.py:69\u001b[0m, in \u001b[0;36mMultipleChoiceQuestion.get_test_accuracy\u001b[0;34m(self, model, use_test_data, check_all_logits, continuous)\u001b[0m\n\u001b[1;32m     66\u001b[0m prompts, labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 69\u001b[0m     last_logits \u001b[38;5;241m=\u001b[39m \u001b[43mget_final_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m possible_choices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_answer_choices(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# print(f\"Decoded last logits: {self.tokenizer.batch_decode(last_logits.argmax(dim=-1))}\")\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# print(f\"Last logit tokens: {last_logits.argmax(dim=-1)}\")\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# print(f\"Labels: {labels}, possible choices: {possible_choices}\")\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# print()\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/tasks/inference_utils.py:146\u001b[0m, in \u001b[0;36mget_final_logits\u001b[0;34m(model, tokenizer, batch_text, device, input_text, len_final_logits)\u001b[0m\n\u001b[1;32m    143\u001b[0m     final_token_pos \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m batch_text]\n\u001b[1;32m    144\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch_text\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 146\u001b[0m logits \u001b[38;5;241m=\u001b[39m process_model_output(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_text), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogits shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match batch_text length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch_text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# get logits for final token in each text\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/peft/peft_model.py:1430\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1429\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1441\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:179\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py:1105\u001b[0m, in \u001b[0;36mGemmaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1102\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1119\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py:923\u001b[0m, in \u001b[0;36mGemmaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    912\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    913\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    920\u001b[0m         cache_position,\n\u001b[1;32m    921\u001b[0m     )\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py:658\u001b[0m, in \u001b[0;36mGemmaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    657\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 658\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    661\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/transformers/models/gemma/modeling_gemma.py:189\u001b[0m, in \u001b[0;36mGemmaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mechanistic-unlearning/.venv/lib/python3.10/site-packages/peft/tuners/lora/layer.py:569\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(lora_A\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dora[active_adapter]:\n\u001b[0;32m--> 569\u001b[0m     result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m+\u001b[39m \u001b[43mlora_B\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlora_A\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    571\u001b[0m     x \u001b[38;5;241m=\u001b[39m dropout(x)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 79.15 GiB of which 974.12 MiB is free. Process 2057057 has 33.06 GiB memory in use. Process 2068297 has 45.13 GiB memory in use. Of the allocated memory 42.42 GiB is allocated by PyTorch, and 2.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "n_eval_iters = 10\n",
    "n_relearn_iters = 10\n",
    "n_relearn_athletes = 2\n",
    "\n",
    "\n",
    "if forget_sport is None:\n",
    "    relearn_sport = SportsTask(batch_size=n_relearn_athletes, tokenizer=tokenizer, forget_player_subset=n_relearn_athletes, train_test_split=False, is_forget_dataset=True)\n",
    "else:\n",
    "    relearn_sport = SportsTask(batch_size=n_relearn_athletes, tokenizer=tokenizer, forget_sport_subset={forget_sport}, forget_player_subset=n_relearn_athletes, train_test_split=False, is_forget_dataset=True)\n",
    "\n",
    "pile = PileTask(batch_size=8, tokenizer=tokenizer, ctx_length=256, shuffle=True, buffer_size=1000)\n",
    "train_tasks = {\"relearn_athletes\": (relearn_sport, .2), \"maintain_athletes\": (maintain_sports, 1), \"pile\": (train_pile, 1)}\n",
    "\n",
    "from tasks.facts.SportsTaskAdversarial import adversarial_sports_eval_redo\n",
    "from tasks.general_capabilities.MCTask_redo import run_general_evals\n",
    "\n",
    "def eval_callback(model):\n",
    "    mmlu_score = run_general_evals(model, model_type=\"gemma\")[\"MMLU\"]\n",
    "    adversarial_results = adversarial_sports_eval_redo(model, model_type=model_type, batch_size=eval_batch_size, \n",
    "                    forget_task_init_kwargs={\"use_system_prompt\":True, \"use_icl\":False}|forget_kwargs, \n",
    "                    maintain_task_init_kwargs={\"use_system_prompt\":True, \"use_icl\":False}|maintain_kwargs, \n",
    "                    continuous=True, include_evals=[\"Normal\", \"MC\"])\n",
    "\n",
    "    # get dictionary of both\n",
    "    return {\"MMLU\": mmlu_score, \"adversarial\": adversarial_results}\n",
    "\n",
    "# del model\n",
    "\n",
    "# for name, model, mask, regular_evals, side_effect_evals, adversarial_evals in [(\"localized\", localized_model, localized_mask, localized_regular_evals, localized_side_effect_evals, localized_adversarial_evals), (\"nonlocalized\", nonlocalized_model, nonlocalized_mask, nonlocalized_regular_evals, nonlocalized_side_effect_evals, nonlocalized_adversarial_evals)]:\n",
    "\n",
    "relearning_train_results = {}\n",
    "relearning_test_results = {}\n",
    "relearning_regular_results = {}\n",
    "relearning_adversarial_results = {}\n",
    "relearning_side_effect_results = {}\n",
    "\n",
    "# for name in mask_init_funcs.keys():\n",
    "\n",
    "locations = [\"orthogonalized_model\"]\n",
    "\n",
    "for name in locations:\n",
    "    print(f\"Running relearning for {name}\")\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(name, torch_dtype=torch.bfloat16)\n",
    "    model.cuda()\n",
    "\n",
    "    train_losses, test_losses = do_relearning(model, train_tasks, n_iters=n_relearn_iters, finetune_lora=True, learning_kwargs={'lr': 1e-4, 'weight_decay': 0, 'use_cosine': True}, eval_callback_fn=eval_callback)\n",
    "\n",
    "    relearning_train_results[name] = train_losses\n",
    "    relearning_test_results[name] = test_losses\n",
    "\n",
    "    relearning_regular_results[name] = {}\n",
    "    for task_name, test_task in [(\"forget_sport\", forget_sport_eval), (\"maintain_sports\", maintain_sports_eval)]:\n",
    "        task_loss = 0\n",
    "        task_accuracy = 0\n",
    "        for i in range(n_eval_iters):\n",
    "            task_loss += test_task.get_test_loss(model).item()\n",
    "            task_accuracy += test_task.get_test_accuracy(model)\n",
    "        relearning_regular_results[name][f\"{task_name}_ce\"] = task_loss / n_eval_iters\n",
    "        relearning_regular_results[name][f\"{task_name}_acc\"] = task_accuracy / n_eval_iters\n",
    "\n",
    "    adversarial_eval_results = adversarial_sports_eval_redo(model, model_type=model_type, batch_size=eval_batch_size, \n",
    "                    forget_task_init_kwargs={\"use_system_prompt\":True, \"use_icl\":False}|forget_kwargs, \n",
    "                    maintain_task_init_kwargs={\"use_system_prompt\":True, \"use_icl\":False}|maintain_kwargs, \n",
    "                    continuous=True, include_evals=[\"Normal\", \"MC\"])\n",
    "    relearning_adversarial_results[name] = adversarial_eval_results\n",
    "\n",
    "    side_effect_eval_results = run_side_effects_evals(model, model_type=model_type, batch_size=eval_batch_size, evals_to_run=[\"General\"], general_batch_size=5)\n",
    "    relearning_side_effect_results[name] = side_effect_eval_results\n",
    "\n",
    "    model.cpu()\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relearning_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to plot relearning results\n",
    "def plot_relearning_results(relearning_test_results, metric, title, ylabel):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for name, results in relearning_test_results.items():\n",
    "        values = [result[metric] if metric != 'adversarial' else result[metric]['Normal']['forget'] for result in results]\n",
    "        plt.plot(range(len(values)), values, label=name, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot MMLU\n",
    "plot_relearning_results(relearning_test_results, 'MMLU', 'MMLU while Relearning Basketball', 'MMLU Score')\n",
    "\n",
    "# Plot adversarial-normal-forget\n",
    "def plot_adversarial_results(relearning_test_results, adversarial_type, forget_or_maintain, title, ylabel):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for name, results in relearning_test_results.items():\n",
    "        values = [result['adversarial'][adversarial_type][forget_or_maintain] for result in results]\n",
    "        plt.plot(range(len(values)), values, label=name, marker='o')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot adversarial-normal-forget\n",
    "plot_adversarial_results(relearning_test_results, 'Normal', 'forget', 'Normal Basketball-forget Accuracy Over Relearning Iterations', 'Normal Basketball-forget Accuracy')\n",
    "\n",
    "# Plot adversarial-normal-maintain\n",
    "plot_adversarial_results(relearning_test_results, 'Normal', 'maintain', 'Normal Sports-maintain Accuracy Over Relearning Iterations', 'Normal Sports-maintain Accuracy')\n",
    "\n",
    "# Plot adversarial-mc-forget\n",
    "plot_adversarial_results(relearning_test_results, 'MC', 'forget', 'MC Basketball-forget Accuracy Over Relearning Iterations', 'MC Basketball-forget Accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{save_dir}/results\", exist_ok=True)\n",
    "with open(f\"{save_dir}/results/relearning_{n_relearn_athletes=}_{n_relearn_iters=}_{model_type}_{combine_heads=}_{beta=}_unlearn_{forget_sport=}_{forget_athletes=}_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"relearning_regular_results\": relearning_regular_results, \"relearning_adversarial_results\": relearning_adversarial_results, \"relearning_side_effect_results\": relearning_side_effect_results, \"relearning_train_results\": relearning_train_results, \"relearning_test_results\": relearning_test_results}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_relearn_athletes = 2\n",
    "n_relearn_iters = 10\n",
    "model_type = \"gemma\"\n",
    "# combine_heads = False\n",
    "beta = 3\n",
    "\n",
    "with open(f\"{save_dir}/results/relearning_{n_relearn_athletes=}_{n_relearn_iters=}_{model_type}_{combine_heads=}_{beta=}_unlearn_{forget_sport=}_{forget_athletes=}_results.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "    relearning_regular_results = results['relearning_regular_results']\n",
    "    relearning_adversarial_results = results['relearning_adversarial_results']\n",
    "    relearning_side_effect_results = results['relearning_side_effect_results']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relearning_regular_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relearning_adversarial_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_heads = False\n",
    "model_paths_dict = {\n",
    "    localization_type: f\"{save_dir}/models/{model_type}_{localization_type}_{combine_heads=}_{beta=}_unlearn_{forget_sport=}_{forget_athletes=}.pt\" for localization_type in localization_types\n",
    "}\n",
    "def model_init_and_load_func(mask_type):\n",
    "    model_path = model_paths_dict[mask_type]\n",
    "    def get_model_fn():\n",
    "        model = AutoModelForCausalLM.from_pretrained(\"google/gemma-7b\", torch_dtype=torch.bfloat16)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        return model\n",
    "    return get_model_fn\n",
    "model_init_and_load_funcs = {mask_type: model_init_and_load_func(mask_type) for mask_type in localization_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b\")\n",
    "left_tokenizer.pad_token_id = left_tokenizer.eos_token_id\n",
    "left_tokenizer.padding_side = \"left\"\n",
    "\n",
    "from collections import defaultdict\n",
    "def layer_hook_function(layer, outputs, last_token_only=True, store_cpu=False):\n",
    "    def hook_fn(module, input, output):\n",
    "        if isinstance(output, tuple):\n",
    "            save_output = output[0].clone().detach()\n",
    "        else:\n",
    "            save_output = output.clone().detach()\n",
    "        if last_token_only:\n",
    "            save_output = save_output[:, -1]\n",
    "        if store_cpu:\n",
    "            save_output = save_output.cpu()\n",
    "        outputs[layer].append(save_output)\n",
    "        # return output\n",
    "    return hook_fn\n",
    "\n",
    "def get_hf_residuals(texts, model, batch_size, last_token_only=True, layers_module=None, store_cpu=True, text_col=\"prompt\"):\n",
    "    # needs left_\n",
    "    outputs = defaultdict(list)\n",
    "    hooks = []\n",
    "    if layers_module is None:\n",
    "        layers_module = model.model.layers\n",
    "    for layer, block in enumerate(layers_module):\n",
    "        hook_fn = layer_hook_function(layer, outputs=outputs, last_token_only=last_token_only, store_cpu=store_cpu)\n",
    "        hook_applied = block.register_forward_hook(hook_fn)\n",
    "        hooks.append(hook_applied)\n",
    "\n",
    "    for idx in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[idx:idx+batch_size]\n",
    "        tokenized = left_tokenizer(batch_texts, return_tensors=\"pt\", padding=True)\n",
    "        tokenized = {k: v.cuda() for k, v in tokenized.items()}\n",
    "        with torch.no_grad():\n",
    "            model(**tokenized)\n",
    "    \n",
    "    for layer in outputs:\n",
    "        outputs[layer] = torch.cat(outputs[layer], dim=0)\n",
    "        if store_cpu:\n",
    "            outputs[layer] = outputs[layer].cpu()\n",
    "\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "def get_resids(sports_task, model):\n",
    "    train_outputs = get_hf_residuals(sports_task.train_df[\"prompt\"].tolist(), model, batch_size, last_token_only=True) # needs to not be last token only because of layernorm\n",
    "    test_outputs = get_hf_residuals(sports_task.test_df[\"prompt\"].tolist(), model, batch_size, last_token_only=True)\n",
    "\n",
    "    train_labels = sports_task.train_df['sport'].tolist()\n",
    "    test_labels = sports_task.test_df['sport'].tolist()\n",
    "    return train_outputs, test_outputs, train_labels, test_labels\n",
    "\n",
    "forget_is_split = True if forget_sport is not None else False\n",
    "if forget_is_split:\n",
    "    forget_train_outputs_dict = {}\n",
    "    forget_test_outputs_dict = {}\n",
    "    forget_train_labels_dict = {}\n",
    "    forget_test_labels_dict = {}\n",
    "else:\n",
    "    forget_outputs_dict = {}\n",
    "    forget_labels_dict = {}\n",
    "\n",
    "maintain_train_outputs_dict = {}\n",
    "maintain_test_outputs_dict = {}\n",
    "maintain_train_labels_dict = {}\n",
    "maintain_test_labels_dict = {}\n",
    "\n",
    "for model_name in model_init_and_load_funcs:\n",
    "    model = model_init_and_load_funcs[model_name]()\n",
    "    model.cuda()\n",
    "    if forget_is_split:\n",
    "        forget_train_outputs_dict[model_name], forget_test_outputs_dict[model_name], forget_train_labels_dict[model_name], forget_test_labels_dict[model_name] = get_resids(forget_sport_eval, model)\n",
    "    else:\n",
    "        forget_outputs_dict[model_name], _, forget_labels_dict[model_name], _ = get_resids(forget_sport_eval, model)\n",
    "    maintain_train_outputs_dict[model_name], maintain_test_outputs_dict[model_name], maintain_train_labels_dict[model_name], maintain_test_labels_dict[model_name] = get_resids(maintain_sports_eval, model)\n",
    "\n",
    "    model.cpu()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set train and test splits\n",
    "if not forget_is_split:\n",
    "    print(\"Performing manual split of the unsplit training dataset\")\n",
    "    train_test_split = .5\n",
    "    forget_train_outputs_dict = {}\n",
    "    forget_test_outputs_dict = {}\n",
    "    forget_train_labels_dict = {}\n",
    "    forget_test_labels_dict = {}\n",
    "    for model_name in model_init_and_load_funcs:\n",
    "        num_train = int(len(forget_labels_dict[model_name]) * train_test_split)\n",
    "        forget_train_labels_dict[model_name] = forget_labels_dict[model_name][:num_train]\n",
    "        forget_test_labels_dict[model_name] = forget_labels_dict[model_name][num_train:]\n",
    "        forget_train_outputs_dict[model_name] = {}\n",
    "        forget_test_outputs_dict[model_name] = {}\n",
    "        for layer in range(n_layers):\n",
    "            forget_train_outputs_dict[model_name][layer] = forget_outputs_dict[model_name][layer][:num_train]\n",
    "            forget_test_outputs_dict[model_name][layer] = forget_outputs_dict[model_name][layer][num_train:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_layers):\n",
    "    print(f\"On layer {i}, AP == CT activations is: {(forget_train_outputs_dict['localized_ap'][i] == forget_train_outputs_dict['localized_ct'][i]).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Approach 1: test probes on forget data and maintain data separately?\n",
    "not really sure what I did here, but it should generalize to individual athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def get_sport_labels(string_labels, return_np=True):\n",
    "    # want three different lists of labels, one for each sport\n",
    "    sports = [\"baseball\", \"football\", \"basketball\"]\n",
    "    sport_labels = {sport: [] for sport in sports}\n",
    "    for label in string_labels:\n",
    "        for sport in sports:\n",
    "            if sport in label:\n",
    "                sport_labels[sport].append(1)\n",
    "            else:\n",
    "                sport_labels[sport].append(0)\n",
    "    if return_np:\n",
    "        for sport in sports:\n",
    "            sport_labels[sport] = np.array(sport_labels[sport])\n",
    "        \n",
    "    assert sum(sport_labels[\"baseball\"]) + sum(sport_labels[\"football\"]) + sum(sport_labels[\"basketball\"]) == len(string_labels)\n",
    "    # assert each position always adds up to 1\n",
    "    for i in range(len(string_labels)):\n",
    "        assert sport_labels[\"baseball\"][i] + sport_labels[\"football\"][i] + sport_labels[\"basketball\"][i] == 1\n",
    "    return sport_labels\n",
    "\n",
    "# train probes\n",
    "all_probes = defaultdict(dict) # double-nested dictionary, first keys are model_name, second keys are layers, final values are dictionaries with keys \"basketball\", \"football\", \"baseball\" and values of probes\n",
    "\n",
    "all_train_accs = defaultdict(dict)\n",
    "all_test_accs = defaultdict(dict)\n",
    "all_forget_accs = defaultdict(dict)\n",
    "all_maintain_accs = defaultdict(dict)\n",
    "\n",
    "combine_accuracies = True\n",
    "\n",
    "shuffle_train = True\n",
    "for model_name in tqdm(model_init_and_load_funcs):\n",
    "    # train_acts = {}\n",
    "\n",
    "    forget_test_acts = forget_test_outputs_dict[model_name]\n",
    "    forget_test_labels = get_sport_labels(forget_test_labels_dict[model_name])\n",
    "    maintain_test_acts = maintain_test_outputs_dict[model_name]\n",
    "    maintain_test_labels = get_sport_labels(maintain_test_labels_dict[model_name])\n",
    "\n",
    "    forget_train_acts = forget_train_outputs_dict[model_name]\n",
    "    maintain_train_acts = maintain_train_outputs_dict[model_name]\n",
    "    # forget_test_labels_dict[model_name] + maintain_test_labels_dict[model_name]\n",
    "    train_labels = forget_train_labels_dict[model_name] + maintain_train_labels_dict[model_name]\n",
    "    train_labels = get_sport_labels(train_labels)\n",
    "\n",
    "    test_labels = forget_test_labels_dict[model_name] + maintain_test_labels_dict[model_name]\n",
    "    test_labels = get_sport_labels(test_labels)\n",
    "\n",
    "    if shuffle_train:\n",
    "        shuffle_idx = torch.randperm(len(list(train_labels.values())[0]))\n",
    "\n",
    "    if shuffle_train:\n",
    "        for sport in train_labels:\n",
    "            train_labels[sport] = train_labels[sport][shuffle_idx]\n",
    "    \n",
    "    # print(f\"Labels look like {train_labels}\")\n",
    "\n",
    "    for layer in range(n_layers):\n",
    "        layer_train_acts = torch.cat([forget_train_acts[layer], maintain_train_acts[layer]], dim=0).float().cpu().numpy()\n",
    "        layer_test_acts = torch.cat([forget_test_acts[layer], maintain_test_acts[layer]], dim=0).float().cpu().numpy()\n",
    "        layer_forget_test_acts = forget_test_acts[layer].float().cpu().numpy()\n",
    "        layer_maintain_test_acts = maintain_test_acts[layer].float().cpu().numpy()\n",
    "\n",
    "        if shuffle_train:\n",
    "            layer_train_acts = layer_train_acts[shuffle_idx]\n",
    "        all_probes[model_name][layer] = {}\n",
    "\n",
    "        if not combine_accuracies:\n",
    "            all_train_accs[model_name][layer] = {}\n",
    "            all_test_accs[model_name][layer] = {}\n",
    "            all_forget_accs[model_name][layer] = {}\n",
    "            all_maintain_accs[model_name][layer] = {}\n",
    "\n",
    "        sports_train_preds = {}\n",
    "        sports_test_preds = {}\n",
    "        sports_forget_preds = {}\n",
    "        sports_maintain_preds = {}\n",
    "        for sport in train_labels:\n",
    "            if sum(train_labels[sport]) <= 0:\n",
    "                print(\"No labels for sport\", sport)\n",
    "                continue\n",
    "            probe = LogisticRegression(max_iter=10000)\n",
    "            # print(f\"Training probe for {sport} at layer {layer}, {layer_train_acts.shape=}, {train_labels[sport].shape=}, {train_labels[sport].mean()=}\")\n",
    "            probe.fit(layer_train_acts, train_labels[sport])\n",
    "            all_probes[model_name][layer][sport] = probe\n",
    "\n",
    "            # test probes\n",
    "            # print(f\"{sport=}, {layer_train_acts.shape=}, {train_labels[sport].shape=}, {train_labels[sport].mean()=}\")\n",
    "            train_preds = probe.predict(layer_train_acts)\n",
    "            if not combine_accuracies:\n",
    "                train_acc = (train_preds == train_labels[sport]).sum() / len(train_labels[sport])\n",
    "                all_train_accs[model_name][layer][sport] = train_acc\n",
    "            else:\n",
    "                sports_train_preds[sport] = train_preds\n",
    "\n",
    "\n",
    "            # print(f\"Testing probe for {sport} at layer {layer}, {layer_test_acts.shape=}, {test_labels[sport].shape=}, {test_labels[sport].mean()=}\")\n",
    "            test_preds = probe.predict(layer_test_acts)\n",
    "            if not combine_accuracies:\n",
    "                test_acc = (test_preds == test_labels[sport]).sum() / len(test_labels[sport])\n",
    "                all_forget_accs[model_name][layer][sport] = test_acc\n",
    "            else:\n",
    "                sports_test_preds[sport] = test_preds\n",
    "\n",
    "            # print(f\"{sport=}, {layer_forget_test_acts.shape=}, {forget_test_labels[sport].shape=}, {forget_test_labels[sport].mean()=}\")\n",
    "            forget_test_preds = probe.predict(layer_forget_test_acts)\n",
    "            if not combine_accuracies:\n",
    "                forget_acc = (forget_test_preds == forget_test_labels[sport]).sum() / len(forget_test_labels[sport])\n",
    "                all_test_accs[model_name][layer][sport] = forget_acc\n",
    "            else:\n",
    "                sports_forget_preds[sport] = forget_test_preds\n",
    "\n",
    "            # print(f\"{sport=}, {layer_maintain_test_acts.shape=}, {maintain_test_labels[sport].shape=}, {maintain_test_labels[sport].mean()=}\")\n",
    "            maintain_test_preds = probe.predict(layer_maintain_test_acts)\n",
    "            if not combine_accuracies:\n",
    "                maintain_acc = (maintain_test_preds == maintain_test_labels[sport]).sum() / len(maintain_test_labels[sport])\n",
    "                all_maintain_accs[model_name][layer][sport] = maintain_acc \n",
    "            else:\n",
    "                sports_maintain_preds[sport] = maintain_test_preds\n",
    "\n",
    "        if combine_accuracies:\n",
    "            # combine accuracies by saying probes correct if all sports are correct\n",
    "            train_correct = np.ones(len(train_labels[\"baseball\"]))\n",
    "            test_correct = np.ones(len(test_labels[\"baseball\"]))\n",
    "            forget_correct = np.ones(len(forget_test_labels[\"baseball\"]))\n",
    "            maintain_correct = np.ones(len(maintain_test_labels[\"baseball\"]))\n",
    "            for sport in train_labels:\n",
    "                if sum(train_labels[sport]) > 0:\n",
    "                    train_correct *= (sports_train_preds[sport] == train_labels[sport])\n",
    "                else:\n",
    "                    print(\"No train labels for sport\", sport)\n",
    "                if sum(test_labels[sport]) > 0:\n",
    "                    test_correct *= (sports_test_preds[sport] == test_labels[sport])\n",
    "                else:\n",
    "                    print(\"No test labels for sport\", sport)\n",
    "                if sum(forget_test_labels[sport]) > 0:\n",
    "                    forget_correct *= (sports_forget_preds[sport] == forget_test_labels[sport])\n",
    "                else:\n",
    "                    print(\"No forget labels for sport\", sport)\n",
    "                if sum(maintain_test_labels[sport]) > 0:\n",
    "                    maintain_correct *= (sports_maintain_preds[sport] == maintain_test_labels[sport])\n",
    "                else:\n",
    "                    print(\"No maintain labels for sport\", sport)\n",
    "\n",
    "            all_train_accs[model_name][layer] = train_correct.mean()\n",
    "            all_test_accs[model_name][layer] = test_correct.mean()\n",
    "            all_forget_accs[model_name][layer] = forget_correct.mean()\n",
    "            all_maintain_accs[model_name][layer] = maintain_correct.mean()\n",
    "\n",
    "with open(f\"{save_dir}/results/probes_{model_type}_{combine_heads=}_{beta=}_unlearn_{forget_sport=}_{forget_athletes=}.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"all_probes\": all_probes, \"all_train_accs\": all_train_accs, \"all_test_accs\": all_test_accs, \"all_forget_accs\": all_forget_accs, \"all_maintain_accs\": all_maintain_accs}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_layers):\n",
    "    print(f\"At layer {i}, {(all_probes['localized_ap'][i]['basketball'].coef_ - all_probes['localized_ct'][i]['basketball'].coef_).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# combine_heads = False #accidentally set this earlier, but its not actually False in the models\n",
    "with open(f\"{save_dir}/results/probes_{model_type}_{combine_heads=}_{beta=}_unlearn_{forget_sport=}_{forget_athletes=}.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "    all_probes = results['all_probes']\n",
    "    all_train_accs = results['all_train_accs']\n",
    "    all_test_accs = results['all_test_accs']\n",
    "    all_forget_accs = results['all_forget_accs']\n",
    "    all_maintain_accs = results['all_maintain_accs']\n",
    "\n",
    "# combine_accuracies = True\n",
    "if combine_accuracies:\n",
    "    def plot_accuracies(all_train_accs, all_test_accs, all_forget_accs, all_maintain_accs):\n",
    "        for model_name in all_train_accs.keys():\n",
    "            layers = list(all_train_accs[model_name].keys())\n",
    "            train_accs = [all_train_accs[model_name][layer] for layer in layers]\n",
    "            test_accs = [all_test_accs[model_name][layer] for layer in layers]\n",
    "            forget_accs = [all_forget_accs[model_name][layer] for layer in layers]\n",
    "            maintain_accs = [all_maintain_accs[model_name][layer] for layer in layers]\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(layers, train_accs, label='Train Accuracy', alpha=0.5, linestyle='--')\n",
    "            # plt.plot(layers, test_accs, label='Test Accuracy')\n",
    "            plt.plot(layers, forget_accs, label='Forget Accuracy')\n",
    "            plt.plot(layers, maintain_accs, label='Maintain Accuracy')\n",
    "            \n",
    "            plt.xlabel('Layer')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Accuracy per Layer for {model_name}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    # Call the function to plot the accuracies\n",
    "    plot_accuracies(all_train_accs, all_test_accs, all_forget_accs, all_maintain_accs)\n",
    "\n",
    "else:\n",
    "    def plot_accuracies(all_train_accs, all_test_accs):\n",
    "        sports = [\"baseball\", \"football\", \"basketball\"]\n",
    "        \n",
    "        for model_name in all_train_accs.keys():\n",
    "            layers = list(all_train_accs[model_name].keys())\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            for sport in sports:\n",
    "                train_accs = [all_train_accs[model_name][layer].get(sport, 0) for layer in layers]\n",
    "                test_accs = [all_test_accs[model_name][layer].get(sport, 0) for layer in layers]\n",
    "                # forget_accs = [all_forget_accs[model_name][layer].get(sport, 0) for layer in layers]\n",
    "                # maintain_accs = [all_maintain_accs[model_name][layer].get(sport, 0) for layer in layers]\n",
    "                \n",
    "                plt.plot(layers, train_accs, label=f'Train Accuracy - {sport}', linestyle='--', alpha=0.5)\n",
    "                plt.plot(layers, test_accs, label=f'Test Accuracy - {sport}')\n",
    "                # plt.plot(layers, forget_accs, label=f'Forget Accuracy - {sport}')\n",
    "                # plt.plot(layers, maintain_accs, label=f'Maintain Accuracy - {sport}')\n",
    "            \n",
    "            plt.xlabel('Layer')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Accuracy per Layer for {model_name}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    # Call the function to plot the accuracies\n",
    "    plot_accuracies(all_train_accs, all_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_final_accuracies(all_accs, formal=True):\n",
    "    # colors = plt.cm.get_cmap('tab10', len(all_train_accs))  # Get a colormap with enough colors for all models\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for idx, model_name in enumerate(all_train_accs.keys()):\n",
    "        layers = list(all_train_accs[model_name].keys())\n",
    "        accs = [all_accs[model_name][layer] for layer in layers]\n",
    "\n",
    "        # plt.plot(layers, train_accs, label=f'{model_name} Train', color=colors(idx), linestyle=line_styles[0], alpha=0.5)\n",
    "        # plt.plot(layers, forget_accs, label=f'{model_name} Forget', color=colors[idx], linestyle=line_styles[1])\n",
    "        plt.plot(layers, accs, label=f'{formal_name_dict[model_name]}', color=color_map[model_name], marker='o')\n",
    "    \n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "# Call the function to plot the accuracies\n",
    "plot_final_accuracies(all_maintain_accs)\n",
    "plt.title('Probe Accuracy on Maintain Athletes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_final_accuracies(all_forget_accs)\n",
    "plt.title('Probe Accuracy on Forget Athletes')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
